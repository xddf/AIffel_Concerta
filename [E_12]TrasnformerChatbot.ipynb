{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "[E-12]TrasnformerChatbot.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# E-12. TrasnformerChatbot"
      ],
      "metadata": {
        "id": "NwzAAIMLx7Hx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- 목차\n",
        "\n",
        "    0. 기본 준비\n",
        "    1. 데이터 로드\n",
        "    2. 전처리\n",
        "    3. SubwordTextEncoder\n",
        "    4. 모델 구성\n",
        "    5. 학습 및 평가\n",
        "    6. 모델 성능 개선\n",
        "    7. 마치며"
      ],
      "metadata": {
        "id": "L85bmdb2QvRC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 0. 기본 준비"
      ],
      "metadata": {
        "id": "6U3bSOzsRQHy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "nJzjSrK3yAB5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3b6849d5-e0b3-4b7f-80b8-209d66e943ca"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow_datasets as tfds\n",
        "import os\n",
        "import re\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "76QDclg1SG3k"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "path = '/content/drive/MyDrive/Aiffel/Exploration/E-12/'"
      ],
      "metadata": {
        "id": "o1qVhcH-yBJG"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.style.use(['dark_background'])"
      ],
      "metadata": {
        "id": "KC5QTInzyTb-"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. 데이터 로드"
      ],
      "metadata": {
        "id": "e9z_JstYR93A"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1.1. 데이터 확인"
      ],
      "metadata": {
        "id": "wkJVCktkSV7L"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- 아래 링크에 공개 되어 있는 'songys'님의 데이터셋을 사용함\n",
        "> https://github.com/songys/Chatbot_data"
      ],
      "metadata": {
        "id": "uD65Q24MSamd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Data description\n",
        "    1. 챗봇 트레이닝용 문답 페어 11,876개\n",
        "    2. 일상다반사 0, 이별(부정) 1, 사랑(긍정) 2로 레이블링"
      ],
      "metadata": {
        "id": "lcVNJVSOSfKg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1.2. 경로 확인, 지정"
      ],
      "metadata": {
        "id": "K_gZp3j1SsCT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "os.listdir(path + 'data')"
      ],
      "metadata": {
        "id": "5Emn0d5pScUk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "307b71e3-4c7b-4143-916c-6f5ba16ab08a"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['ChatbotData .csv']"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "path_to_dataset = path + 'data/ChatbotData .csv'"
      ],
      "metadata": {
        "id": "OC1rfz6cSiP5"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. 기본 전처리\n",
        "\n",
        "- 아래에서 바로 확인할 수 있는 데이터셋을 보면 이미 어느 정도 정제된 데이터임을 알 수 있다.\n",
        "> https://github.com/songys/Chatbot_data/blob/master/ChatbotData.csv\n",
        "\n",
        "- 위의 디스크립션에서 확인할 수 있듯, 문답 페어의 갯수가 약 12000개이므로 샘플을 줄이는 과정은 생략한다.\n",
        "\n",
        "- 또한 실습과 달리 대화(또는 문답)이 1:1 비율로 작성되어있는 하나의 문서이기 때문에 전처리 과정에 차이가 있을 것."
      ],
      "metadata": {
        "id": "TubKBpNASj1R"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2.1. 전처리 함수 지정"
      ],
      "metadata": {
        "id": "BxsRdYJdS8X7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- preprocess"
      ],
      "metadata": {
        "id": "x9VYzf_WTFgO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess_sentence(sentence):\n",
        "  sentence = sentence.lower().strip()\n",
        "\n",
        "  # 단어와 구두점(punctuation) 사이의 거리를 만듭니다.\n",
        "  # 예를 들어서 \"I am a student.\" => \"I am a student .\"와 같이\n",
        "  # student와 온점 사이에 거리를 만듭니다.\n",
        "  sentence = re.sub(r\"([?.!,])\", r\" \\1 \", sentence)\n",
        "  sentence = re.sub(r'[\" \"]+', \" \", sentence)\n",
        "\n",
        "  return sentence"
      ],
      "metadata": {
        "id": "4H0O5fARTL3f"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "T = open(path_to_dataset, 'r')\n",
        "T.readlines()[0:5][4]"
      ],
      "metadata": {
        "id": "ZRlO3OEuTNio",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "c884c713-198a-4bc4-d22d-b397067e6e88"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'3박4일 정도 놀러가고 싶다,여행은 언제나 좋죠.,0\\n'"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- 데이터셋 페어 구성 함수"
      ],
      "metadata": {
        "id": "4P7O4h2DTxe3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 질문과 답변의 쌍인 데이터셋을 구성하기 위한 데이터 로드 함수\n",
        "def load_conversations():\n",
        "  \n",
        "  # 라벨 데이터가 있으니 빈 리스트를 하나 더 생성, 따로 담을것.\n",
        "  inputs, outputs, label = [], [], []\n",
        "  # 데이터셋을 연다.\n",
        "  with open(path_to_dataset, 'r') as file:\n",
        "    # 줄 단위로 읽어오기.  \n",
        "    lines = file.readlines()\n",
        "\n",
        "  for line in lines[1:]:\n",
        "    # 프로젝트의 데이터셋은 각 줄마다 쉼표 구분된 Q, A, label 로 구성 \n",
        "    # 첫줄은 컬럼의 역할을 하므로 제외   \n",
        "    # 줄바꿈 기호 제거\n",
        "    # 쉼표 기준으로 스플릿한다\n",
        "    conversation = line.replace('\\n', '').split(',')\n",
        "    # Q, A, label을 각각 전처리 후 리스트에 추가.\n",
        "    inputs.append(preprocess_sentence(conversation[0]))\n",
        "    outputs.append(preprocess_sentence(conversation[1]))\n",
        "    label.append(conversation[2])\n",
        "\n",
        "  return inputs, outputs, label"
      ],
      "metadata": {
        "id": "hStLFbs2TObt"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2.2. 스플릿"
      ],
      "metadata": {
        "id": "jj5MxdajT7yC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- QnA, label 스플릿"
      ],
      "metadata": {
        "id": "m3HVW79eTPsG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "questions, answers, label = load_conversations()\n",
        "print('전체 샘플 수 :', len(questions))\n",
        "print('전체 샘플 수 :', len(answers))"
      ],
      "metadata": {
        "id": "nPqcmf3xTUao",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a1d69c9e-6daf-42c8-924e-c4dc38bf3153"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "전체 샘플 수 : 11823\n",
            "전체 샘플 수 : 11823\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('전처리 후의 100번째 질문 샘플: {}'.format(questions[99]))\n",
        "print('전처리 후의 100번째 답변 샘플: {}'.format(answers[99]))"
      ],
      "metadata": {
        "id": "f4PTpk6qTU49",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "19b60464-08b6-4c9c-a29e-42e2409f1f93"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "전처리 후의 100번째 질문 샘플: 거지 같이 일해 놓고 갔어\n",
            "전처리 후의 100번째 답변 샘플: 일 못하는 사람이 있으면 옆에 있는 사람이 더 힘들죠 . \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. SubwordTextEncoder"
      ],
      "metadata": {
        "id": "-59s2nkja4LO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3.1. 단어장 만들기"
      ],
      "metadata": {
        "id": "c-NuCFpvTVsT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow_datasets as tfds\n",
        "# 데이터 총량이 적고 사용된 어휘가 비교적 균일하다.\n",
        "# 단어장 크기를 넉넉히 지정해본다.\n",
        "tokenizer = tfds.deprecated.text.SubwordTextEncoder.build_from_corpus(questions + answers, target_vocab_size=10500)"
      ],
      "metadata": {
        "id": "9AQqDjCeTZOA"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer.vocab_size"
      ],
      "metadata": {
        "id": "4SXfYBKmTakZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "587dd65d-948f-4966-cbeb-3362d59f3ff2"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "10077"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3.2. 토큰화"
      ],
      "metadata": {
        "id": "wY_0vHfYTbb9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 인코딩 처리 후 예제\n",
        "print('정수 인코딩 후의 100번째 질문 샘플: {}'.format(tokenizer.encode(questions[99])))\n",
        "print('정수 인코딩 후의 100번째 답변 샘플: {}'.format(tokenizer.encode(answers[99])))"
      ],
      "metadata": {
        "id": "Mn6TLIFWUPL5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f2d11a66-3b0a-44cb-e1dc-a9b43a3a9da1"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "정수 인코딩 후의 100번째 질문 샘플: [1692, 9853, 76, 5536, 9853, 976, 3257]\n",
            "정수 인코딩 후의 100번째 답변 샘플: [102, 862, 34, 151, 1342, 61, 34, 7, 676, 1]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 시작 토큰과 종료 토큰에 고유한 정수를 부여합니다.\n",
        "START_TOKEN, END_TOKEN = [tokenizer.vocab_size], [tokenizer.vocab_size + 1]"
      ],
      "metadata": {
        "id": "BhADwBVYUZxS"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('START_TOKEN의 번호 :' ,[tokenizer.vocab_size])\n",
        "print('END_TOKEN의 번호 :' ,[tokenizer.vocab_size + 1])"
      ],
      "metadata": {
        "id": "SFZxIiXPUbck",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5db21cbf-f126-473a-976b-2546617d246f"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "START_TOKEN의 번호 : [10077]\n",
            "END_TOKEN의 번호 : [10078]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "VOCAB_SIZE = tokenizer.vocab_size + 2\n",
        "print(VOCAB_SIZE)"
      ],
      "metadata": {
        "id": "HADqCpvLY4rr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f95adf17-506a-462a-e31e-94ced6aa41c1"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "10079\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3.3. 최대 길이 제한과 패딩"
      ],
      "metadata": {
        "id": "Udp-9U2fWrBJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- 문장의 길이를 확인해보자."
      ],
      "metadata": {
        "id": "NXAvmcZDW1sd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "q_lens = [len(s.split()) for s in questions]\n",
        "a_lens = [len(s.split()) for s in answers]\n",
        "s_lens = [len(s.split()) for s in questions + answers]"
      ],
      "metadata": {
        "id": "ik8QD2yMUdBn"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "np.std(q_lens)"
      ],
      "metadata": {
        "id": "b8UzUWVGUoZa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1ff42790-09f8-4180-e530-84045c85b37f"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1.8439116643228872"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "np.mean(q_lens)"
      ],
      "metadata": {
        "id": "-YurMhU0VeGq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "54aecc26-ec0e-4403-b57d-9bcadbd2d129"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3.9283599763173473"
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "np.std(a_lens)"
      ],
      "metadata": {
        "id": "Hqut5LNiVg6j",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7b600891-d8dd-45e7-f81f-ea5a371e3be9"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1.9021435205216073"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "np.mean(a_lens)"
      ],
      "metadata": {
        "id": "r-4Vt9fcVjiK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e0166269-1e2f-4c17-b0e8-df038f4d53d1"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4.684936141419268"
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 표준편차\n",
        "np.std(s_lens)"
      ],
      "metadata": {
        "id": "hC9NnF7FUiJl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bf764bfb-1896-4624-d4db-1fe7bcd7668d"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1.9110682804767203"
            ]
          },
          "metadata": {},
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 평균\n",
        "np.mean(s_lens)"
      ],
      "metadata": {
        "id": "WweNEi-WUm97",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "356034ee-fd7d-481e-f467-c92049f35ef5"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4.306648058868308"
            ]
          },
          "metadata": {},
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "weight = s_lens\n",
        "\n",
        "plt.hist(weight)\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "sU0Q0aP7UfWi",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "outputId": "3d9a3a88-2de9-4681-e925-d35f6f2c8cf9"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- 질문 문장과 답변 문장 간의 평균 및 편차가 그다지 차이나지 않는다. 최대 길이 제한을 일원화 해도 괜찮을 것 같다.\n",
        "- 일차적으로 최대 문장 길이 제한은 정규분포의 올림인 7에 시작 및 끝 토큰을 더한 9로 정한다."
      ],
      "metadata": {
        "id": "FgyovfcCVkwN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "MAX_LENGTH = 9"
      ],
      "metadata": {
        "id": "Ty7kgMBNYffp"
      },
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 정수 인코딩, 최대 길이를 초과하는 샘플 제거, 패딩\n",
        "def tokenize_and_filter(inputs, outputs):\n",
        "  tokenized_inputs, tokenized_outputs = [], []\n",
        "  \n",
        "  for (sentence1, sentence2) in zip(inputs, outputs):\n",
        "    # 정수 인코딩 과정에서 시작 토큰과 종료 토큰을 추가\n",
        "    sentence1 = START_TOKEN + tokenizer.encode(sentence1) + END_TOKEN\n",
        "    sentence2 = START_TOKEN + tokenizer.encode(sentence2) + END_TOKEN\n",
        "\n",
        "    # 최대 길이 9 이하인 경우에만 데이터셋으로 허용\n",
        "    if len(sentence1) <= MAX_LENGTH and len(sentence2) <= MAX_LENGTH:\n",
        "      tokenized_inputs.append(sentence1)\n",
        "      tokenized_outputs.append(sentence2)\n",
        "  \n",
        "  # 최대 길이 9로 모든 데이터셋을 패딩\n",
        "  tokenized_inputs = tf.keras.preprocessing.sequence.pad_sequences(\n",
        "      tokenized_inputs, maxlen=MAX_LENGTH, padding='post')\n",
        "  tokenized_outputs = tf.keras.preprocessing.sequence.pad_sequences(\n",
        "      tokenized_outputs, maxlen=MAX_LENGTH, padding='post')\n",
        "  \n",
        "  return tokenized_inputs, tokenized_outputs"
      ],
      "metadata": {
        "id": "kolADkzGYovq"
      },
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "questions, answers = tokenize_and_filter(questions, answers)\n",
        "print('단어장의 크기 :',(VOCAB_SIZE))\n",
        "print('필터링 후의 질문 샘플 개수: {}'.format(len(questions)))\n",
        "print('필터링 후의 답변 샘플 개수: {}'.format(len(answers)))"
      ],
      "metadata": {
        "id": "iwiCUwDMYtM8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "88075c4e-8db9-459f-c345-e76123122f11"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "단어장의 크기 : 10079\n",
            "필터링 후의 질문 샘플 개수: 8405\n",
            "필터링 후의 답변 샘플 개수: 8405\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3.4. 교사강요 적용하기"
      ],
      "metadata": {
        "id": "fwEJs1cqYu04"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "BATCH_SIZE = 32\n",
        "BUFFER_SIZE = 8405\n",
        "\n",
        "# 디코더는 이전의 target을 다음의 input으로 사용합니다.\n",
        "# 이에 따라 outputs에서는 START_TOKEN을 제거하겠습니다.\n",
        "dataset = tf.data.Dataset.from_tensor_slices((\n",
        "    {\n",
        "        'inputs': questions,\n",
        "        'dec_inputs': answers[:, :-1]\n",
        "    },\n",
        "    {\n",
        "        'outputs': answers[:, 1:]\n",
        "    },\n",
        "))\n",
        "\n",
        "dataset = dataset.cache()\n",
        "dataset = dataset.shuffle(BUFFER_SIZE)\n",
        "dataset = dataset.batch(BATCH_SIZE)\n",
        "dataset = dataset.prefetch(tf.data.experimental.AUTOTUNE)"
      ],
      "metadata": {
        "id": "WELg0TxpZjMe"
      },
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4. 모델 구성"
      ],
      "metadata": {
        "id": "cLpaizc5akG3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4.1. 트랜스포머 부품(?)준비"
      ],
      "metadata": {
        "id": "LDeFggSpbH-W"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- 포지셔널 인코딩 클래스 생성"
      ],
      "metadata": {
        "id": "NTSyFOSfgmUe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 포지셔널 인코딩 레이어\n",
        "class PositionalEncoding(tf.keras.layers.Layer):\n",
        "\n",
        "  def __init__(self, position, d_model):\n",
        "    super(PositionalEncoding, self).__init__()\n",
        "    self.pos_encoding = self.positional_encoding(position, d_model)\n",
        "\n",
        "  def get_angles(self, position, i, d_model):\n",
        "    angles = 1 / tf.pow(10000, (2 * (i // 2)) / tf.cast(d_model, tf.float32))\n",
        "    return position * angles\n",
        "\n",
        "  def positional_encoding(self, position, d_model):\n",
        "    # 각도 배열 생성\n",
        "    angle_rads = self.get_angles(\n",
        "        position=tf.range(position, dtype=tf.float32)[:, tf.newaxis],\n",
        "        i=tf.range(d_model, dtype=tf.float32)[tf.newaxis, :],\n",
        "        d_model=d_model)\n",
        "\n",
        "    # 배열의 짝수 인덱스에는 sin 함수 적용\n",
        "    sines = tf.math.sin(angle_rads[:, 0::2])\n",
        "    # 배열의 홀수 인덱스에는 cosine 함수 적용\n",
        "    cosines = tf.math.cos(angle_rads[:, 1::2])\n",
        "\n",
        "    # sin과 cosine이 교차되도록 재배열\n",
        "    pos_encoding = tf.stack([sines, cosines], axis=0)\n",
        "    pos_encoding = tf.transpose(pos_encoding,[1, 2, 0]) \n",
        "    pos_encoding = tf.reshape(pos_encoding, [position, d_model])\n",
        "\n",
        "    pos_encoding = pos_encoding[tf.newaxis, ...]\n",
        "    return tf.cast(pos_encoding, tf.float32)\n",
        "\n",
        "  def call(self, inputs):\n",
        "    return inputs + self.pos_encoding[:, :tf.shape(inputs)[1], :]"
      ],
      "metadata": {
        "id": "Sdr3Z_fkgpI6"
      },
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "PwiIJJiAgpqy"
      },
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- 어텐션"
      ],
      "metadata": {
        "id": "GTaoyUWVcNX5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 스케일드 닷 프로덕트 어텐션 함수\n",
        "def scaled_dot_product_attention(query, key, value, mask):\n",
        "  # 어텐션 가중치는 Q와 K의 닷 프로덕트\n",
        "  matmul_qk = tf.matmul(query, key, transpose_b=True)\n",
        "\n",
        "  # 가중치를 정규화\n",
        "  depth = tf.cast(tf.shape(key)[-1], tf.float32)\n",
        "  logits = matmul_qk / tf.math.sqrt(depth)\n",
        "\n",
        "  # 패딩에 마스크 추가\n",
        "  if mask is not None:\n",
        "    logits += (mask * -1e9)\n",
        "\n",
        "  # softmax적용\n",
        "  attention_weights = tf.nn.softmax(logits, axis=-1)\n",
        "\n",
        "  # 최종 어텐션은 가중치와 V의 닷 프로덕트\n",
        "  output = tf.matmul(attention_weights, value)\n",
        "  return output"
      ],
      "metadata": {
        "id": "0ScQSQYFcMdt"
      },
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class MultiHeadAttention(tf.keras.layers.Layer):\n",
        "\n",
        "  def __init__(self, d_model, num_heads, name=\"multi_head_attention\"):\n",
        "    super(MultiHeadAttention, self).__init__(name=name)\n",
        "    self.num_heads = num_heads\n",
        "    self.d_model = d_model\n",
        "\n",
        "    assert d_model % self.num_heads == 0\n",
        "\n",
        "    self.depth = d_model // self.num_heads\n",
        "\n",
        "    self.query_dense = tf.keras.layers.Dense(units=d_model)\n",
        "    self.key_dense = tf.keras.layers.Dense(units=d_model)\n",
        "    self.value_dense = tf.keras.layers.Dense(units=d_model)\n",
        "\n",
        "    self.dense = tf.keras.layers.Dense(units=d_model)\n",
        "\n",
        "  def split_heads(self, inputs, batch_size):\n",
        "    inputs = tf.reshape(\n",
        "        inputs, shape=(batch_size, -1, self.num_heads, self.depth))\n",
        "    return tf.transpose(inputs, perm=[0, 2, 1, 3])\n",
        "\n",
        "  def call(self, inputs):\n",
        "    query, key, value, mask = inputs['query'], inputs['key'], inputs[\n",
        "        'value'], inputs['mask']\n",
        "    batch_size = tf.shape(query)[0]\n",
        "\n",
        "    # Q, K, V에 각각 Dense를 적용합니다\n",
        "    query = self.query_dense(query)\n",
        "    key = self.key_dense(key)\n",
        "    value = self.value_dense(value)\n",
        "\n",
        "    # 병렬 연산을 위한 머리를 여러 개 만듭니다\n",
        "    query = self.split_heads(query, batch_size)\n",
        "    key = self.split_heads(key, batch_size)\n",
        "    value = self.split_heads(value, batch_size)\n",
        "\n",
        "    # 스케일드 닷 프로덕트 어텐션 함수\n",
        "    scaled_attention = scaled_dot_product_attention(query, key, value, mask)\n",
        "\n",
        "    scaled_attention = tf.transpose(scaled_attention, perm=[0, 2, 1, 3])\n",
        "\n",
        "    # 어텐션 연산 후에 각 결과를 다시 연결(concatenate)합니다\n",
        "    concat_attention = tf.reshape(scaled_attention,\n",
        "                                  (batch_size, -1, self.d_model))\n",
        "\n",
        "    # 최종 결과에도 Dense를 한 번 더 적용합니다\n",
        "    outputs = self.dense(concat_attention)\n",
        "\n",
        "    return outputs"
      ],
      "metadata": {
        "id": "GbUno3MJcQV9"
      },
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- 마스킹"
      ],
      "metadata": {
        "id": "ov8xCVn7cO_t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 패딩 마스킹\n",
        "def create_padding_mask(x):\n",
        "  mask = tf.cast(tf.math.equal(x, 0), tf.float32)\n",
        "  # (batch_size, 1, 1, sequence length)\n",
        "  return mask[:, tf.newaxis, tf.newaxis, :]"
      ],
      "metadata": {
        "id": "ZmJHrd0-cTR0"
      },
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 패딩 마스킹 in 트랜스포머\n",
        "def create_look_ahead_mask(x):\n",
        "  seq_len = tf.shape(x)[1]\n",
        "  look_ahead_mask = 1 - tf.linalg.band_part(tf.ones((seq_len, seq_len)), -1, 0)\n",
        "  padding_mask = create_padding_mask(x)\n",
        "  return tf.maximum(look_ahead_mask, padding_mask)"
      ],
      "metadata": {
        "id": "Vdt9xqancV1e"
      },
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- 인코더 / 디코더"
      ],
      "metadata": {
        "id": "NNFG9VCgcXIu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 인코더 하나의 레이어를 함수로 구현.\n",
        "# 이 하나의 레이어 안에는 두 개의 서브 레이어가 존재합니다.\n",
        "def encoder_layer(units, d_model, num_heads, dropout, name=\"encoder_layer\"):\n",
        "  inputs = tf.keras.Input(shape=(None, d_model), name=\"inputs\")\n",
        "\n",
        "  # 패딩 마스크 사용\n",
        "  padding_mask = tf.keras.Input(shape=(1, 1, None), name=\"padding_mask\")\n",
        "\n",
        "  # 첫 번째 서브 레이어 : 멀티 헤드 어텐션 수행 (셀프 어텐션)\n",
        "  attention = MultiHeadAttention(\n",
        "      d_model, num_heads, name=\"attention\")({\n",
        "          'query': inputs,\n",
        "          'key': inputs,\n",
        "          'value': inputs,\n",
        "          'mask': padding_mask\n",
        "      })\n",
        "\n",
        "  # 어텐션의 결과는 Dropout과 Layer Normalization이라는 훈련을 돕는 테크닉을 수행\n",
        "  attention = tf.keras.layers.Dropout(rate=dropout)(attention)\n",
        "  attention = tf.keras.layers.LayerNormalization(\n",
        "      epsilon=1e-6)(inputs + attention)\n",
        "\n",
        "  # 두 번째 서브 레이어 : 2개의 완전연결층\n",
        "  outputs = tf.keras.layers.Dense(units=units, activation='relu')(attention)\n",
        "  outputs = tf.keras.layers.Dense(units=d_model)(outputs)\n",
        "\n",
        "  # 완전연결층의 결과는 Dropout과 LayerNormalization이라는 훈련을 돕는 테크닉을 수행\n",
        "  outputs = tf.keras.layers.Dropout(rate=dropout)(outputs)\n",
        "  outputs = tf.keras.layers.LayerNormalization(\n",
        "      epsilon=1e-6)(attention + outputs)\n",
        "\n",
        "  return tf.keras.Model(\n",
        "      inputs=[inputs, padding_mask], outputs=outputs, name=name)"
      ],
      "metadata": {
        "id": "8IQd0QGbca8k"
      },
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def encoder(vocab_size,\n",
        "            num_layers,\n",
        "            units,\n",
        "            d_model,\n",
        "            num_heads,\n",
        "            dropout,\n",
        "            name=\"encoder\"):\n",
        "  inputs = tf.keras.Input(shape=(None,), name=\"inputs\")\n",
        "\n",
        "  # 패딩 마스크 사용\n",
        "  padding_mask = tf.keras.Input(shape=(1, 1, None), name=\"padding_mask\")\n",
        "\n",
        "  # 임베딩 레이어\n",
        "  embeddings = tf.keras.layers.Embedding(vocab_size, d_model)(inputs)\n",
        "  embeddings *= tf.math.sqrt(tf.cast(d_model, tf.float32))\n",
        "\n",
        "  # 포지셔널 인코딩\n",
        "  embeddings = PositionalEncoding(vocab_size, d_model)(embeddings)\n",
        "\n",
        "  outputs = tf.keras.layers.Dropout(rate=dropout)(embeddings)\n",
        "\n",
        "  # num_layers만큼 쌓아올린 인코더의 층.\n",
        "  for i in range(num_layers):\n",
        "    outputs = encoder_layer(\n",
        "        units=units,\n",
        "        d_model=d_model,\n",
        "        num_heads=num_heads,\n",
        "        dropout=dropout,\n",
        "        name=\"encoder_layer_{}\".format(i),\n",
        "    )([outputs, padding_mask])\n",
        "\n",
        "  return tf.keras.Model(\n",
        "      inputs=[inputs, padding_mask], outputs=outputs, name=name)"
      ],
      "metadata": {
        "id": "KUhPvhogce7Z"
      },
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 디코더 하나의 레이어를 함수로 구현.\n",
        "# 이 하나의 레이어 안에는 세 개의 서브 레이어가 존재합니다.\n",
        "def decoder_layer(units, d_model, num_heads, dropout, name=\"decoder_layer\"):\n",
        "  inputs = tf.keras.Input(shape=(None, d_model), name=\"inputs\")\n",
        "  enc_outputs = tf.keras.Input(shape=(None, d_model), name=\"encoder_outputs\")\n",
        "  look_ahead_mask = tf.keras.Input(\n",
        "      shape=(1, None, None), name=\"look_ahead_mask\")\n",
        "  padding_mask = tf.keras.Input(shape=(1, 1, None), name='padding_mask')\n",
        "\n",
        "  # 첫 번째 서브 레이어 : 멀티 헤드 어텐션 수행 (셀프 어텐션)\n",
        "  attention1 = MultiHeadAttention(\n",
        "      d_model, num_heads, name=\"attention_1\")(inputs={\n",
        "          'query': inputs,\n",
        "          'key': inputs,\n",
        "          'value': inputs,\n",
        "          'mask': look_ahead_mask\n",
        "      })\n",
        "\n",
        "  # 멀티 헤드 어텐션의 결과는 LayerNormalization이라는 훈련을 돕는 테크닉을 수행\n",
        "  attention1 = tf.keras.layers.LayerNormalization(\n",
        "      epsilon=1e-6)(attention1 + inputs)\n",
        "\n",
        "  # 두 번째 서브 레이어 : 마스크드 멀티 헤드 어텐션 수행 (인코더-디코더 어텐션)\n",
        "  attention2 = MultiHeadAttention(\n",
        "      d_model, num_heads, name=\"attention_2\")(inputs={\n",
        "          'query': attention1,\n",
        "          'key': enc_outputs,\n",
        "          'value': enc_outputs,\n",
        "          'mask': padding_mask\n",
        "      })\n",
        "\n",
        "  # 마스크드 멀티 헤드 어텐션의 결과는\n",
        "  # Dropout과 LayerNormalization이라는 훈련을 돕는 테크닉을 수행\n",
        "  attention2 = tf.keras.layers.Dropout(rate=dropout)(attention2)\n",
        "  attention2 = tf.keras.layers.LayerNormalization(\n",
        "      epsilon=1e-6)(attention2 + attention1)\n",
        "\n",
        "  # 세 번째 서브 레이어 : 2개의 완전연결층\n",
        "  outputs = tf.keras.layers.Dense(units=units, activation='relu')(attention2)\n",
        "  outputs = tf.keras.layers.Dense(units=d_model)(outputs)\n",
        "\n",
        "  # 완전연결층의 결과는 Dropout과 LayerNormalization 수행\n",
        "  outputs = tf.keras.layers.Dropout(rate=dropout)(outputs)\n",
        "  outputs = tf.keras.layers.LayerNormalization(\n",
        "      epsilon=1e-6)(outputs + attention2)\n",
        "\n",
        "  return tf.keras.Model(\n",
        "      inputs=[inputs, enc_outputs, look_ahead_mask, padding_mask],\n",
        "      outputs=outputs,\n",
        "      name=name)"
      ],
      "metadata": {
        "id": "kNc5W7efchmr"
      },
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def decoder(vocab_size,\n",
        "            num_layers,\n",
        "            units,\n",
        "            d_model,\n",
        "            num_heads,\n",
        "            dropout,\n",
        "            name='decoder'):\n",
        "  inputs = tf.keras.Input(shape=(None,), name='inputs')\n",
        "  enc_outputs = tf.keras.Input(shape=(None, d_model), name='encoder_outputs')\n",
        "  look_ahead_mask = tf.keras.Input(\n",
        "      shape=(1, None, None), name='look_ahead_mask')\n",
        "\n",
        "  # 패딩 마스크\n",
        "  padding_mask = tf.keras.Input(shape=(1, 1, None), name='padding_mask')\n",
        "  \n",
        "  # 임베딩 레이어\n",
        "  embeddings = tf.keras.layers.Embedding(vocab_size, d_model)(inputs)\n",
        "  embeddings *= tf.math.sqrt(tf.cast(d_model, tf.float32))\n",
        "\n",
        "  # 포지셔널 인코딩\n",
        "  embeddings = PositionalEncoding(vocab_size, d_model)(embeddings)\n",
        "\n",
        "  # Dropout이라는 훈련을 돕는 테크닉을 수행\n",
        "  outputs = tf.keras.layers.Dropout(rate=dropout)(embeddings)\n",
        "\n",
        "  for i in range(num_layers):\n",
        "    outputs = decoder_layer(\n",
        "        units=units,\n",
        "        d_model=d_model,\n",
        "        num_heads=num_heads,\n",
        "        dropout=dropout,\n",
        "        name='decoder_layer_{}'.format(i),\n",
        "    )(inputs=[outputs, enc_outputs, look_ahead_mask, padding_mask])\n",
        "\n",
        "  return tf.keras.Model(\n",
        "      inputs=[inputs, enc_outputs, look_ahead_mask, padding_mask],\n",
        "      outputs=outputs,\n",
        "      name=name)"
      ],
      "metadata": {
        "id": "lYOuhKqJciLk"
      },
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4.2. 트랜스포머 모델 조립(?)"
      ],
      "metadata": {
        "id": "tNzIf_m7ckV7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def transformer(vocab_size,\n",
        "                num_layers,\n",
        "                units,\n",
        "                d_model,\n",
        "                num_heads,\n",
        "                dropout,\n",
        "                name=\"transformer\"):\n",
        "  inputs = tf.keras.Input(shape=(None,), name=\"inputs\")\n",
        "  dec_inputs = tf.keras.Input(shape=(None,), name=\"dec_inputs\")\n",
        "\n",
        "  # 인코더에서 패딩을 위한 마스크\n",
        "  enc_padding_mask = tf.keras.layers.Lambda(\n",
        "      create_padding_mask, output_shape=(1, 1, None),\n",
        "      name='enc_padding_mask')(inputs)\n",
        "\n",
        "  # 디코더에서 미래의 토큰을 마스크 하기 위해서 사용합니다.\n",
        "  # 내부적으로 패딩 마스크도 포함되어져 있습니다.\n",
        "  look_ahead_mask = tf.keras.layers.Lambda(\n",
        "      create_look_ahead_mask,\n",
        "      output_shape=(1, None, None),\n",
        "      name='look_ahead_mask')(dec_inputs)\n",
        "\n",
        "  # 두 번째 어텐션 블록에서 인코더의 벡터들을 마스킹\n",
        "  # 디코더에서 패딩을 위한 마스크\n",
        "  dec_padding_mask = tf.keras.layers.Lambda(\n",
        "      create_padding_mask, output_shape=(1, 1, None),\n",
        "      name='dec_padding_mask')(inputs)\n",
        "\n",
        "  # 인코더\n",
        "  enc_outputs = encoder(\n",
        "      vocab_size=vocab_size,\n",
        "      num_layers=num_layers,\n",
        "      units=units,\n",
        "      d_model=d_model,\n",
        "      num_heads=num_heads,\n",
        "      dropout=dropout,\n",
        "  )(inputs=[inputs, enc_padding_mask])\n",
        "\n",
        "  # 디코더\n",
        "  dec_outputs = decoder(\n",
        "      vocab_size=vocab_size,\n",
        "      num_layers=num_layers,\n",
        "      units=units,\n",
        "      d_model=d_model,\n",
        "      num_heads=num_heads,\n",
        "      dropout=dropout,\n",
        "  )(inputs=[dec_inputs, enc_outputs, look_ahead_mask, dec_padding_mask])\n",
        "\n",
        "  # 완전연결층\n",
        "  outputs = tf.keras.layers.Dense(units=vocab_size, name=\"outputs\")(dec_outputs)\n",
        "\n",
        "  return tf.keras.Model(inputs=[inputs, dec_inputs], outputs=outputs, name=name)\n"
      ],
      "metadata": {
        "id": "QvlE1KNzbReZ"
      },
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5. 학습 및 평가"
      ],
      "metadata": {
        "id": "w_--yTGFctb5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 5.1. 모델 정의"
      ],
      "metadata": {
        "id": "NhB33tE8bRvv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 5.1.1. 하이퍼파라미터 설정"
      ],
      "metadata": {
        "id": "NY8UHmMcc9CA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tf.keras.backend.clear_session()\n",
        "\n",
        "# 하이퍼파라미터\n",
        "NUM_LAYERS = 2 # 인코더와 디코더의 층의 개수\n",
        "D_MODEL = 256 # 인코더와 디코더 내부의 입, 출력의 고정 차원\n",
        "NUM_HEADS = 8 # 멀티 헤드 어텐션에서의 헤드 수 \n",
        "UNITS = 512 # 피드 포워드 신경망의 은닉층의 크기\n",
        "DROPOUT = 0.1 # 드롭아웃의 비율\n",
        "\n",
        "model = transformer(\n",
        "    vocab_size=VOCAB_SIZE,\n",
        "    num_layers=NUM_LAYERS,\n",
        "    units=UNITS,\n",
        "    d_model=D_MODEL,\n",
        "    num_heads=NUM_HEADS,\n",
        "    dropout=DROPOUT)\n",
        "\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "kNwWP9VPbZuM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0f4c2433-620b-4fca-9f5c-9b8734cbbd85"
      },
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"transformer\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " inputs (InputLayer)            [(None, None)]       0           []                               \n",
            "                                                                                                  \n",
            " dec_inputs (InputLayer)        [(None, None)]       0           []                               \n",
            "                                                                                                  \n",
            " enc_padding_mask (Lambda)      (None, 1, 1, None)   0           ['inputs[0][0]']                 \n",
            "                                                                                                  \n",
            " encoder (Functional)           (None, None, 256)    3634432     ['inputs[0][0]',                 \n",
            "                                                                  'enc_padding_mask[0][0]']       \n",
            "                                                                                                  \n",
            " look_ahead_mask (Lambda)       (None, 1, None, Non  0           ['dec_inputs[0][0]']             \n",
            "                                e)                                                                \n",
            "                                                                                                  \n",
            " dec_padding_mask (Lambda)      (None, 1, 1, None)   0           ['inputs[0][0]']                 \n",
            "                                                                                                  \n",
            " decoder (Functional)           (None, None, 256)    4161792     ['dec_inputs[0][0]',             \n",
            "                                                                  'encoder[0][0]',                \n",
            "                                                                  'look_ahead_mask[0][0]',        \n",
            "                                                                  'dec_padding_mask[0][0]']       \n",
            "                                                                                                  \n",
            " outputs (Dense)                (None, None, 10079)  2590303     ['decoder[0][0]']                \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 10,386,527\n",
            "Trainable params: 10,386,527\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 5.1.2. 손실함수 지정"
      ],
      "metadata": {
        "id": "RZ24gsIvbZ-7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def loss_function(y_true, y_pred):\n",
        "  y_true = tf.reshape(y_true, shape=(-1, MAX_LENGTH - 1))\n",
        "  \n",
        "  loss = tf.keras.losses.SparseCategoricalCrossentropy(\n",
        "      from_logits=True, reduction='none')(y_true, y_pred)\n",
        "\n",
        "  mask = tf.cast(tf.not_equal(y_true, 0), tf.float32)\n",
        "  loss = tf.multiply(loss, mask)\n",
        "\n",
        "  return tf.reduce_mean(loss)"
      ],
      "metadata": {
        "id": "wpxvJ_Yu2EyK"
      },
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 5.1.3. 학습률 설정"
      ],
      "metadata": {
        "id": "bBgj3dwj2UWD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class CustomSchedule(tf.keras.optimizers.schedules.LearningRateSchedule):\n",
        "\n",
        "  def __init__(self, d_model, warmup_steps=4000):\n",
        "    super(CustomSchedule, self).__init__()\n",
        "\n",
        "    self.d_model = d_model\n",
        "    self.d_model = tf.cast(self.d_model, tf.float32)\n",
        "\n",
        "    self.warmup_steps = warmup_steps\n",
        "\n",
        "  def __call__(self, step):\n",
        "    arg1 = tf.math.rsqrt(step)\n",
        "    arg2 = step * (self.warmup_steps**-1.5)\n",
        "\n",
        "    return tf.math.rsqrt(self.d_model) * tf.math.minimum(arg1, arg2)"
      ],
      "metadata": {
        "id": "dynjdGYm2ZfV"
      },
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sample_learning_rate = CustomSchedule(d_model=128)\n",
        "\n",
        "plt.plot(sample_learning_rate(tf.range(200000, dtype=tf.float32)))\n",
        "plt.ylabel(\"Learning Rate\")\n",
        "plt.xlabel(\"Train Step\")"
      ],
      "metadata": {
        "id": "M3PmEdHP2aeg",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        },
        "outputId": "184b5b8c-438f-466c-f6db-1ee8f1877000"
      },
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0.5, 0, 'Train Step')"
            ]
          },
          "metadata": {},
          "execution_count": 71
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 5.1.4. 컴파일"
      ],
      "metadata": {
        "id": "S3wNnKRA2d46"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "learning_rate = CustomSchedule(D_MODEL)\n",
        "\n",
        "optimizer = tf.keras.optimizers.Adam(\n",
        "    learning_rate, beta_1=0.9, beta_2=0.98, epsilon=1e-9)\n",
        "\n",
        "def accuracy(y_true, y_pred):\n",
        "  y_true = tf.reshape(y_true, shape=(-1, MAX_LENGTH - 1))\n",
        "  return tf.keras.metrics.sparse_categorical_accuracy(y_true, y_pred)\n",
        "\n",
        "model.compile(optimizer=optimizer, loss=loss_function, metrics=[accuracy])"
      ],
      "metadata": {
        "id": "_NdObQOK2ixy"
      },
      "execution_count": 72,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 5.2. 학습(기본 설정)"
      ],
      "metadata": {
        "id": "UsKn7TBA2jeR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "EPOCHS = 20\n",
        "model.fit(dataset, epochs=EPOCHS, verbose=1)"
      ],
      "metadata": {
        "id": "VhzIvioV2tzm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c640a214-1cc6-424e-c575-5fc877257715"
      },
      "execution_count": 106,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "263/263 [==============================] - 6s 21ms/step - loss: 0.1411 - accuracy: 0.6743\n",
            "Epoch 2/20\n",
            "263/263 [==============================] - 6s 21ms/step - loss: 0.1294 - accuracy: 0.6769\n",
            "Epoch 3/20\n",
            "263/263 [==============================] - 6s 21ms/step - loss: 0.1155 - accuracy: 0.6811\n",
            "Epoch 4/20\n",
            "263/263 [==============================] - 6s 22ms/step - loss: 0.1055 - accuracy: 0.6829\n",
            "Epoch 5/20\n",
            "263/263 [==============================] - 6s 21ms/step - loss: 0.0956 - accuracy: 0.6855\n",
            "Epoch 6/20\n",
            "263/263 [==============================] - 6s 21ms/step - loss: 0.0848 - accuracy: 0.6877\n",
            "Epoch 7/20\n",
            "263/263 [==============================] - 6s 21ms/step - loss: 0.0806 - accuracy: 0.6889\n",
            "Epoch 8/20\n",
            "263/263 [==============================] - 10s 39ms/step - loss: 0.0746 - accuracy: 0.6909\n",
            "Epoch 9/20\n",
            "263/263 [==============================] - 6s 21ms/step - loss: 0.0699 - accuracy: 0.6915\n",
            "Epoch 10/20\n",
            "263/263 [==============================] - 8s 32ms/step - loss: 0.0687 - accuracy: 0.6919\n",
            "Epoch 11/20\n",
            "263/263 [==============================] - 6s 24ms/step - loss: 0.0594 - accuracy: 0.6943\n",
            "Epoch 12/20\n",
            "263/263 [==============================] - 6s 21ms/step - loss: 0.0609 - accuracy: 0.6943\n",
            "Epoch 13/20\n",
            "263/263 [==============================] - 6s 21ms/step - loss: 0.0533 - accuracy: 0.6960\n",
            "Epoch 14/20\n",
            "263/263 [==============================] - 6s 21ms/step - loss: 0.0532 - accuracy: 0.6960\n",
            "Epoch 15/20\n",
            "263/263 [==============================] - 6s 21ms/step - loss: 0.0482 - accuracy: 0.6972\n",
            "Epoch 16/20\n",
            "263/263 [==============================] - 6s 21ms/step - loss: 0.0469 - accuracy: 0.6976\n",
            "Epoch 17/20\n",
            "263/263 [==============================] - 6s 21ms/step - loss: 0.0451 - accuracy: 0.6976\n",
            "Epoch 18/20\n",
            "263/263 [==============================] - 6s 21ms/step - loss: 0.0418 - accuracy: 0.6986\n",
            "Epoch 19/20\n",
            "263/263 [==============================] - 6s 21ms/step - loss: 0.0417 - accuracy: 0.6985\n",
            "Epoch 20/20\n",
            "263/263 [==============================] - 6s 21ms/step - loss: 0.0403 - accuracy: 0.6991\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7ff7cb6d8250>"
            ]
          },
          "metadata": {},
          "execution_count": 106
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 5.3. 모델 실행"
      ],
      "metadata": {
        "id": "L4Cc2RXi25QF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def decoder_inference(sentence):\n",
        "  sentence = preprocess_sentence(sentence)\n",
        "\n",
        "  # 입력된 문장을 정수 인코딩 후, 시작 토큰과 종료 토큰을 앞뒤로 추가.\n",
        "  # ex) Where have you been? → [[8331   86   30    5 1059    7 8332]]\n",
        "  sentence = tf.expand_dims(\n",
        "      START_TOKEN + tokenizer.encode(sentence) + END_TOKEN, axis=0)\n",
        "\n",
        "  # 디코더의 현재까지의 예측한 출력 시퀀스가 지속적으로 저장되는 변수.\n",
        "  # 처음에는 예측한 내용이 없음으로 시작 토큰만 별도 저장. ex) 8331\n",
        "  output_sequence = tf.expand_dims(START_TOKEN, 0)\n",
        "\n",
        "  # 디코더의 인퍼런스 단계\n",
        "  for i in range(MAX_LENGTH):\n",
        "    # 디코더는 최대 MAX_LENGTH의 길이만큼 다음 단어 예측을 반복합니다.\n",
        "    predictions = model(inputs=[sentence, output_sequence], training=False)\n",
        "    predictions = predictions[:, -1:, :]\n",
        "\n",
        "    # 현재 예측한 단어의 정수\n",
        "    predicted_id = tf.cast(tf.argmax(predictions, axis=-1), tf.int32)\n",
        "\n",
        "    # 만약 현재 예측한 단어가 종료 토큰이라면 for문을 종료\n",
        "    if tf.equal(predicted_id, END_TOKEN[0]):\n",
        "      break\n",
        "                                                                                                                                                                                        \n",
        "    # 예측한 단어들은 지속적으로 output_sequence에 추가됩니다.\n",
        "    # 이 output_sequence는 다시 디코더의 입력이 됩니다.\n",
        "    output_sequence = tf.concat([output_sequence, predicted_id], axis=-1)\n",
        "\n",
        "  return tf.squeeze(output_sequence, axis=0)"
      ],
      "metadata": {
        "id": "cwfHr_fM2udm"
      },
      "execution_count": 76,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def sentence_generation(sentence):\n",
        "  # 입력 문장에 대해서 디코더를 동작 시켜 예측된 정수 시퀀스를 리턴받습니다.\n",
        "  prediction = decoder_inference(sentence)\n",
        "\n",
        "  # 정수 시퀀스를 다시 텍스트 시퀀스로 변환합니다.\n",
        "  predicted_sentence = tokenizer.decode(\n",
        "      [i for i in prediction if i < tokenizer.vocab_size])\n",
        "\n",
        "  print('입력 : {}'.format(sentence))\n",
        "  print('출력 : {}'.format(predicted_sentence))\n",
        "\n",
        "  return predicted_sentence"
      ],
      "metadata": {
        "id": "zvlNLWOA2-dm"
      },
      "execution_count": 77,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sentence_generation('요즘 컨디션이 별로야')"
      ],
      "metadata": {
        "id": "rcZxGlWl2-rD",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        },
        "outputId": "7e7886d5-319a-4c8a-98c8-d207571e1799"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "입력 : 요즘 컨디션이 별로야\n",
            "출력 : 아무래도 그렇겠죠 . \n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'아무래도 그렇겠죠 . '"
            ]
          },
          "metadata": {},
          "execution_count": 661
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sentence_generation('어떻게 생각할까?')"
      ],
      "metadata": {
        "id": "2Yp0wuGJHU1u",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        },
        "outputId": "ecdac07d-4ca8-4f16-d8bc-1a20dda08bed"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "입력 : 어떻게 생각할까?\n",
            "출력 : 글쎄요 . \n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'글쎄요 . '"
            ]
          },
          "metadata": {},
          "execution_count": 662
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sentence_generation('오늘 너무 피곤하다')"
      ],
      "metadata": {
        "id": "8lNhJoEaH3N7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        },
        "outputId": "18605d8a-5270-4451-a015-0e2ea21fff92"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "입력 : 오늘 너무 피곤하다\n",
            "출력 : 그땐 그게 맞다고 생각했으니까요 . \n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'그땐 그게 맞다고 생각했으니까요 . '"
            ]
          },
          "metadata": {},
          "execution_count": 663
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 5.4. 평가\n",
        "\n",
        ": \n",
        "- 문장의 형태는 그럴듯 하나 동문서답이다"
      ],
      "metadata": {
        "id": "qX-c7ySUCc62"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 6. 모델 성능 개선\n",
        "\n",
        "공통사항\n",
        "- batch size = 32\n",
        "- 손실함수, 학습률, 컴파일 실습과 동일\n",
        "\n",
        "\n",
        "비고\n",
        "- 배치사이즈 :\n",
        "\n",
        "    따로 기록을 남기지 않았으나, 멀티 헤드를 비교하는 첫 번째 구간에서 크기를 몇 번 변경해 보았으나 거의 영향이 없었다."
      ],
      "metadata": {
        "id": "FRSCfBKZ8w1C"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 6.1. 재실행 구간\n",
        "\n",
        "백엔드 클리어 세션이라는 함수를 사용하여 비교 검증을 위해 특별히 지속적으로 재실행해야 할 부분은 없는 것 같다.\n",
        "\n"
      ],
      "metadata": {
        "id": "L6hZcjrnDo-3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 6.2. 하이퍼파라미터 수정 - NUM_HEAD\n",
        "\n",
        "요약: \n",
        "- 생성된 문장을 기준으로, 넘헤드 갯수가 대단히 큰 영향을 미치지는 않는 것 같다.\n",
        "- 동일 epoch에서 갯수가 많아지면 지표가 조금 더 좋다.\n",
        "- 넘헤드의 갯수를 줄였을 때 생성된 문장이 연속적으로 더 적합했던 케이스가 있어 한동안 반복 실행했으나, 결과적으로 갯수가 줄어드는 것이 긍정적인 영향은 미치지 않는 것으로 보인다.\n",
        "    > 바로 탈락시키지 않고, 다른 지표를 바꾸어 재검증 해 볼 것\n"
      ],
      "metadata": {
        "id": "Pqh8h1-6DrZO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 6.2.1. 멀티 헤드 갯수 늘려보기(1)"
      ],
      "metadata": {
        "id": "t-wiZn2uFBve"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "NUM_HEAD \n",
        "\n",
        ": 8 -> 16\n"
      ],
      "metadata": {
        "id": "0mTO_du_EtZv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tf.keras.backend.clear_session()\n",
        "\n",
        "NUM_LAYERS = 2 # 인코더와 디코더의 층의 개수\n",
        "D_MODEL = 256 # 인코더와 디코더 내부의 입, 출력의 고정 차원\n",
        "NUM_HEADS = 16 # 멀티 헤드 어텐션에서의 헤드 수 \n",
        "UNITS = 512 # 피드 포워드 신경망의 은닉층의 크기\n",
        "DROPOUT = 0.1 # 드롭아웃의 비율\n",
        "\n",
        "model = transformer(\n",
        "    vocab_size=VOCAB_SIZE,\n",
        "    num_layers=NUM_LAYERS,\n",
        "    units=UNITS,\n",
        "    d_model=D_MODEL,\n",
        "    num_heads=NUM_HEADS,\n",
        "    dropout=DROPOUT)\n",
        "\n",
        "model.summary()\n",
        "\n",
        "# 컴파일\n",
        "learning_rate = CustomSchedule(D_MODEL)\n",
        "\n",
        "optimizer = tf.keras.optimizers.Adam(\n",
        "    learning_rate, beta_1=0.9, beta_2=0.98, epsilon=1e-9)\n",
        "\n",
        "def accuracy(y_true, y_pred):\n",
        "  y_true = tf.reshape(y_true, shape=(-1, MAX_LENGTH - 1))\n",
        "  return tf.keras.metrics.sparse_categorical_accuracy(y_true, y_pred)\n",
        "\n",
        "model.compile(optimizer=optimizer, loss=loss_function, metrics=[accuracy])"
      ],
      "metadata": {
        "id": "SddcF5QiGNi9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "69fb9ebf-e2fd-4d00-f224-33bff65c1aa7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"transformer\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " inputs (InputLayer)            [(None, None)]       0           []                               \n",
            "                                                                                                  \n",
            " dec_inputs (InputLayer)        [(None, None)]       0           []                               \n",
            "                                                                                                  \n",
            " enc_padding_mask (Lambda)      (None, 1, 1, None)   0           ['inputs[0][0]']                 \n",
            "                                                                                                  \n",
            " encoder (Functional)           (None, None, 256)    6634240     ['inputs[0][0]',                 \n",
            "                                                                  'enc_padding_mask[0][0]']       \n",
            "                                                                                                  \n",
            " look_ahead_mask (Lambda)       (None, 1, None, Non  0           ['dec_inputs[0][0]']             \n",
            "                                e)                                                                \n",
            "                                                                                                  \n",
            " dec_padding_mask (Lambda)      (None, 1, 1, None)   0           ['inputs[0][0]']                 \n",
            "                                                                                                  \n",
            " decoder (Functional)           (None, None, 256)    7161600     ['dec_inputs[0][0]',             \n",
            "                                                                  'encoder[0][0]',                \n",
            "                                                                  'look_ahead_mask[0][0]',        \n",
            "                                                                  'dec_padding_mask[0][0]']       \n",
            "                                                                                                  \n",
            " outputs (Dense)                (None, None, 21797)  5601829     ['decoder[0][0]']                \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 19,397,669\n",
            "Trainable params: 19,397,669\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- 학습"
      ],
      "metadata": {
        "id": "-Ijctrp0G1dv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "EPOCHS = 20\n",
        "model.fit(dataset, epochs=EPOCHS, verbose=1)"
      ],
      "metadata": {
        "id": "9HUB8zjvIE7I",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5c8467c5-49a9-48f2-d96d-fe1766b13dfa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "328/328 [==============================] - 15s 28ms/step - loss: 5.6748 - accuracy: 0.1804\n",
            "Epoch 2/20\n",
            "328/328 [==============================] - 9s 28ms/step - loss: 3.7526 - accuracy: 0.2426\n",
            "Epoch 3/20\n",
            "328/328 [==============================] - 9s 28ms/step - loss: 3.2922 - accuracy: 0.2538\n",
            "Epoch 4/20\n",
            "328/328 [==============================] - 9s 28ms/step - loss: 3.0116 - accuracy: 0.2688\n",
            "Epoch 5/20\n",
            "328/328 [==============================] - 9s 28ms/step - loss: 2.7187 - accuracy: 0.2929\n",
            "Epoch 6/20\n",
            "328/328 [==============================] - 9s 28ms/step - loss: 2.3872 - accuracy: 0.3284\n",
            "Epoch 7/20\n",
            "328/328 [==============================] - 9s 28ms/step - loss: 2.0342 - accuracy: 0.3705\n",
            "Epoch 8/20\n",
            "328/328 [==============================] - 9s 28ms/step - loss: 1.6852 - accuracy: 0.4099\n",
            "Epoch 9/20\n",
            "328/328 [==============================] - 9s 29ms/step - loss: 1.3481 - accuracy: 0.4470\n",
            "Epoch 10/20\n",
            "328/328 [==============================] - 9s 28ms/step - loss: 1.0602 - accuracy: 0.4819\n",
            "Epoch 11/20\n",
            "328/328 [==============================] - 9s 28ms/step - loss: 0.8269 - accuracy: 0.5137\n",
            "Epoch 12/20\n",
            "328/328 [==============================] - 9s 28ms/step - loss: 0.6460 - accuracy: 0.5417\n",
            "Epoch 13/20\n",
            "328/328 [==============================] - 9s 28ms/step - loss: 0.5220 - accuracy: 0.5618\n",
            "Epoch 14/20\n",
            "328/328 [==============================] - 10s 29ms/step - loss: 0.3891 - accuracy: 0.5855\n",
            "Epoch 15/20\n",
            "328/328 [==============================] - 9s 28ms/step - loss: 0.2971 - accuracy: 0.6035\n",
            "Epoch 16/20\n",
            "328/328 [==============================] - 9s 28ms/step - loss: 0.2408 - accuracy: 0.6153\n",
            "Epoch 17/20\n",
            "328/328 [==============================] - 9s 28ms/step - loss: 0.1993 - accuracy: 0.6242\n",
            "Epoch 18/20\n",
            "328/328 [==============================] - 9s 28ms/step - loss: 0.1705 - accuracy: 0.6303\n",
            "Epoch 19/20\n",
            "328/328 [==============================] - 9s 28ms/step - loss: 0.1505 - accuracy: 0.6348\n",
            "Epoch 20/20\n",
            "328/328 [==============================] - 9s 28ms/step - loss: 0.1425 - accuracy: 0.6378\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7efcdb4cd690>"
            ]
          },
          "metadata": {},
          "execution_count": 665
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sentence_generation('요즘 컨디션이 별로야')"
      ],
      "metadata": {
        "id": "N2Zc8TrOIH_x",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        },
        "outputId": "8e68f87b-9645-4027-b566-b107909c9c99"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "입력 : 요즘 컨디션이 별로야\n",
            "출력 : 믿음이 가장 중요하죠 . \n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'믿음이 가장 중요하죠 . '"
            ]
          },
          "metadata": {},
          "execution_count": 666
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sentence_generation('어떻게 생각할까?')"
      ],
      "metadata": {
        "id": "OtUlZFEsIH_x",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        },
        "outputId": "b5c4e770-71ca-4d8a-8bfd-079f3da1b66d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "입력 : 어떻게 생각할까?\n",
            "출력 : 아직은 잘 모르겠어요 . \n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'아직은 잘 모르겠어요 . '"
            ]
          },
          "metadata": {},
          "execution_count": 667
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sentence_generation('오늘 너무 피곤하다')"
      ],
      "metadata": {
        "id": "Nt2g0wXaIH_x",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        },
        "outputId": "ae3234d7-1b0e-49cf-9a30-8f53cdd4a4b8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "입력 : 오늘 너무 피곤하다\n",
            "출력 : 눈물 더 흘려도 돼요 . \n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'눈물 더 흘려도 돼요 . '"
            ]
          },
          "metadata": {},
          "execution_count": 668
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sentence_generation('안녕하세요'), sentence_generation('반가워요!'), sentence_generation('재밌는 경기입니다.'), sentence_generation('너무 화가나요'), sentence_generation('배고파요'), sentence_generation('지쳤어요'), sentence_generation('공부하기 싫어요'), sentence_generation('저녁은 드셨나요?')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a7f64d64-8986-404a-92e8-1d29345e562b",
        "id": "c8zDif2BsXmp"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "입력 : 안녕하세요\n",
            "출력 : 안녕하세요 . \n",
            "입력 : 반가워요!\n",
            "출력 : 잠시 쉬어도 괜찮아요 . \n",
            "입력 : 재밌는 경기입니다.\n",
            "출력 : 제가 있잖아요 . \n",
            "입력 : 너무 화가나요\n",
            "출력 : 안 좋은일이 있었나봐요 . \n",
            "입력 : 배고파요\n",
            "출력 : 얼른 맛난 음식 드세요 . \n",
            "입력 : 지쳤어요\n",
            "출력 : 아픔을 헤아려도 달라지는 건 없어요 . \n",
            "입력 : 공부하기 싫어요\n",
            "출력 : 모든 일이 뜻대로 되진 않나봐요 . \n",
            "입력 : 저녁은 드셨나요?\n",
            "출력 : 어떤 선택이든 후회가 남기 마련이지요 . \n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('안녕하세요 . ',\n",
              " '잠시 쉬어도 괜찮아요 . ',\n",
              " '제가 있잖아요 . ',\n",
              " '안 좋은일이 있었나봐요 . ',\n",
              " '얼른 맛난 음식 드세요 . ',\n",
              " '아픔을 헤아려도 달라지는 건 없어요 . ',\n",
              " '모든 일이 뜻대로 되진 않나봐요 . ',\n",
              " '어떤 선택이든 후회가 남기 마련이지요 . ')"
            ]
          },
          "metadata": {},
          "execution_count": 669
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- 평가\n",
        "\n",
        "    - 정확도 및 손실값 : 거의 차이 없음\n",
        "    - 문장 구현 : 여전히 동문서답 중\n",
        "\n"
      ],
      "metadata": {
        "id": "gNTRGzabFf2N"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 6.2.2. 멀티 헤드 갯수 늘려보기(2)"
      ],
      "metadata": {
        "id": "PnfZOMsPJkfw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "NUM_HEAD \n",
        "\n",
        ": 16 -> 32\n"
      ],
      "metadata": {
        "id": "nadrtHjIJkf2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tf.keras.backend.clear_session()\n",
        "\n",
        "NUM_LAYERS = 2 # 인코더와 디코더의 층의 개수\n",
        "D_MODEL = 256 # 인코더와 디코더 내부의 입, 출력의 고정 차원\n",
        "NUM_HEADS = 32 # 멀티 헤드 어텐션에서의 헤드 수 \n",
        "UNITS = 512 # 피드 포워드 신경망의 은닉층의 크기\n",
        "DROPOUT = 0.1 # 드롭아웃의 비율\n",
        "\n",
        "model = transformer(\n",
        "    vocab_size=VOCAB_SIZE,\n",
        "    num_layers=NUM_LAYERS,\n",
        "    units=UNITS,\n",
        "    d_model=D_MODEL,\n",
        "    num_heads=NUM_HEADS,\n",
        "    dropout=DROPOUT)\n",
        "\n",
        "model.summary()\n",
        "\n",
        "# 컴파일\n",
        "learning_rate = CustomSchedule(D_MODEL)\n",
        "\n",
        "optimizer = tf.keras.optimizers.Adam(\n",
        "    learning_rate, beta_1=0.9, beta_2=0.98, epsilon=1e-9)\n",
        "\n",
        "def accuracy(y_true, y_pred):\n",
        "  y_true = tf.reshape(y_true, shape=(-1, MAX_LENGTH - 1))\n",
        "  return tf.keras.metrics.sparse_categorical_accuracy(y_true, y_pred)\n",
        "\n",
        "model.compile(optimizer=optimizer, loss=loss_function, metrics=[accuracy])"
      ],
      "metadata": {
        "id": "9IFhs3vYJkf2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "105dfa1d-8bd9-44ae-c534-28cc8dafb879"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"transformer\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " inputs (InputLayer)            [(None, None)]       0           []                               \n",
            "                                                                                                  \n",
            " dec_inputs (InputLayer)        [(None, None)]       0           []                               \n",
            "                                                                                                  \n",
            " enc_padding_mask (Lambda)      (None, 1, 1, None)   0           ['inputs[0][0]']                 \n",
            "                                                                                                  \n",
            " encoder (Functional)           (None, None, 256)    6634240     ['inputs[0][0]',                 \n",
            "                                                                  'enc_padding_mask[0][0]']       \n",
            "                                                                                                  \n",
            " look_ahead_mask (Lambda)       (None, 1, None, Non  0           ['dec_inputs[0][0]']             \n",
            "                                e)                                                                \n",
            "                                                                                                  \n",
            " dec_padding_mask (Lambda)      (None, 1, 1, None)   0           ['inputs[0][0]']                 \n",
            "                                                                                                  \n",
            " decoder (Functional)           (None, None, 256)    7161600     ['dec_inputs[0][0]',             \n",
            "                                                                  'encoder[0][0]',                \n",
            "                                                                  'look_ahead_mask[0][0]',        \n",
            "                                                                  'dec_padding_mask[0][0]']       \n",
            "                                                                                                  \n",
            " outputs (Dense)                (None, None, 21797)  5601829     ['decoder[0][0]']                \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 19,397,669\n",
            "Trainable params: 19,397,669\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- 학습"
      ],
      "metadata": {
        "id": "sY5Vz_GeJkf2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "EPOCHS = 20\n",
        "model.fit(dataset, epochs=EPOCHS, verbose=1)"
      ],
      "metadata": {
        "id": "CDsjHHytJkf2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "78308b38-a4f2-4d1c-93e0-c9abbe917bd4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "328/328 [==============================] - 15s 28ms/step - loss: 5.6745 - accuracy: 0.1863\n",
            "Epoch 2/20\n",
            "328/328 [==============================] - 9s 28ms/step - loss: 3.7505 - accuracy: 0.2423\n",
            "Epoch 3/20\n",
            "328/328 [==============================] - 9s 28ms/step - loss: 3.2896 - accuracy: 0.2535\n",
            "Epoch 4/20\n",
            "328/328 [==============================] - 9s 28ms/step - loss: 3.0147 - accuracy: 0.2684\n",
            "Epoch 5/20\n",
            "328/328 [==============================] - 9s 28ms/step - loss: 2.7227 - accuracy: 0.2917\n",
            "Epoch 6/20\n",
            "328/328 [==============================] - 9s 28ms/step - loss: 2.3921 - accuracy: 0.3272\n",
            "Epoch 7/20\n",
            "328/328 [==============================] - 9s 28ms/step - loss: 2.0384 - accuracy: 0.3692\n",
            "Epoch 8/20\n",
            "328/328 [==============================] - 9s 28ms/step - loss: 1.6920 - accuracy: 0.4098\n",
            "Epoch 9/20\n",
            "328/328 [==============================] - 9s 28ms/step - loss: 1.3612 - accuracy: 0.4458\n",
            "Epoch 10/20\n",
            "328/328 [==============================] - 9s 28ms/step - loss: 1.0753 - accuracy: 0.4808\n",
            "Epoch 11/20\n",
            "328/328 [==============================] - 9s 28ms/step - loss: 0.8389 - accuracy: 0.5129\n",
            "Epoch 12/20\n",
            "328/328 [==============================] - 9s 28ms/step - loss: 0.6564 - accuracy: 0.5402\n",
            "Epoch 13/20\n",
            "328/328 [==============================] - 9s 28ms/step - loss: 0.5134 - accuracy: 0.5639\n",
            "Epoch 14/20\n",
            "328/328 [==============================] - 9s 28ms/step - loss: 0.3919 - accuracy: 0.5851\n",
            "Epoch 15/20\n",
            "328/328 [==============================] - 9s 28ms/step - loss: 0.2980 - accuracy: 0.6030\n",
            "Epoch 16/20\n",
            "328/328 [==============================] - 9s 28ms/step - loss: 0.2378 - accuracy: 0.6159\n",
            "Epoch 17/20\n",
            "328/328 [==============================] - 9s 28ms/step - loss: 0.1933 - accuracy: 0.6257\n",
            "Epoch 18/20\n",
            "328/328 [==============================] - 9s 28ms/step - loss: 0.1662 - accuracy: 0.6321\n",
            "Epoch 19/20\n",
            "328/328 [==============================] - 9s 28ms/step - loss: 0.1501 - accuracy: 0.6352\n",
            "Epoch 20/20\n",
            "328/328 [==============================] - 9s 28ms/step - loss: 0.1351 - accuracy: 0.6394\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7efce15d2a90>"
            ]
          },
          "metadata": {},
          "execution_count": 671
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sentence_generation('요즘 컨디션이 별로야')"
      ],
      "metadata": {
        "id": "zolMWM3iJkf3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        },
        "outputId": "8ef693ca-5579-4090-81e3-c6df8375f33c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "입력 : 요즘 컨디션이 별로야\n",
            "출력 : 인연이 여기까지였나봅니다 . \n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'인연이 여기까지였나봅니다 . '"
            ]
          },
          "metadata": {},
          "execution_count": 672
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sentence_generation('어떻게 생각할까?')"
      ],
      "metadata": {
        "id": "7fo2B26JJkf3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        },
        "outputId": "11891037-9fea-471d-a6a1-7baa97fc78ce"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "입력 : 어떻게 생각할까?\n",
            "출력 : 글쎄요 . \n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'글쎄요 . '"
            ]
          },
          "metadata": {},
          "execution_count": 673
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sentence_generation('오늘 너무 피곤하다')"
      ],
      "metadata": {
        "id": "FJQ2MgLUJkf3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        },
        "outputId": "8908f941-5350-4bb1-ec56-ce9310fffbe8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "입력 : 오늘 너무 피곤하다\n",
            "출력 : 다시 연락을 했나봐요 . \n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'다시 연락을 했나봐요 . '"
            ]
          },
          "metadata": {},
          "execution_count": 674
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sentence_generation('안녕하세요'), sentence_generation('반가워요!'), sentence_generation('재밌는 경기입니다.'), sentence_generation('너무 화가나요'), sentence_generation('배고파요'), sentence_generation('지쳤어요'), sentence_generation('공부하기 싫어요'), sentence_generation('저녁은 드셨나요?')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "eca5a264-86d4-49ac-d8c3-b876c245f080",
        "id": "PacCs8-_sc1b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "입력 : 안녕하세요\n",
            "출력 : 안녕하세요 . \n",
            "입력 : 반가워요!\n",
            "출력 : 돈 없어도 할 수 있는게 많아요\n",
            "입력 : 재밌는 경기입니다.\n",
            "출력 : 제가 있잖아요 . \n",
            "입력 : 너무 화가나요\n",
            "출력 : 안 좋은일이 있었나봐요 . \n",
            "입력 : 배고파요\n",
            "출력 : 무슨 일 있었나봐요 . \n",
            "입력 : 지쳤어요\n",
            "출력 : 다시 썸부터 시작해도 좋을 것 같아요 . \n",
            "입력 : 공부하기 싫어요\n",
            "출력 : 잠시 쉬어도 돼요 . \n",
            "입력 : 저녁은 드셨나요?\n",
            "출력 : 눈을 깜빡거려보세요 . \n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('안녕하세요 . ',\n",
              " '돈 없어도 할 수 있는게 많아요',\n",
              " '제가 있잖아요 . ',\n",
              " '안 좋은일이 있었나봐요 . ',\n",
              " '무슨 일 있었나봐요 . ',\n",
              " '다시 썸부터 시작해도 좋을 것 같아요 . ',\n",
              " '잠시 쉬어도 돼요 . ',\n",
              " '눈을 깜빡거려보세요 . ')"
            ]
          },
          "metadata": {},
          "execution_count": 675
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- 평가\n",
        "\n",
        "    - 정확도 및 손실값 : 거의 차이 없음\n",
        "    - 문장 구현 : 더(?) 동문서답 중\n",
        "\n"
      ],
      "metadata": {
        "id": "KyuMPIajJkf3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 6.2.3. 멀티 헤드 갯수 줄여보기(1)"
      ],
      "metadata": {
        "id": "RAfFH8lzZcfo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "NUM_HEAD \n",
        "\n",
        ": 32 -> 4\n"
      ],
      "metadata": {
        "id": "Zah4VAgtZcft"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tf.keras.backend.clear_session()\n",
        "\n",
        "NUM_LAYERS = 2 # 인코더와 디코더의 층의 개수\n",
        "D_MODEL = 256 # 인코더와 디코더 내부의 입, 출력의 고정 차원\n",
        "NUM_HEADS = 4 # 멀티 헤드 어텐션에서의 헤드 수 \n",
        "UNITS = 512 # 피드 포워드 신경망의 은닉층의 크기\n",
        "DROPOUT = 0.1 # 드롭아웃의 비율\n",
        "\n",
        "model = transformer(\n",
        "    vocab_size=VOCAB_SIZE,\n",
        "    num_layers=NUM_LAYERS,\n",
        "    units=UNITS,\n",
        "    d_model=D_MODEL,\n",
        "    num_heads=NUM_HEADS,\n",
        "    dropout=DROPOUT)\n",
        "\n",
        "model.summary()\n",
        "\n",
        "# 컴파일\n",
        "learning_rate = CustomSchedule(D_MODEL)\n",
        "\n",
        "optimizer = tf.keras.optimizers.Adam(\n",
        "    learning_rate, beta_1=0.9, beta_2=0.98, epsilon=1e-9)\n",
        "\n",
        "def accuracy(y_true, y_pred):\n",
        "  y_true = tf.reshape(y_true, shape=(-1, MAX_LENGTH - 1))\n",
        "  return tf.keras.metrics.sparse_categorical_accuracy(y_true, y_pred)\n",
        "\n",
        "model.compile(optimizer=optimizer, loss=loss_function, metrics=[accuracy])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "82838ee1-eef3-4be2-c21c-48acac80bc71",
        "id": "A4Jl_vHVZcft"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"transformer\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " inputs (InputLayer)            [(None, None)]       0           []                               \n",
            "                                                                                                  \n",
            " dec_inputs (InputLayer)        [(None, None)]       0           []                               \n",
            "                                                                                                  \n",
            " enc_padding_mask (Lambda)      (None, 1, 1, None)   0           ['inputs[0][0]']                 \n",
            "                                                                                                  \n",
            " encoder (Functional)           (None, None, 256)    6634240     ['inputs[0][0]',                 \n",
            "                                                                  'enc_padding_mask[0][0]']       \n",
            "                                                                                                  \n",
            " look_ahead_mask (Lambda)       (None, 1, None, Non  0           ['dec_inputs[0][0]']             \n",
            "                                e)                                                                \n",
            "                                                                                                  \n",
            " dec_padding_mask (Lambda)      (None, 1, 1, None)   0           ['inputs[0][0]']                 \n",
            "                                                                                                  \n",
            " decoder (Functional)           (None, None, 256)    7161600     ['dec_inputs[0][0]',             \n",
            "                                                                  'encoder[0][0]',                \n",
            "                                                                  'look_ahead_mask[0][0]',        \n",
            "                                                                  'dec_padding_mask[0][0]']       \n",
            "                                                                                                  \n",
            " outputs (Dense)                (None, None, 21797)  5601829     ['decoder[0][0]']                \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 19,397,669\n",
            "Trainable params: 19,397,669\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- 학습"
      ],
      "metadata": {
        "id": "1A0wBwQlZcft"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "EPOCHS = 20\n",
        "model.fit(dataset, epochs=EPOCHS, verbose=1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "56d599ff-3484-45bb-e044-aa234193a773",
        "id": "a0nD0mBiZcft"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "328/328 [==============================] - 15s 27ms/step - loss: 5.6415 - accuracy: 0.1930\n",
            "Epoch 2/20\n",
            "328/328 [==============================] - 9s 28ms/step - loss: 3.7441 - accuracy: 0.2434\n",
            "Epoch 3/20\n",
            "328/328 [==============================] - 9s 27ms/step - loss: 3.2942 - accuracy: 0.2543\n",
            "Epoch 4/20\n",
            "328/328 [==============================] - 9s 27ms/step - loss: 3.0121 - accuracy: 0.2683\n",
            "Epoch 5/20\n",
            "328/328 [==============================] - 9s 27ms/step - loss: 2.7166 - accuracy: 0.2926\n",
            "Epoch 6/20\n",
            "328/328 [==============================] - 9s 27ms/step - loss: 2.3867 - accuracy: 0.3279\n",
            "Epoch 7/20\n",
            "328/328 [==============================] - 9s 27ms/step - loss: 2.0419 - accuracy: 0.3692\n",
            "Epoch 8/20\n",
            "328/328 [==============================] - 9s 27ms/step - loss: 1.6972 - accuracy: 0.4078\n",
            "Epoch 9/20\n",
            "328/328 [==============================] - 9s 27ms/step - loss: 1.3686 - accuracy: 0.4424\n",
            "Epoch 10/20\n",
            "328/328 [==============================] - 9s 27ms/step - loss: 1.0840 - accuracy: 0.4779\n",
            "Epoch 11/20\n",
            "328/328 [==============================] - 9s 28ms/step - loss: 0.8453 - accuracy: 0.5102\n",
            "Epoch 12/20\n",
            "328/328 [==============================] - 9s 27ms/step - loss: 0.6709 - accuracy: 0.5358\n",
            "Epoch 13/20\n",
            "328/328 [==============================] - 9s 27ms/step - loss: 0.5339 - accuracy: 0.5585\n",
            "Epoch 14/20\n",
            "328/328 [==============================] - 9s 27ms/step - loss: 0.4076 - accuracy: 0.5810\n",
            "Epoch 15/20\n",
            "328/328 [==============================] - 9s 27ms/step - loss: 0.3168 - accuracy: 0.5975\n",
            "Epoch 16/20\n",
            "328/328 [==============================] - 9s 27ms/step - loss: 0.2588 - accuracy: 0.6096\n",
            "Epoch 17/20\n",
            "328/328 [==============================] - 9s 27ms/step - loss: 0.2108 - accuracy: 0.6211\n",
            "Epoch 18/20\n",
            "328/328 [==============================] - 9s 28ms/step - loss: 0.1772 - accuracy: 0.6283\n",
            "Epoch 19/20\n",
            "328/328 [==============================] - 9s 27ms/step - loss: 0.1572 - accuracy: 0.6332\n",
            "Epoch 20/20\n",
            "328/328 [==============================] - 9s 27ms/step - loss: 0.1425 - accuracy: 0.6368\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7efb1228a550>"
            ]
          },
          "metadata": {},
          "execution_count": 677
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sentence_generation('요즘 컨디션이 별로야')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        },
        "outputId": "ac6b895f-1dfe-499a-a51a-55e379ad357f",
        "id": "ZYr4tUQ3Zcfu"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "입력 : 요즘 컨디션이 별로야\n",
            "출력 : 아픔을 가늠할 수 없었으니까요 . \n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'아픔을 가늠할 수 없었으니까요 . '"
            ]
          },
          "metadata": {},
          "execution_count": 678
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sentence_generation('어떻게 생각할까?')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        },
        "outputId": "098f5c11-aa2a-4d73-e305-a6314eaa0e17",
        "id": "tAYzUacCZcfu"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "입력 : 어떻게 생각할까?\n",
            "출력 : 아직은 부담스럽지 않은 선물이 좋겠네요 . \n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'아직은 부담스럽지 않은 선물이 좋겠네요 . '"
            ]
          },
          "metadata": {},
          "execution_count": 679
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sentence_generation('오늘 너무 피곤하다')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        },
        "outputId": "98f562e1-7e81-43f1-84a0-d3883e5abe3b",
        "id": "CNvUaLWxZcfu"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "입력 : 오늘 너무 피곤하다\n",
            "출력 : 인스타를 삭제하는게 좋겠네요 . \n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'인스타를 삭제하는게 좋겠네요 . '"
            ]
          },
          "metadata": {},
          "execution_count": 680
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sentence_generation('안녕하세요'), sentence_generation('반가워요!'), sentence_generation('재밌는 경기입니다.'), sentence_generation('너무 화가나요'), sentence_generation('배고파요'), sentence_generation('지쳤어요'), sentence_generation('공부하기 싫어요'), sentence_generation('저녁은 드셨나요?')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "466273d9-f9f3-462a-fb64-3f7766b11f4e",
        "id": "knp8BgxPshFW"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "입력 : 안녕하세요\n",
            "출력 : 안녕하세요 . \n",
            "입력 : 반가워요!\n",
            "출력 : 볼 수 있어 좋은 가봐요 . \n",
            "입력 : 재밌는 경기입니다.\n",
            "출력 : 제가 있잖아요 . \n",
            "입력 : 너무 화가나요\n",
            "출력 : 안 좋은일이 있었나봐요 . \n",
            "입력 : 배고파요\n",
            "출력 : 그래서 표현이 중요해요 . \n",
            "입력 : 지쳤어요\n",
            "출력 : 그래서 표현이 중요해요 . \n",
            "입력 : 공부하기 싫어요\n",
            "출력 : 믿음이 더 필요해 보이네요 . \n",
            "입력 : 저녁은 드셨나요?\n",
            "출력 : 볼 수 있을 거 같아요 . \n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('안녕하세요 . ',\n",
              " '볼 수 있어 좋은 가봐요 . ',\n",
              " '제가 있잖아요 . ',\n",
              " '안 좋은일이 있었나봐요 . ',\n",
              " '그래서 표현이 중요해요 . ',\n",
              " '그래서 표현이 중요해요 . ',\n",
              " '믿음이 더 필요해 보이네요 . ',\n",
              " '볼 수 있을 거 같아요 . ')"
            ]
          },
          "metadata": {},
          "execution_count": 681
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- 평가\n",
        "\n",
        "    - 정확도 및 손실값 : -\n",
        "    - 문장 구현 : 비교적 응답이 적절해 보이는 갯수가 늘었으나 신뢰할 수 없다.\n",
        "\n"
      ],
      "metadata": {
        "id": "Nj7pZ2ODZcfu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 6.2.4. 멀티 헤드 갯수 줄여보기(2)"
      ],
      "metadata": {
        "id": "4cvEiN3yacCO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "NUM_HEAD \n",
        "\n",
        ": 4 -> 2\n"
      ],
      "metadata": {
        "id": "Ll_2mjuzacCO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tf.keras.backend.clear_session()\n",
        "\n",
        "NUM_LAYERS = 2 # 인코더와 디코더의 층의 개수\n",
        "D_MODEL = 256 # 인코더와 디코더 내부의 입, 출력의 고정 차원\n",
        "NUM_HEADS = 2 # 멀티 헤드 어텐션에서의 헤드 수 \n",
        "UNITS = 512 # 피드 포워드 신경망의 은닉층의 크기\n",
        "DROPOUT = 0.1 # 드롭아웃의 비율\n",
        "\n",
        "model = transformer(\n",
        "    vocab_size=VOCAB_SIZE,\n",
        "    num_layers=NUM_LAYERS,\n",
        "    units=UNITS,\n",
        "    d_model=D_MODEL,\n",
        "    num_heads=NUM_HEADS,\n",
        "    dropout=DROPOUT)\n",
        "\n",
        "model.summary()\n",
        "\n",
        "# 컴파일\n",
        "learning_rate = CustomSchedule(D_MODEL)\n",
        "\n",
        "optimizer = tf.keras.optimizers.Adam(\n",
        "    learning_rate, beta_1=0.9, beta_2=0.98, epsilon=1e-9)\n",
        "\n",
        "def accuracy(y_true, y_pred):\n",
        "  y_true = tf.reshape(y_true, shape=(-1, MAX_LENGTH - 1))\n",
        "  return tf.keras.metrics.sparse_categorical_accuracy(y_true, y_pred)\n",
        "\n",
        "model.compile(optimizer=optimizer, loss=loss_function, metrics=[accuracy])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "59cc9583-fd47-42cc-9520-aaf49f6a76ab",
        "id": "NTiII0jFacCO"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"transformer\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " inputs (InputLayer)            [(None, None)]       0           []                               \n",
            "                                                                                                  \n",
            " dec_inputs (InputLayer)        [(None, None)]       0           []                               \n",
            "                                                                                                  \n",
            " enc_padding_mask (Lambda)      (None, 1, 1, None)   0           ['inputs[0][0]']                 \n",
            "                                                                                                  \n",
            " encoder (Functional)           (None, None, 256)    6634240     ['inputs[0][0]',                 \n",
            "                                                                  'enc_padding_mask[0][0]']       \n",
            "                                                                                                  \n",
            " look_ahead_mask (Lambda)       (None, 1, None, Non  0           ['dec_inputs[0][0]']             \n",
            "                                e)                                                                \n",
            "                                                                                                  \n",
            " dec_padding_mask (Lambda)      (None, 1, 1, None)   0           ['inputs[0][0]']                 \n",
            "                                                                                                  \n",
            " decoder (Functional)           (None, None, 256)    7161600     ['dec_inputs[0][0]',             \n",
            "                                                                  'encoder[0][0]',                \n",
            "                                                                  'look_ahead_mask[0][0]',        \n",
            "                                                                  'dec_padding_mask[0][0]']       \n",
            "                                                                                                  \n",
            " outputs (Dense)                (None, None, 21797)  5601829     ['decoder[0][0]']                \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 19,397,669\n",
            "Trainable params: 19,397,669\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- 학습"
      ],
      "metadata": {
        "id": "VevGChaMacCP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "EPOCHS = 20\n",
        "model.fit(dataset, epochs=EPOCHS, verbose=1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ca078153-9170-4098-d372-ac07d1117d1e",
        "id": "vu5nyXOUacCQ"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "328/328 [==============================] - 15s 28ms/step - loss: 5.6431 - accuracy: 0.1812\n",
            "Epoch 2/20\n",
            "328/328 [==============================] - 9s 27ms/step - loss: 3.7421 - accuracy: 0.2431\n",
            "Epoch 3/20\n",
            "328/328 [==============================] - 9s 27ms/step - loss: 3.3144 - accuracy: 0.2521\n",
            "Epoch 4/20\n",
            "328/328 [==============================] - 9s 27ms/step - loss: 3.0502 - accuracy: 0.2661\n",
            "Epoch 5/20\n",
            "328/328 [==============================] - 9s 27ms/step - loss: 2.7636 - accuracy: 0.2876\n",
            "Epoch 6/20\n",
            "328/328 [==============================] - 9s 27ms/step - loss: 2.4272 - accuracy: 0.3231\n",
            "Epoch 7/20\n",
            "328/328 [==============================] - 9s 27ms/step - loss: 2.0759 - accuracy: 0.3635\n",
            "Epoch 8/20\n",
            "328/328 [==============================] - 9s 27ms/step - loss: 1.7194 - accuracy: 0.4023\n",
            "Epoch 9/20\n",
            "328/328 [==============================] - 9s 27ms/step - loss: 1.3824 - accuracy: 0.4400\n",
            "Epoch 10/20\n",
            "328/328 [==============================] - 9s 27ms/step - loss: 1.0947 - accuracy: 0.4754\n",
            "Epoch 11/20\n",
            "328/328 [==============================] - 9s 27ms/step - loss: 0.8617 - accuracy: 0.5078\n",
            "Epoch 12/20\n",
            "328/328 [==============================] - 9s 27ms/step - loss: 0.6947 - accuracy: 0.5314\n",
            "Epoch 13/20\n",
            "328/328 [==============================] - 9s 28ms/step - loss: 0.5551 - accuracy: 0.5536\n",
            "Epoch 14/20\n",
            "328/328 [==============================] - 9s 27ms/step - loss: 0.4353 - accuracy: 0.5754\n",
            "Epoch 15/20\n",
            "328/328 [==============================] - 9s 28ms/step - loss: 0.3448 - accuracy: 0.5919\n",
            "Epoch 16/20\n",
            "328/328 [==============================] - 9s 28ms/step - loss: 0.2770 - accuracy: 0.6063\n",
            "Epoch 17/20\n",
            "328/328 [==============================] - 9s 27ms/step - loss: 0.2281 - accuracy: 0.6170\n",
            "Epoch 18/20\n",
            "328/328 [==============================] - 9s 27ms/step - loss: 0.1960 - accuracy: 0.6236\n",
            "Epoch 19/20\n",
            "328/328 [==============================] - 9s 27ms/step - loss: 0.1665 - accuracy: 0.6309\n",
            "Epoch 20/20\n",
            "328/328 [==============================] - 9s 27ms/step - loss: 0.1548 - accuracy: 0.6333\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7efb107c3310>"
            ]
          },
          "metadata": {},
          "execution_count": 683
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sentence_generation('요즘 컨디션이 별로야')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        },
        "outputId": "87c3ad66-0da5-400b-849d-c08eb4d2ac97",
        "id": "_hrD9kffacCQ"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "입력 : 요즘 컨디션이 별로야\n",
            "출력 : 후회하지 않을 자신이 있다면 만나봐요 . \n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'후회하지 않을 자신이 있다면 만나봐요 . '"
            ]
          },
          "metadata": {},
          "execution_count": 684
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sentence_generation('어떻게 생각할까?')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        },
        "outputId": "d71ee96b-589e-471f-894d-99164a110535",
        "id": "QK0xK5wHacCQ"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "입력 : 어떻게 생각할까?\n",
            "출력 : 글쎄요 . \n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'글쎄요 . '"
            ]
          },
          "metadata": {},
          "execution_count": 685
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sentence_generation('오늘 너무 피곤하다')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        },
        "outputId": "281d0076-c9f2-4731-90c0-f16154870322",
        "id": "n-YdWV7QacCQ"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "입력 : 오늘 너무 피곤하다\n",
            "출력 : 알다가도 모르는게 연애 같아요 . \n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'알다가도 모르는게 연애 같아요 . '"
            ]
          },
          "metadata": {},
          "execution_count": 686
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sentence_generation('안녕하세요'), sentence_generation('반가워요!'), sentence_generation('재밌는 경기입니다.'), sentence_generation('너무 화가나요'), sentence_generation('배고파요'), sentence_generation('지쳤어요'), sentence_generation('공부하기 싫어요'), sentence_generation('저녁은 드셨나요?')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KNjeBKeNk4t4",
        "outputId": "6a3134e3-f056-41c2-e354-9a2c37f8b030"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "입력 : 안녕하세요\n",
            "출력 : 안녕하세요 . \n",
            "입력 : 반가워요!\n",
            "출력 : 더 생각이 나셨군요 . \n",
            "입력 : 재밌는 경기입니다.\n",
            "출력 : 제가 있잖아요 . \n",
            "입력 : 너무 화가나요\n",
            "출력 : 안 좋은일이 있었나봐요 . \n",
            "입력 : 배고파요\n",
            "출력 : 천천히 말해봐요 . \n",
            "입력 : 지쳤어요\n",
            "출력 : 천천히 잊어가요 . \n",
            "입력 : 공부하기 싫어요\n",
            "출력 : 충분한 대화를 나눴길 바랍니다 . \n",
            "입력 : 저녁은 드셨나요?\n",
            "출력 : 자신의 존재를 알리는 게 우선이겠네요 . \n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('안녕하세요 . ',\n",
              " '더 생각이 나셨군요 . ',\n",
              " '제가 있잖아요 . ',\n",
              " '안 좋은일이 있었나봐요 . ',\n",
              " '천천히 말해봐요 . ',\n",
              " '천천히 잊어가요 . ',\n",
              " '충분한 대화를 나눴길 바랍니다 . ',\n",
              " '자신의 존재를 알리는 게 우선이겠네요 . ')"
            ]
          },
          "metadata": {},
          "execution_count": 687
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- 평가\n",
        "\n",
        "    - 정확도 및 손실값 : 여전히 큰 차이가 없으나, 헤드의 수가 줄어드니 지표가 감소하는 것 같다.\n",
        "    - 문장 구현 : -\n",
        "\n"
      ],
      "metadata": {
        "id": "-sdgVKJnacCQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 6.2.5. 멀티 헤드 갯수 줄여보기(3)"
      ],
      "metadata": {
        "id": "fiygTnFshmG2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "NUM_HEAD \n",
        "\n",
        ": 2 -> 1"
      ],
      "metadata": {
        "id": "9owoT1KMhmG8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tf.keras.backend.clear_session()\n",
        "\n",
        "NUM_LAYERS = 2 # 인코더와 디코더의 층의 개수\n",
        "D_MODEL = 256 # 인코더와 디코더 내부의 입, 출력의 고정 차원\n",
        "NUM_HEADS = 1 # 멀티 헤드 어텐션에서의 헤드 수 \n",
        "UNITS = 512 # 피드 포워드 신경망의 은닉층의 크기\n",
        "DROPOUT = 0.1 # 드롭아웃의 비율\n",
        "\n",
        "model = transformer(\n",
        "    vocab_size=VOCAB_SIZE,\n",
        "    num_layers=NUM_LAYERS,\n",
        "    units=UNITS,\n",
        "    d_model=D_MODEL,\n",
        "    num_heads=NUM_HEADS,\n",
        "    dropout=DROPOUT)\n",
        "\n",
        "model.summary()\n",
        "\n",
        "# 컴파일\n",
        "learning_rate = CustomSchedule(D_MODEL)\n",
        "\n",
        "optimizer = tf.keras.optimizers.Adam(\n",
        "    learning_rate, beta_1=0.9, beta_2=0.98, epsilon=1e-9)\n",
        "\n",
        "def accuracy(y_true, y_pred):\n",
        "  y_true = tf.reshape(y_true, shape=(-1, MAX_LENGTH - 1))\n",
        "  return tf.keras.metrics.sparse_categorical_accuracy(y_true, y_pred)\n",
        "\n",
        "model.compile(optimizer=optimizer, loss=loss_function, metrics=[accuracy])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "591055b6-346a-484c-9078-f398cb880025",
        "id": "qO5CoxyXhmG8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"transformer\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " inputs (InputLayer)            [(None, None)]       0           []                               \n",
            "                                                                                                  \n",
            " dec_inputs (InputLayer)        [(None, None)]       0           []                               \n",
            "                                                                                                  \n",
            " enc_padding_mask (Lambda)      (None, 1, 1, None)   0           ['inputs[0][0]']                 \n",
            "                                                                                                  \n",
            " encoder (Functional)           (None, None, 256)    6634240     ['inputs[0][0]',                 \n",
            "                                                                  'enc_padding_mask[0][0]']       \n",
            "                                                                                                  \n",
            " look_ahead_mask (Lambda)       (None, 1, None, Non  0           ['dec_inputs[0][0]']             \n",
            "                                e)                                                                \n",
            "                                                                                                  \n",
            " dec_padding_mask (Lambda)      (None, 1, 1, None)   0           ['inputs[0][0]']                 \n",
            "                                                                                                  \n",
            " decoder (Functional)           (None, None, 256)    7161600     ['dec_inputs[0][0]',             \n",
            "                                                                  'encoder[0][0]',                \n",
            "                                                                  'look_ahead_mask[0][0]',        \n",
            "                                                                  'dec_padding_mask[0][0]']       \n",
            "                                                                                                  \n",
            " outputs (Dense)                (None, None, 21797)  5601829     ['decoder[0][0]']                \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 19,397,669\n",
            "Trainable params: 19,397,669\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- 학습"
      ],
      "metadata": {
        "id": "pUfj_AUehmG8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "EPOCHS = 20\n",
        "model.fit(dataset, epochs=EPOCHS, verbose=1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ef7650c5-b0d4-4347-ce94-214c9935fa73",
        "id": "fr_p_gvMhmG8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "328/328 [==============================] - 14s 27ms/step - loss: 5.6993 - accuracy: 0.1836\n",
            "Epoch 2/20\n",
            "328/328 [==============================] - 9s 27ms/step - loss: 3.7678 - accuracy: 0.2436\n",
            "Epoch 3/20\n",
            "328/328 [==============================] - 9s 27ms/step - loss: 3.3211 - accuracy: 0.2525\n",
            "Epoch 4/20\n",
            "328/328 [==============================] - 9s 27ms/step - loss: 3.0295 - accuracy: 0.2671\n",
            "Epoch 5/20\n",
            "328/328 [==============================] - 9s 27ms/step - loss: 2.7228 - accuracy: 0.2927\n",
            "Epoch 6/20\n",
            "328/328 [==============================] - 9s 26ms/step - loss: 2.3949 - accuracy: 0.3286\n",
            "Epoch 7/20\n",
            "328/328 [==============================] - 9s 27ms/step - loss: 2.0554 - accuracy: 0.3692\n",
            "Epoch 8/20\n",
            "328/328 [==============================] - 9s 26ms/step - loss: 1.7324 - accuracy: 0.4038\n",
            "Epoch 9/20\n",
            "328/328 [==============================] - 9s 27ms/step - loss: 1.4290 - accuracy: 0.4346\n",
            "Epoch 10/20\n",
            "328/328 [==============================] - 9s 27ms/step - loss: 1.1643 - accuracy: 0.4647\n",
            "Epoch 11/20\n",
            "328/328 [==============================] - 9s 27ms/step - loss: 0.9407 - accuracy: 0.4925\n",
            "Epoch 12/20\n",
            "328/328 [==============================] - 9s 27ms/step - loss: 0.7700 - accuracy: 0.5168\n",
            "Epoch 13/20\n",
            "328/328 [==============================] - 9s 27ms/step - loss: 0.6419 - accuracy: 0.5370\n",
            "Epoch 14/20\n",
            "328/328 [==============================] - 9s 26ms/step - loss: 0.5126 - accuracy: 0.5589\n",
            "Epoch 15/20\n",
            "328/328 [==============================] - 9s 27ms/step - loss: 0.4117 - accuracy: 0.5781\n",
            "Epoch 16/20\n",
            "328/328 [==============================] - 9s 26ms/step - loss: 0.3362 - accuracy: 0.5922\n",
            "Epoch 17/20\n",
            "328/328 [==============================] - 9s 26ms/step - loss: 0.2775 - accuracy: 0.6054\n",
            "Epoch 18/20\n",
            "328/328 [==============================] - 9s 27ms/step - loss: 0.2373 - accuracy: 0.6152\n",
            "Epoch 19/20\n",
            "328/328 [==============================] - 9s 27ms/step - loss: 0.2062 - accuracy: 0.6213\n",
            "Epoch 20/20\n",
            "328/328 [==============================] - 9s 27ms/step - loss: 0.1813 - accuracy: 0.6277\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7efb0f5aef90>"
            ]
          },
          "metadata": {},
          "execution_count": 689
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sentence_generation('요즘 컨디션이 별로야')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        },
        "outputId": "0cea8ed2-6945-434c-b9e5-0fcd087f8d04",
        "id": "I_eC2EclhmG8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "입력 : 요즘 컨디션이 별로야\n",
            "출력 : 좋아하는 감정은 정말 복잡하고 힘들어요 . \n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'좋아하는 감정은 정말 복잡하고 힘들어요 . '"
            ]
          },
          "metadata": {},
          "execution_count": 690
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sentence_generation('어떻게 생각할까?')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        },
        "outputId": "c5f420ac-421f-4de2-b482-d55207bd3d15",
        "id": "0yBjo_WIhmG8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "입력 : 어떻게 생각할까?\n",
            "출력 : 글쎄요 . \n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'글쎄요 . '"
            ]
          },
          "metadata": {},
          "execution_count": 691
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sentence_generation('오늘 너무 피곤하다')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        },
        "outputId": "291e8fb3-4223-413e-9055-49716b10a658",
        "id": "Lv6rPfVvhmG9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "입력 : 오늘 너무 피곤하다\n",
            "출력 : 마음을 천천히 보듬어 주세요 . \n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'마음을 천천히 보듬어 주세요 . '"
            ]
          },
          "metadata": {},
          "execution_count": 692
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sentence_generation('안녕하세요'), sentence_generation('반가워요!'), sentence_generation('재밌는 경기입니다.'), sentence_generation('너무 화가나요'), sentence_generation('배고파요'), sentence_generation('지쳤어요'), sentence_generation('공부하기 싫어요'), sentence_generation('저녁은 드셨나요?')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6dv4c5J2p_qw",
        "outputId": "306737de-c8fb-4f9f-b89a-13818a2f3a00"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "입력 : 안녕하세요\n",
            "출력 : 안녕하세요 . \n",
            "입력 : 반가워요!\n",
            "출력 : 인연이 거기까지인가봐요 . \n",
            "입력 : 재밌는 경기입니다.\n",
            "출력 : 제가 있잖아요 . \n",
            "입력 : 너무 화가나요\n",
            "출력 : 안 본 웹툰이 있는지 먼저 물어보고싶네요 . \n",
            "입력 : 배고파요\n",
            "출력 : 좀 더 편하게 생각해보세요 . \n",
            "입력 : 지쳤어요\n",
            "출력 : 더 이상 신경쓰지 마세요 . \n",
            "입력 : 공부하기 싫어요\n",
            "출력 : 조금만 더 버텨보세요 . \n",
            "입력 : 저녁은 드셨나요?\n",
            "출력 : 마음은 좀 정리 되어가길 바랍니다 . \n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('안녕하세요 . ',\n",
              " '인연이 거기까지인가봐요 . ',\n",
              " '제가 있잖아요 . ',\n",
              " '안 본 웹툰이 있는지 먼저 물어보고싶네요 . ',\n",
              " '좀 더 편하게 생각해보세요 . ',\n",
              " '더 이상 신경쓰지 마세요 . ',\n",
              " '조금만 더 버텨보세요 . ',\n",
              " '마음은 좀 정리 되어가길 바랍니다 . ')"
            ]
          },
          "metadata": {},
          "execution_count": 693
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- 평가\n",
        "\n",
        "    - 정확도 및 손실값 : 더 감소했다. 헤드의 수에 영향을 받는 것이 어느 정도 확인된다.\n",
        "    - 문장 구현 : -\n",
        "\n"
      ],
      "metadata": {
        "id": "a4FlLoCJhmG8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 6.3. vocab_size에 관련한 조정\n",
        "\n",
        "기존\n",
        "- traget_vocab_size = 2**14 / MAX_LENGTH = 9\n",
        "- BUFFER_SIZE = 샘플 수\n",
        "\n",
        "    >- 단어장의 크기 : 21797\n",
        "    >- 필터링 후의 질문 샘플 개수: 10476\n",
        "    >- 필터링 후의 답변 샘플 개수: 10476\n",
        "\n",
        "- 샘플 수가 적고, 한 명이 작성한 인공 데이터셋임을 감안해 단어장 목표 사이즈를 넉넉하게 설정했었다.\n",
        "\n",
        "\n",
        "참조\n",
        "- 단어장 타겟 사이즈를 2^15, 2^16으로 변경해도 더 큰 단어장이 생성되지는 않는다.\n",
        "- 예제 데이터의 기본 목표 사이즈였던 2^13의 경우 아래와 같다\n",
        "    >- 단어장의 크기 : 8149\n",
        "    >- 필터링 후의 질문 샘플 개수: 7843\n",
        "    >- 필터링 후의 답변 샘플 개수: 7843\n",
        "    >\n",
        "    > 필터링 후 샘플 이 많이 손실된다고 판단\n",
        "- 따라서 최대치 단어장 크기 목표 기준 샘플 갯수와 비슷한 목표 단어장을 설정해보았다.\n",
        "\n",
        "\n",
        "변경\n",
        "- traget_vocab_size = 10500 / MAX_LENGTH = 9\n",
        "    >- 단어장의 크기 : 10079\n",
        "    >- 필터링 후의 질문 샘플 개수: 8405\n",
        "    >- 필터링 후의 답변 샘플 개수: 8405\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "4WdQ1G5RFgaQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 위의 조절을 기준으로 재실행\n",
        "\n",
        "6.3.에 대한 평가\n",
        "- 전반적인 정확도가 올라갔다.\n",
        "    > 단어장 설정의 기준 확보\n",
        "- 멀티 헤드 갯수를 줄이는 것은 좋지 못한 생각이다.\n",
        "    >- 정확도와 손실값 지표가 좋지 않고, 문장 구현 능력도 부족하다.\n",
        "    >- 멀티 헤드의 갯수가 많을 수록 지표에 대한 수렴이 빠르기 때문에 epoch을 달리 해야 더 적절한 비교가 될 수 있다고 볼 수도 있으나, 학습 시간 비용을 고려하면 적절한 헤드 수를 사용하는 것이 좋다.\n",
        "- 각각 1, 2, 4, 8, 16, 32 개의 헤드 수에서, 32개일 경우 지표가 가잫 좋았으나 문장 구현은 16에서 더 좋았다.\n",
        "    > 하지만 기록하지 않은 수많은 학습 결과, 문장 생성 표본은 그다지 신뢰도가 높지 않으니 여전히 비교군에 유지한다.\n",
        "\n",
        "\n",
        "6.3. 결과반영\n",
        "- 목표 단어장 설정 10500\n",
        "- 버퍼 사이즈 = 샘플 사이즈 = 8405\n",
        "- 넘헤드 갯수 줄여보기 모델들은 탈락\n",
        "     "
      ],
      "metadata": {
        "id": "6DN7N6iMGFNf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 6.3.1. 기본 모델\n",
        "\n",
        "loss: 0.0403 - accuracy: 0.6991"
      ],
      "metadata": {
        "id": "fmiHn74FM46S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sentence_generation('요즘 컨디션이 별로야')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "outputId": "54e8f1db-6747-4a8d-ff1d-64d454902170",
        "id": "QIJMikcWNAAB"
      },
      "execution_count": 107,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "입력 : 요즘 컨디션이 별로야\n",
            "출력 : 무엇이 다 말씀하세요 . \n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'무엇이 다 말씀하세요 . '"
            ]
          },
          "metadata": {},
          "execution_count": 107
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sentence_generation('어떻게 생각할까?')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "outputId": "3245512f-4d63-4362-cb7d-bf230853ae4b",
        "id": "aUxF0XrKNAAC"
      },
      "execution_count": 108,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "입력 : 어떻게 생각할까?\n",
            "출력 : 아직은 잘 모르겠어요 . \n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'아직은 잘 모르겠어요 . '"
            ]
          },
          "metadata": {},
          "execution_count": 108
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sentence_generation('오늘 너무 피곤하다')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "outputId": "3c039d5e-485b-4b01-a90e-12691a109ef1",
        "id": "-VCdL9YSNAAC"
      },
      "execution_count": 109,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "입력 : 오늘 너무 피곤하다\n",
            "출력 : 아무래도 사생활이 적으니까요 . \n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'아무래도 사생활이 적으니까요 . '"
            ]
          },
          "metadata": {},
          "execution_count": 109
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sentence_generation('안녕하세요'), sentence_generation('반가워요!'), sentence_generation('재밌는 경기입니다.'), sentence_generation('너무 화가나요'), sentence_generation('배고파요'), sentence_generation('지쳤어요'), sentence_generation('공부하기 싫어요'), sentence_generation('저녁은 드셨나요?')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "18a0c2ba-f842-4efd-e6e8-bdb022e4e5c6",
        "id": "3wTv434eNAAC"
      },
      "execution_count": 110,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "입력 : 안녕하세요\n",
            "출력 : 안녕하세요 . \n",
            "입력 : 반가워요!\n",
            "출력 : 반갑습니다 . \n",
            "입력 : 재밌는 경기입니다.\n",
            "출력 : 제가 있잖아요 . \n",
            "입력 : 너무 화가나요\n",
            "출력 : 자신을 먼저 사랑해주세요 . \n",
            "입력 : 배고파요\n",
            "출력 : 뭐 좀 챙겨드세요 . \n",
            "입력 : 지쳤어요\n",
            "출력 : 고생 많았어요 . \n",
            "입력 : 공부하기 싫어요\n",
            "출력 : 새로운 스타일에 도전하는 것도 좋아요 . \n",
            "입력 : 저녁은 드셨나요?\n",
            "출력 : 맛있는 거 드세요 . \n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('안녕하세요 . ',\n",
              " '반갑습니다 . ',\n",
              " '제가 있잖아요 . ',\n",
              " '자신을 먼저 사랑해주세요 . ',\n",
              " '뭐 좀 챙겨드세요 . ',\n",
              " '고생 많았어요 . ',\n",
              " '새로운 스타일에 도전하는 것도 좋아요 . ',\n",
              " '맛있는 거 드세요 . ')"
            ]
          },
          "metadata": {},
          "execution_count": 110
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 6.3.2. 멀티 헤드 갯수 늘려보기(1)"
      ],
      "metadata": {
        "id": "Z3wm2sB9GFNf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "NUM_HEAD \n",
        "\n",
        ": 8 -> 16\n"
      ],
      "metadata": {
        "id": "dcNieaXZGFNg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tf.keras.backend.clear_session()\n",
        "\n",
        "NUM_LAYERS = 2 # 인코더와 디코더의 층의 개수\n",
        "D_MODEL = 256 # 인코더와 디코더 내부의 입, 출력의 고정 차원\n",
        "NUM_HEADS = 16 # 멀티 헤드 어텐션에서의 헤드 수 \n",
        "UNITS = 512 # 피드 포워드 신경망의 은닉층의 크기\n",
        "DROPOUT = 0.1 # 드롭아웃의 비율\n",
        "\n",
        "model = transformer(\n",
        "    vocab_size=VOCAB_SIZE,\n",
        "    num_layers=NUM_LAYERS,\n",
        "    units=UNITS,\n",
        "    d_model=D_MODEL,\n",
        "    num_heads=NUM_HEADS,\n",
        "    dropout=DROPOUT)\n",
        "\n",
        "model.summary()\n",
        "\n",
        "# 컴파일\n",
        "learning_rate = CustomSchedule(D_MODEL)\n",
        "\n",
        "optimizer = tf.keras.optimizers.Adam(\n",
        "    learning_rate, beta_1=0.9, beta_2=0.98, epsilon=1e-9)\n",
        "\n",
        "def accuracy(y_true, y_pred):\n",
        "  y_true = tf.reshape(y_true, shape=(-1, MAX_LENGTH - 1))\n",
        "  return tf.keras.metrics.sparse_categorical_accuracy(y_true, y_pred)\n",
        "\n",
        "model.compile(optimizer=optimizer, loss=loss_function, metrics=[accuracy])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bfa9d6f8-d4bf-4f32-83b7-d6e479838c95",
        "id": "n7P0DgDlGFNg"
      },
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"transformer\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " inputs (InputLayer)            [(None, None)]       0           []                               \n",
            "                                                                                                  \n",
            " dec_inputs (InputLayer)        [(None, None)]       0           []                               \n",
            "                                                                                                  \n",
            " enc_padding_mask (Lambda)      (None, 1, 1, None)   0           ['inputs[0][0]']                 \n",
            "                                                                                                  \n",
            " encoder (Functional)           (None, None, 256)    3634432     ['inputs[0][0]',                 \n",
            "                                                                  'enc_padding_mask[0][0]']       \n",
            "                                                                                                  \n",
            " look_ahead_mask (Lambda)       (None, 1, None, Non  0           ['dec_inputs[0][0]']             \n",
            "                                e)                                                                \n",
            "                                                                                                  \n",
            " dec_padding_mask (Lambda)      (None, 1, 1, None)   0           ['inputs[0][0]']                 \n",
            "                                                                                                  \n",
            " decoder (Functional)           (None, None, 256)    4161792     ['dec_inputs[0][0]',             \n",
            "                                                                  'encoder[0][0]',                \n",
            "                                                                  'look_ahead_mask[0][0]',        \n",
            "                                                                  'dec_padding_mask[0][0]']       \n",
            "                                                                                                  \n",
            " outputs (Dense)                (None, None, 10079)  2590303     ['decoder[0][0]']                \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 10,386,527\n",
            "Trainable params: 10,386,527\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- 학습"
      ],
      "metadata": {
        "id": "bRKKmyzzGFNg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "EPOCHS = 20\n",
        "model.fit(dataset, epochs=EPOCHS, verbose=1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8aa0eaee-1dd5-4f38-9cc4-359d4da44a88",
        "id": "s3JmD2fnGFNg"
      },
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "263/263 [==============================] - 14s 22ms/step - loss: 5.6921 - accuracy: 0.1409\n",
            "Epoch 2/20\n",
            "263/263 [==============================] - 6s 22ms/step - loss: 4.0994 - accuracy: 0.2410\n",
            "Epoch 3/20\n",
            "263/263 [==============================] - 6s 24ms/step - loss: 3.5479 - accuracy: 0.2515\n",
            "Epoch 4/20\n",
            "263/263 [==============================] - 6s 22ms/step - loss: 3.2692 - accuracy: 0.2667\n",
            "Epoch 5/20\n",
            "263/263 [==============================] - 6s 22ms/step - loss: 2.9936 - accuracy: 0.2878\n",
            "Epoch 6/20\n",
            "263/263 [==============================] - 6s 22ms/step - loss: 2.6796 - accuracy: 0.3227\n",
            "Epoch 7/20\n",
            "263/263 [==============================] - 6s 22ms/step - loss: 2.3241 - accuracy: 0.3667\n",
            "Epoch 8/20\n",
            "263/263 [==============================] - 6s 22ms/step - loss: 1.9506 - accuracy: 0.4118\n",
            "Epoch 9/20\n",
            "263/263 [==============================] - 6s 22ms/step - loss: 1.5704 - accuracy: 0.4566\n",
            "Epoch 10/20\n",
            "263/263 [==============================] - 6s 22ms/step - loss: 1.2183 - accuracy: 0.5002\n",
            "Epoch 11/20\n",
            "263/263 [==============================] - 6s 22ms/step - loss: 0.9184 - accuracy: 0.5412\n",
            "Epoch 12/20\n",
            "263/263 [==============================] - 6s 22ms/step - loss: 0.6779 - accuracy: 0.5768\n",
            "Epoch 13/20\n",
            "263/263 [==============================] - 6s 22ms/step - loss: 0.4975 - accuracy: 0.6085\n",
            "Epoch 14/20\n",
            "263/263 [==============================] - 6s 22ms/step - loss: 0.3805 - accuracy: 0.6277\n",
            "Epoch 15/20\n",
            "263/263 [==============================] - 6s 24ms/step - loss: 0.3069 - accuracy: 0.6409\n",
            "Epoch 16/20\n",
            "263/263 [==============================] - 6s 22ms/step - loss: 0.2615 - accuracy: 0.6486\n",
            "Epoch 17/20\n",
            "263/263 [==============================] - 6s 22ms/step - loss: 0.2038 - accuracy: 0.6626\n",
            "Epoch 18/20\n",
            "263/263 [==============================] - 6s 24ms/step - loss: 0.1645 - accuracy: 0.6705\n",
            "Epoch 19/20\n",
            "263/263 [==============================] - 6s 22ms/step - loss: 0.1424 - accuracy: 0.6757\n",
            "Epoch 20/20\n",
            "263/263 [==============================] - 6s 22ms/step - loss: 0.1228 - accuracy: 0.6798\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7ff872567dd0>"
            ]
          },
          "metadata": {},
          "execution_count": 74
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sentence_generation('요즘 컨디션이 별로야')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "outputId": "7b744dd5-9a30-4ac9-9b83-76de74acc57c",
        "id": "ExSMn3-bGFNg"
      },
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "입력 : 요즘 컨디션이 별로야\n",
            "출력 : 건강에 마음의 준비가 필요하겠네요 . \n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'건강에 마음의 준비가 필요하겠네요 . '"
            ]
          },
          "metadata": {},
          "execution_count": 78
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sentence_generation('어떻게 생각할까?')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "outputId": "4544326a-6f6f-4a39-bdd7-9db313665c61",
        "id": "48H-CEMpGFNg"
      },
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "입력 : 어떻게 생각할까?\n",
            "출력 : 잘 모르겠어요 . \n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'잘 모르겠어요 . '"
            ]
          },
          "metadata": {},
          "execution_count": 79
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sentence_generation('오늘 너무 피곤하다')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "outputId": "a996d667-bece-4782-b9f9-519f9c79dc34",
        "id": "HlVIh9FvGFNh"
      },
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "입력 : 오늘 너무 피곤하다\n",
            "출력 : 아무래도 사생활이 적으니까요 . \n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'아무래도 사생활이 적으니까요 . '"
            ]
          },
          "metadata": {},
          "execution_count": 80
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sentence_generation('안녕하세요'), sentence_generation('반가워요!'), sentence_generation('재밌는 경기입니다.'), sentence_generation('너무 화가나요'), sentence_generation('배고파요'), sentence_generation('지쳤어요'), sentence_generation('공부하기 싫어요'), sentence_generation('저녁은 드셨나요?')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "851bf70e-8a8e-4d8d-faaa-8e510dc63872",
        "id": "Ww00Srk0GFNh"
      },
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "입력 : 안녕하세요\n",
            "출력 : 안녕하세요 . \n",
            "입력 : 반가워요!\n",
            "출력 : 반갑습니다 . \n",
            "입력 : 재밌는 경기입니다.\n",
            "출력 : 제가 있잖아요 . \n",
            "입력 : 너무 화가나요\n",
            "출력 : 생각보다 힘든 일이 있었나봐요 . \n",
            "입력 : 배고파요\n",
            "출력 : 맛난 거 드세요 . \n",
            "입력 : 지쳤어요\n",
            "출력 : 지칠 때는 쉬어도 돼요 . \n",
            "입력 : 공부하기 싫어요\n",
            "출력 : 잠시 쉬어도 괜찮습니다 . \n",
            "입력 : 저녁은 드셨나요?\n",
            "출력 : 솔직한 사람에게 매력을 느끼나봐요 . \n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('안녕하세요 . ',\n",
              " '반갑습니다 . ',\n",
              " '제가 있잖아요 . ',\n",
              " '생각보다 힘든 일이 있었나봐요 . ',\n",
              " '맛난 거 드세요 . ',\n",
              " '지칠 때는 쉬어도 돼요 . ',\n",
              " '잠시 쉬어도 괜찮습니다 . ',\n",
              " '솔직한 사람에게 매력을 느끼나봐요 . ')"
            ]
          },
          "metadata": {},
          "execution_count": 81
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 6.3.3. 멀티 헤드 갯수 늘려보기(2)"
      ],
      "metadata": {
        "id": "w39JuLQgGFNh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "NUM_HEAD \n",
        "\n",
        ": 16 -> 32\n"
      ],
      "metadata": {
        "id": "oRr8c4tAGFNh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tf.keras.backend.clear_session()\n",
        "\n",
        "NUM_LAYERS = 2 # 인코더와 디코더의 층의 개수\n",
        "D_MODEL = 256 # 인코더와 디코더 내부의 입, 출력의 고정 차원\n",
        "NUM_HEADS = 32 # 멀티 헤드 어텐션에서의 헤드 수 \n",
        "UNITS = 512 # 피드 포워드 신경망의 은닉층의 크기\n",
        "DROPOUT = 0.1 # 드롭아웃의 비율\n",
        "\n",
        "model = transformer(\n",
        "    vocab_size=VOCAB_SIZE,\n",
        "    num_layers=NUM_LAYERS,\n",
        "    units=UNITS,\n",
        "    d_model=D_MODEL,\n",
        "    num_heads=NUM_HEADS,\n",
        "    dropout=DROPOUT)\n",
        "\n",
        "model.summary()\n",
        "\n",
        "# 컴파일\n",
        "learning_rate = CustomSchedule(D_MODEL)\n",
        "\n",
        "optimizer = tf.keras.optimizers.Adam(\n",
        "    learning_rate, beta_1=0.9, beta_2=0.98, epsilon=1e-9)\n",
        "\n",
        "def accuracy(y_true, y_pred):\n",
        "  y_true = tf.reshape(y_true, shape=(-1, MAX_LENGTH - 1))\n",
        "  return tf.keras.metrics.sparse_categorical_accuracy(y_true, y_pred)\n",
        "\n",
        "model.compile(optimizer=optimizer, loss=loss_function, metrics=[accuracy])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f90df11c-d1de-49cc-faa0-51b3d1947dbf",
        "id": "Fm8zVOlYGFNh"
      },
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"transformer\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " inputs (InputLayer)            [(None, None)]       0           []                               \n",
            "                                                                                                  \n",
            " dec_inputs (InputLayer)        [(None, None)]       0           []                               \n",
            "                                                                                                  \n",
            " enc_padding_mask (Lambda)      (None, 1, 1, None)   0           ['inputs[0][0]']                 \n",
            "                                                                                                  \n",
            " encoder (Functional)           (None, None, 256)    3634432     ['inputs[0][0]',                 \n",
            "                                                                  'enc_padding_mask[0][0]']       \n",
            "                                                                                                  \n",
            " look_ahead_mask (Lambda)       (None, 1, None, Non  0           ['dec_inputs[0][0]']             \n",
            "                                e)                                                                \n",
            "                                                                                                  \n",
            " dec_padding_mask (Lambda)      (None, 1, 1, None)   0           ['inputs[0][0]']                 \n",
            "                                                                                                  \n",
            " decoder (Functional)           (None, None, 256)    4161792     ['dec_inputs[0][0]',             \n",
            "                                                                  'encoder[0][0]',                \n",
            "                                                                  'look_ahead_mask[0][0]',        \n",
            "                                                                  'dec_padding_mask[0][0]']       \n",
            "                                                                                                  \n",
            " outputs (Dense)                (None, None, 10079)  2590303     ['decoder[0][0]']                \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 10,386,527\n",
            "Trainable params: 10,386,527\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- 학습"
      ],
      "metadata": {
        "id": "Axwy1GCAGFNi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "EPOCHS = 20\n",
        "model.fit(dataset, epochs=EPOCHS, verbose=1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9c29a258-c0f7-4a8f-ea5c-d6629472e4ed",
        "id": "q3UIVLSzGFNi"
      },
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "263/263 [==============================] - 12s 23ms/step - loss: 5.7179 - accuracy: 0.1381\n",
            "Epoch 2/20\n",
            "263/263 [==============================] - 6s 23ms/step - loss: 4.1111 - accuracy: 0.2412\n",
            "Epoch 3/20\n",
            "263/263 [==============================] - 6s 23ms/step - loss: 3.5639 - accuracy: 0.2510\n",
            "Epoch 4/20\n",
            "263/263 [==============================] - 6s 23ms/step - loss: 3.2756 - accuracy: 0.2655\n",
            "Epoch 5/20\n",
            "263/263 [==============================] - 6s 23ms/step - loss: 2.9841 - accuracy: 0.2889\n",
            "Epoch 6/20\n",
            "263/263 [==============================] - 6s 23ms/step - loss: 2.6603 - accuracy: 0.3238\n",
            "Epoch 7/20\n",
            "263/263 [==============================] - 6s 23ms/step - loss: 2.3022 - accuracy: 0.3692\n",
            "Epoch 8/20\n",
            "263/263 [==============================] - 6s 23ms/step - loss: 1.9276 - accuracy: 0.4159\n",
            "Epoch 9/20\n",
            "263/263 [==============================] - 6s 23ms/step - loss: 1.5482 - accuracy: 0.4613\n",
            "Epoch 10/20\n",
            "263/263 [==============================] - 6s 23ms/step - loss: 1.2005 - accuracy: 0.5047\n",
            "Epoch 11/20\n",
            "263/263 [==============================] - 7s 25ms/step - loss: 0.9025 - accuracy: 0.5442\n",
            "Epoch 12/20\n",
            "263/263 [==============================] - 6s 23ms/step - loss: 0.6665 - accuracy: 0.5811\n",
            "Epoch 13/20\n",
            "263/263 [==============================] - 6s 23ms/step - loss: 0.4877 - accuracy: 0.6113\n",
            "Epoch 14/20\n",
            "263/263 [==============================] - 6s 23ms/step - loss: 0.3745 - accuracy: 0.6280\n",
            "Epoch 15/20\n",
            "263/263 [==============================] - 6s 23ms/step - loss: 0.3018 - accuracy: 0.6421\n",
            "Epoch 16/20\n",
            "263/263 [==============================] - 6s 23ms/step - loss: 0.2554 - accuracy: 0.6514\n",
            "Epoch 17/20\n",
            "263/263 [==============================] - 6s 23ms/step - loss: 0.2005 - accuracy: 0.6620\n",
            "Epoch 18/20\n",
            "263/263 [==============================] - 6s 23ms/step - loss: 0.1621 - accuracy: 0.6709\n",
            "Epoch 19/20\n",
            "263/263 [==============================] - 6s 23ms/step - loss: 0.1353 - accuracy: 0.6769\n",
            "Epoch 20/20\n",
            "263/263 [==============================] - 6s 23ms/step - loss: 0.1194 - accuracy: 0.6807\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7ff7f4795050>"
            ]
          },
          "metadata": {},
          "execution_count": 83
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sentence_generation('요즘 컨디션이 별로야')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "outputId": "06124031-c9ed-48f8-b5ee-31bf50ce9c5f",
        "id": "epC5IslgGFNi"
      },
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "입력 : 요즘 컨디션이 별로야\n",
            "출력 : 하다보면 늘어요 . \n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'하다보면 늘어요 . '"
            ]
          },
          "metadata": {},
          "execution_count": 84
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sentence_generation('어떻게 생각할까?')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "outputId": "cfd3f6f7-7991-4b37-cebe-6e63fcd689c7",
        "id": "NDnV3Rd4GFNi"
      },
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "입력 : 어떻게 생각할까?\n",
            "출력 : 아직은 모르겠어요 . \n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'아직은 모르겠어요 . '"
            ]
          },
          "metadata": {},
          "execution_count": 85
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sentence_generation('오늘 너무 피곤하다')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "outputId": "6b71f5a4-e4cb-4bbf-f875-0c7cfa811421",
        "id": "LQl2QjaBGFNi"
      },
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "입력 : 오늘 너무 피곤하다\n",
            "출력 : 자신에게 돌아가는 시간이 힘들겠네요 . \n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'자신에게 돌아가는 시간이 힘들겠네요 . '"
            ]
          },
          "metadata": {},
          "execution_count": 86
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sentence_generation('안녕하세요'), sentence_generation('반가워요!'), sentence_generation('재밌는 경기입니다.'), sentence_generation('너무 화가나요'), sentence_generation('배고파요'), sentence_generation('지쳤어요'), sentence_generation('공부하기 싫어요'), sentence_generation('저녁은 드셨나요?')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "70247ae2-4173-4eea-8add-1c50a5c12611",
        "id": "mMN0XgecGFNi"
      },
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "입력 : 안녕하세요\n",
            "출력 : 안녕하세요 . \n",
            "입력 : 반가워요!\n",
            "출력 : 현재를 즐기세요 ! \n",
            "입력 : 재밌는 경기입니다.\n",
            "출력 : 제가 있잖아요 . \n",
            "입력 : 너무 화가나요\n",
            "출력 : 안 좋은일이 있었나봐요 . \n",
            "입력 : 배고파요\n",
            "출력 : 뭐 좀 챙겨드세요 . \n",
            "입력 : 지쳤어요\n",
            "출력 : 고생 많았어요 . \n",
            "입력 : 공부하기 싫어요\n",
            "출력 : 잠시 쉬어도 돼요 . \n",
            "입력 : 저녁은 드셨나요?\n",
            "출력 : 나중에 후회할 수도 있을 것 같아요 . \n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('안녕하세요 . ',\n",
              " '현재를 즐기세요 ! ',\n",
              " '제가 있잖아요 . ',\n",
              " '안 좋은일이 있었나봐요 . ',\n",
              " '뭐 좀 챙겨드세요 . ',\n",
              " '고생 많았어요 . ',\n",
              " '잠시 쉬어도 돼요 . ',\n",
              " '나중에 후회할 수도 있을 것 같아요 . ')"
            ]
          },
          "metadata": {},
          "execution_count": 87
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 6.3.4. 멀티 헤드 갯수 줄여보기(1)"
      ],
      "metadata": {
        "id": "QTesIj0sGFNi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "NUM_HEAD \n",
        "\n",
        ": 32 -> 4\n"
      ],
      "metadata": {
        "id": "qa-IjepyGFNj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tf.keras.backend.clear_session()\n",
        "\n",
        "NUM_LAYERS = 2 # 인코더와 디코더의 층의 개수\n",
        "D_MODEL = 256 # 인코더와 디코더 내부의 입, 출력의 고정 차원\n",
        "NUM_HEADS = 4 # 멀티 헤드 어텐션에서의 헤드 수 \n",
        "UNITS = 512 # 피드 포워드 신경망의 은닉층의 크기\n",
        "DROPOUT = 0.1 # 드롭아웃의 비율\n",
        "\n",
        "model = transformer(\n",
        "    vocab_size=VOCAB_SIZE,\n",
        "    num_layers=NUM_LAYERS,\n",
        "    units=UNITS,\n",
        "    d_model=D_MODEL,\n",
        "    num_heads=NUM_HEADS,\n",
        "    dropout=DROPOUT)\n",
        "\n",
        "model.summary()\n",
        "\n",
        "# 컴파일\n",
        "learning_rate = CustomSchedule(D_MODEL)\n",
        "\n",
        "optimizer = tf.keras.optimizers.Adam(\n",
        "    learning_rate, beta_1=0.9, beta_2=0.98, epsilon=1e-9)\n",
        "\n",
        "def accuracy(y_true, y_pred):\n",
        "  y_true = tf.reshape(y_true, shape=(-1, MAX_LENGTH - 1))\n",
        "  return tf.keras.metrics.sparse_categorical_accuracy(y_true, y_pred)\n",
        "\n",
        "model.compile(optimizer=optimizer, loss=loss_function, metrics=[accuracy])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "09fd1c9e-296a-4283-bb07-fcc686039da7",
        "id": "bcVm5cTuGFNj"
      },
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"transformer\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " inputs (InputLayer)            [(None, None)]       0           []                               \n",
            "                                                                                                  \n",
            " dec_inputs (InputLayer)        [(None, None)]       0           []                               \n",
            "                                                                                                  \n",
            " enc_padding_mask (Lambda)      (None, 1, 1, None)   0           ['inputs[0][0]']                 \n",
            "                                                                                                  \n",
            " encoder (Functional)           (None, None, 256)    3634432     ['inputs[0][0]',                 \n",
            "                                                                  'enc_padding_mask[0][0]']       \n",
            "                                                                                                  \n",
            " look_ahead_mask (Lambda)       (None, 1, None, Non  0           ['dec_inputs[0][0]']             \n",
            "                                e)                                                                \n",
            "                                                                                                  \n",
            " dec_padding_mask (Lambda)      (None, 1, 1, None)   0           ['inputs[0][0]']                 \n",
            "                                                                                                  \n",
            " decoder (Functional)           (None, None, 256)    4161792     ['dec_inputs[0][0]',             \n",
            "                                                                  'encoder[0][0]',                \n",
            "                                                                  'look_ahead_mask[0][0]',        \n",
            "                                                                  'dec_padding_mask[0][0]']       \n",
            "                                                                                                  \n",
            " outputs (Dense)                (None, None, 10079)  2590303     ['decoder[0][0]']                \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 10,386,527\n",
            "Trainable params: 10,386,527\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- 학습"
      ],
      "metadata": {
        "id": "Bxd_n1E2GFNj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "EPOCHS = 20\n",
        "model.fit(dataset, epochs=EPOCHS, verbose=1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "de2579f7-14b9-4e72-d089-3e65f505ef2f",
        "id": "MFjF5EBKGFNj"
      },
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "263/263 [==============================] - 11s 22ms/step - loss: 5.6973 - accuracy: 0.1395\n",
            "Epoch 2/20\n",
            "263/263 [==============================] - 6s 22ms/step - loss: 4.1159 - accuracy: 0.2412\n",
            "Epoch 3/20\n",
            "263/263 [==============================] - 6s 22ms/step - loss: 3.5876 - accuracy: 0.2498\n",
            "Epoch 4/20\n",
            "263/263 [==============================] - 6s 22ms/step - loss: 3.3029 - accuracy: 0.2639\n",
            "Epoch 5/20\n",
            "263/263 [==============================] - 6s 22ms/step - loss: 3.0140 - accuracy: 0.2865\n",
            "Epoch 6/20\n",
            "263/263 [==============================] - 6s 22ms/step - loss: 2.6880 - accuracy: 0.3216\n",
            "Epoch 7/20\n",
            "263/263 [==============================] - 6s 22ms/step - loss: 2.3267 - accuracy: 0.3657\n",
            "Epoch 8/20\n",
            "263/263 [==============================] - 6s 22ms/step - loss: 1.9337 - accuracy: 0.4121\n",
            "Epoch 9/20\n",
            "263/263 [==============================] - 6s 22ms/step - loss: 1.5487 - accuracy: 0.4577\n",
            "Epoch 10/20\n",
            "263/263 [==============================] - 6s 22ms/step - loss: 1.1965 - accuracy: 0.5007\n",
            "Epoch 11/20\n",
            "263/263 [==============================] - 6s 22ms/step - loss: 0.8955 - accuracy: 0.5433\n",
            "Epoch 12/20\n",
            "263/263 [==============================] - 6s 22ms/step - loss: 0.6598 - accuracy: 0.5804\n",
            "Epoch 13/20\n",
            "263/263 [==============================] - 6s 22ms/step - loss: 0.4893 - accuracy: 0.6084\n",
            "Epoch 14/20\n",
            "263/263 [==============================] - 6s 22ms/step - loss: 0.3800 - accuracy: 0.6260\n",
            "Epoch 15/20\n",
            "263/263 [==============================] - 6s 22ms/step - loss: 0.3196 - accuracy: 0.6370\n",
            "Epoch 16/20\n",
            "263/263 [==============================] - 6s 22ms/step - loss: 0.2683 - accuracy: 0.6467\n",
            "Epoch 17/20\n",
            "263/263 [==============================] - 6s 22ms/step - loss: 0.2141 - accuracy: 0.6592\n",
            "Epoch 18/20\n",
            "263/263 [==============================] - 6s 22ms/step - loss: 0.1735 - accuracy: 0.6678\n",
            "Epoch 19/20\n",
            "263/263 [==============================] - 6s 22ms/step - loss: 0.1496 - accuracy: 0.6725\n",
            "Epoch 20/20\n",
            "263/263 [==============================] - 6s 22ms/step - loss: 0.1248 - accuracy: 0.6789\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7ff7cdc1f650>"
            ]
          },
          "metadata": {},
          "execution_count": 89
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sentence_generation('요즘 컨디션이 별로야')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "outputId": "9e6dbdc7-e32d-4a4d-8e9a-b62fa26b0ab2",
        "id": "otW0H1qoGFNj"
      },
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "입력 : 요즘 컨디션이 별로야\n",
            "출력 : 마음에 드는걸로 하세요 . \n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'마음에 드는걸로 하세요 . '"
            ]
          },
          "metadata": {},
          "execution_count": 90
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sentence_generation('어떻게 생각할까?')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "outputId": "486f495f-119a-437a-921b-70366b5e7558",
        "id": "melfG7bYGFNj"
      },
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "입력 : 어떻게 생각할까?\n",
            "출력 : 아직은 실감이 나지 않을 거예요 . \n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'아직은 실감이 나지 않을 거예요 . '"
            ]
          },
          "metadata": {},
          "execution_count": 91
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sentence_generation('오늘 너무 피곤하다')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "outputId": "a9b357fd-a5d9-4b77-ea38-166f54184c31",
        "id": "NufqI8PXGFNj"
      },
      "execution_count": 92,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "입력 : 오늘 너무 피곤하다\n",
            "출력 : 아무래도 덜 경쟁하겠죠 . \n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'아무래도 덜 경쟁하겠죠 . '"
            ]
          },
          "metadata": {},
          "execution_count": 92
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sentence_generation('안녕하세요'), sentence_generation('반가워요!'), sentence_generation('재밌는 경기입니다.'), sentence_generation('너무 화가나요'), sentence_generation('배고파요'), sentence_generation('지쳤어요'), sentence_generation('공부하기 싫어요'), sentence_generation('저녁은 드셨나요?')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9344a81c-200a-4579-fbcd-99b55cd3c9a0",
        "id": "xKw3vDq5GFNj"
      },
      "execution_count": 93,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "입력 : 안녕하세요\n",
            "출력 : 안녕하세요 . \n",
            "입력 : 반가워요!\n",
            "출력 : 맛있겠네요 . \n",
            "입력 : 재밌는 경기입니다.\n",
            "출력 : 제가 있잖아요 . \n",
            "입력 : 너무 화가나요\n",
            "출력 : 그럴수록 당신이 힘들 거예요 . \n",
            "입력 : 배고파요\n",
            "출력 : 디져트 드세요 . \n",
            "입력 : 지쳤어요\n",
            "출력 : 지칠 때는 쉬어도 돼요 . \n",
            "입력 : 공부하기 싫어요\n",
            "출력 : 저는 성이 없어요 . \n",
            "입력 : 저녁은 드셨나요?\n",
            "출력 : 맛있는 거 드세요 . \n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('안녕하세요 . ',\n",
              " '맛있겠네요 . ',\n",
              " '제가 있잖아요 . ',\n",
              " '그럴수록 당신이 힘들 거예요 . ',\n",
              " '디져트 드세요 . ',\n",
              " '지칠 때는 쉬어도 돼요 . ',\n",
              " '저는 성이 없어요 . ',\n",
              " '맛있는 거 드세요 . ')"
            ]
          },
          "metadata": {},
          "execution_count": 93
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 6.3.5. 멀티 헤드 갯수 줄여보기(2)"
      ],
      "metadata": {
        "id": "BaOKodXNGFNk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "NUM_HEAD \n",
        "\n",
        ": 4 -> 2\n"
      ],
      "metadata": {
        "id": "PTrbGxL2GFNk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tf.keras.backend.clear_session()\n",
        "\n",
        "NUM_LAYERS = 2 # 인코더와 디코더의 층의 개수\n",
        "D_MODEL = 256 # 인코더와 디코더 내부의 입, 출력의 고정 차원\n",
        "NUM_HEADS = 2 # 멀티 헤드 어텐션에서의 헤드 수 \n",
        "UNITS = 512 # 피드 포워드 신경망의 은닉층의 크기\n",
        "DROPOUT = 0.1 # 드롭아웃의 비율\n",
        "\n",
        "model = transformer(\n",
        "    vocab_size=VOCAB_SIZE,\n",
        "    num_layers=NUM_LAYERS,\n",
        "    units=UNITS,\n",
        "    d_model=D_MODEL,\n",
        "    num_heads=NUM_HEADS,\n",
        "    dropout=DROPOUT)\n",
        "\n",
        "model.summary()\n",
        "\n",
        "# 컴파일\n",
        "learning_rate = CustomSchedule(D_MODEL)\n",
        "\n",
        "optimizer = tf.keras.optimizers.Adam(\n",
        "    learning_rate, beta_1=0.9, beta_2=0.98, epsilon=1e-9)\n",
        "\n",
        "def accuracy(y_true, y_pred):\n",
        "  y_true = tf.reshape(y_true, shape=(-1, MAX_LENGTH - 1))\n",
        "  return tf.keras.metrics.sparse_categorical_accuracy(y_true, y_pred)\n",
        "\n",
        "model.compile(optimizer=optimizer, loss=loss_function, metrics=[accuracy])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "89a0c1d3-cf04-40b1-93ec-52c6f6d7c151",
        "id": "632gyEvLGFNk"
      },
      "execution_count": 94,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"transformer\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " inputs (InputLayer)            [(None, None)]       0           []                               \n",
            "                                                                                                  \n",
            " dec_inputs (InputLayer)        [(None, None)]       0           []                               \n",
            "                                                                                                  \n",
            " enc_padding_mask (Lambda)      (None, 1, 1, None)   0           ['inputs[0][0]']                 \n",
            "                                                                                                  \n",
            " encoder (Functional)           (None, None, 256)    3634432     ['inputs[0][0]',                 \n",
            "                                                                  'enc_padding_mask[0][0]']       \n",
            "                                                                                                  \n",
            " look_ahead_mask (Lambda)       (None, 1, None, Non  0           ['dec_inputs[0][0]']             \n",
            "                                e)                                                                \n",
            "                                                                                                  \n",
            " dec_padding_mask (Lambda)      (None, 1, 1, None)   0           ['inputs[0][0]']                 \n",
            "                                                                                                  \n",
            " decoder (Functional)           (None, None, 256)    4161792     ['dec_inputs[0][0]',             \n",
            "                                                                  'encoder[0][0]',                \n",
            "                                                                  'look_ahead_mask[0][0]',        \n",
            "                                                                  'dec_padding_mask[0][0]']       \n",
            "                                                                                                  \n",
            " outputs (Dense)                (None, None, 10079)  2590303     ['decoder[0][0]']                \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 10,386,527\n",
            "Trainable params: 10,386,527\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- 학습"
      ],
      "metadata": {
        "id": "6n90N2KfGFNk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "EPOCHS = 20\n",
        "model.fit(dataset, epochs=EPOCHS, verbose=1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c6951a6d-564a-4c88-e246-9e210be18ea0",
        "id": "TbKQH0EBGFNk"
      },
      "execution_count": 95,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "263/263 [==============================] - 11s 22ms/step - loss: 5.6568 - accuracy: 0.1679\n",
            "Epoch 2/20\n",
            "263/263 [==============================] - 6s 22ms/step - loss: 4.0896 - accuracy: 0.2419\n",
            "Epoch 3/20\n",
            "263/263 [==============================] - 6s 22ms/step - loss: 3.5872 - accuracy: 0.2489\n",
            "Epoch 4/20\n",
            "263/263 [==============================] - 6s 22ms/step - loss: 3.3149 - accuracy: 0.2640\n",
            "Epoch 5/20\n",
            "263/263 [==============================] - 6s 22ms/step - loss: 3.0378 - accuracy: 0.2840\n",
            "Epoch 6/20\n",
            "263/263 [==============================] - 6s 22ms/step - loss: 2.7142 - accuracy: 0.3173\n",
            "Epoch 7/20\n",
            "263/263 [==============================] - 6s 22ms/step - loss: 2.3516 - accuracy: 0.3605\n",
            "Epoch 8/20\n",
            "263/263 [==============================] - 6s 22ms/step - loss: 1.9596 - accuracy: 0.4070\n",
            "Epoch 9/20\n",
            "263/263 [==============================] - 6s 22ms/step - loss: 1.5658 - accuracy: 0.4531\n",
            "Epoch 10/20\n",
            "263/263 [==============================] - 6s 22ms/step - loss: 1.2103 - accuracy: 0.4986\n",
            "Epoch 11/20\n",
            "263/263 [==============================] - 6s 22ms/step - loss: 0.9080 - accuracy: 0.5410\n",
            "Epoch 12/20\n",
            "263/263 [==============================] - 6s 22ms/step - loss: 0.6732 - accuracy: 0.5756\n",
            "Epoch 13/20\n",
            "263/263 [==============================] - 6s 22ms/step - loss: 0.5115 - accuracy: 0.6028\n",
            "Epoch 14/20\n",
            "263/263 [==============================] - 6s 22ms/step - loss: 0.4002 - accuracy: 0.6215\n",
            "Epoch 15/20\n",
            "263/263 [==============================] - 6s 22ms/step - loss: 0.3283 - accuracy: 0.6349\n",
            "Epoch 16/20\n",
            "263/263 [==============================] - 6s 22ms/step - loss: 0.2864 - accuracy: 0.6435\n",
            "Epoch 17/20\n",
            "263/263 [==============================] - 6s 22ms/step - loss: 0.2334 - accuracy: 0.6544\n",
            "Epoch 18/20\n",
            "263/263 [==============================] - 6s 22ms/step - loss: 0.1891 - accuracy: 0.6634\n",
            "Epoch 19/20\n",
            "263/263 [==============================] - 6s 22ms/step - loss: 0.1579 - accuracy: 0.6709\n",
            "Epoch 20/20\n",
            "263/263 [==============================] - 6s 22ms/step - loss: 0.1410 - accuracy: 0.6747\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7ff7cb9d1510>"
            ]
          },
          "metadata": {},
          "execution_count": 95
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sentence_generation('요즘 컨디션이 별로야')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "outputId": "2b6a8106-99a4-4e01-b13b-8f5829b7fcbe",
        "id": "GzJZMsjBGFNk"
      },
      "execution_count": 96,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "입력 : 요즘 컨디션이 별로야\n",
            "출력 : 공부 좋죠 . \n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'공부 좋죠 . '"
            ]
          },
          "metadata": {},
          "execution_count": 96
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sentence_generation('어떻게 생각할까?')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "outputId": "0f79c4d8-20f2-4a84-fbe8-5b62d3c36646",
        "id": "MPUnHgacGFNk"
      },
      "execution_count": 97,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "입력 : 어떻게 생각할까?\n",
            "출력 : 글쎄요 . \n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'글쎄요 . '"
            ]
          },
          "metadata": {},
          "execution_count": 97
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sentence_generation('오늘 너무 피곤하다')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "outputId": "864f25f2-72fc-4dc1-fea6-0ef703db3af3",
        "id": "GSXhhC8oGFNl"
      },
      "execution_count": 98,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "입력 : 오늘 너무 피곤하다\n",
            "출력 : 아무래도 사생활이 적으니까요 . \n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'아무래도 사생활이 적으니까요 . '"
            ]
          },
          "metadata": {},
          "execution_count": 98
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sentence_generation('안녕하세요'), sentence_generation('반가워요!'), sentence_generation('재밌는 경기입니다.'), sentence_generation('너무 화가나요'), sentence_generation('배고파요'), sentence_generation('지쳤어요'), sentence_generation('공부하기 싫어요'), sentence_generation('저녁은 드셨나요?')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7d9549dc-9dbb-4186-d1eb-274abf25a41a",
        "id": "nMy2J-rBGFNl"
      },
      "execution_count": 99,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "입력 : 안녕하세요\n",
            "출력 : 안녕하세요 . \n",
            "입력 : 반가워요!\n",
            "출력 : 반갑습니다 . \n",
            "입력 : 재밌는 경기입니다.\n",
            "출력 : 제가 있잖아요 . \n",
            "입력 : 너무 화가나요\n",
            "출력 : 안 좋은 회사네요 . \n",
            "입력 : 배고파요\n",
            "출력 : 얼른 뭐라도 드세요 . \n",
            "입력 : 지쳤어요\n",
            "출력 : 고생 많았어요 . \n",
            "입력 : 공부하기 싫어요\n",
            "출력 : 그러는 편이 미련이 덜 상처겠지요 . \n",
            "입력 : 저녁은 드셨나요?\n",
            "출력 : 맛있는 거 드세요 . \n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('안녕하세요 . ',\n",
              " '반갑습니다 . ',\n",
              " '제가 있잖아요 . ',\n",
              " '안 좋은 회사네요 . ',\n",
              " '얼른 뭐라도 드세요 . ',\n",
              " '고생 많았어요 . ',\n",
              " '그러는 편이 미련이 덜 상처겠지요 . ',\n",
              " '맛있는 거 드세요 . ')"
            ]
          },
          "metadata": {},
          "execution_count": 99
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 6.3.6. 멀티 헤드 갯수 줄여보기(3)"
      ],
      "metadata": {
        "id": "rrw79TpDGFNl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "NUM_HEAD \n",
        "\n",
        ": 2 -> 1"
      ],
      "metadata": {
        "id": "vyPIOj53GFNl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tf.keras.backend.clear_session()\n",
        "\n",
        "NUM_LAYERS = 2 # 인코더와 디코더의 층의 개수\n",
        "D_MODEL = 256 # 인코더와 디코더 내부의 입, 출력의 고정 차원\n",
        "NUM_HEADS = 1 # 멀티 헤드 어텐션에서의 헤드 수 \n",
        "UNITS = 512 # 피드 포워드 신경망의 은닉층의 크기\n",
        "DROPOUT = 0.1 # 드롭아웃의 비율\n",
        "\n",
        "model = transformer(\n",
        "    vocab_size=VOCAB_SIZE,\n",
        "    num_layers=NUM_LAYERS,\n",
        "    units=UNITS,\n",
        "    d_model=D_MODEL,\n",
        "    num_heads=NUM_HEADS,\n",
        "    dropout=DROPOUT)\n",
        "\n",
        "model.summary()\n",
        "\n",
        "# 컴파일\n",
        "learning_rate = CustomSchedule(D_MODEL)\n",
        "\n",
        "optimizer = tf.keras.optimizers.Adam(\n",
        "    learning_rate, beta_1=0.9, beta_2=0.98, epsilon=1e-9)\n",
        "\n",
        "def accuracy(y_true, y_pred):\n",
        "  y_true = tf.reshape(y_true, shape=(-1, MAX_LENGTH - 1))\n",
        "  return tf.keras.metrics.sparse_categorical_accuracy(y_true, y_pred)\n",
        "\n",
        "model.compile(optimizer=optimizer, loss=loss_function, metrics=[accuracy])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b9adeed4-4b84-403a-d0bf-d7f15e55dbba",
        "id": "2TAncRrWGFNl"
      },
      "execution_count": 100,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"transformer\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " inputs (InputLayer)            [(None, None)]       0           []                               \n",
            "                                                                                                  \n",
            " dec_inputs (InputLayer)        [(None, None)]       0           []                               \n",
            "                                                                                                  \n",
            " enc_padding_mask (Lambda)      (None, 1, 1, None)   0           ['inputs[0][0]']                 \n",
            "                                                                                                  \n",
            " encoder (Functional)           (None, None, 256)    3634432     ['inputs[0][0]',                 \n",
            "                                                                  'enc_padding_mask[0][0]']       \n",
            "                                                                                                  \n",
            " look_ahead_mask (Lambda)       (None, 1, None, Non  0           ['dec_inputs[0][0]']             \n",
            "                                e)                                                                \n",
            "                                                                                                  \n",
            " dec_padding_mask (Lambda)      (None, 1, 1, None)   0           ['inputs[0][0]']                 \n",
            "                                                                                                  \n",
            " decoder (Functional)           (None, None, 256)    4161792     ['dec_inputs[0][0]',             \n",
            "                                                                  'encoder[0][0]',                \n",
            "                                                                  'look_ahead_mask[0][0]',        \n",
            "                                                                  'dec_padding_mask[0][0]']       \n",
            "                                                                                                  \n",
            " outputs (Dense)                (None, None, 10079)  2590303     ['decoder[0][0]']                \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 10,386,527\n",
            "Trainable params: 10,386,527\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- 학습"
      ],
      "metadata": {
        "id": "TFbhz24MGFNl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "EPOCHS = 20\n",
        "model.fit(dataset, epochs=EPOCHS, verbose=1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "55251c3f-9b2a-41d9-fc87-a71888de0e93",
        "id": "dpTwRoOeGFNl"
      },
      "execution_count": 101,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "263/263 [==============================] - 12s 21ms/step - loss: 5.6673 - accuracy: 0.1860\n",
            "Epoch 2/20\n",
            "263/263 [==============================] - 6s 21ms/step - loss: 4.1050 - accuracy: 0.2413\n",
            "Epoch 3/20\n",
            "263/263 [==============================] - 6s 21ms/step - loss: 3.5999 - accuracy: 0.2486\n",
            "Epoch 4/20\n",
            "263/263 [==============================] - 6s 21ms/step - loss: 3.3227 - accuracy: 0.2624\n",
            "Epoch 5/20\n",
            "263/263 [==============================] - 6s 21ms/step - loss: 3.0343 - accuracy: 0.2842\n",
            "Epoch 6/20\n",
            "263/263 [==============================] - 6s 21ms/step - loss: 2.7148 - accuracy: 0.3184\n",
            "Epoch 7/20\n",
            "263/263 [==============================] - 6s 21ms/step - loss: 2.3663 - accuracy: 0.3601\n",
            "Epoch 8/20\n",
            "263/263 [==============================] - 6s 21ms/step - loss: 1.9841 - accuracy: 0.4051\n",
            "Epoch 9/20\n",
            "263/263 [==============================] - 6s 21ms/step - loss: 1.6051 - accuracy: 0.4487\n",
            "Epoch 10/20\n",
            "263/263 [==============================] - 6s 21ms/step - loss: 1.2630 - accuracy: 0.4895\n",
            "Epoch 11/20\n",
            "263/263 [==============================] - 6s 22ms/step - loss: 0.9755 - accuracy: 0.5262\n",
            "Epoch 12/20\n",
            "263/263 [==============================] - 6s 21ms/step - loss: 0.7523 - accuracy: 0.5605\n",
            "Epoch 13/20\n",
            "263/263 [==============================] - 6s 21ms/step - loss: 0.5886 - accuracy: 0.5873\n",
            "Epoch 14/20\n",
            "263/263 [==============================] - 6s 21ms/step - loss: 0.4724 - accuracy: 0.6058\n",
            "Epoch 15/20\n",
            "263/263 [==============================] - 6s 21ms/step - loss: 0.4010 - accuracy: 0.6170\n",
            "Epoch 16/20\n",
            "263/263 [==============================] - 6s 21ms/step - loss: 0.3452 - accuracy: 0.6283\n",
            "Epoch 17/20\n",
            "263/263 [==============================] - 6s 21ms/step - loss: 0.2882 - accuracy: 0.6395\n",
            "Epoch 18/20\n",
            "263/263 [==============================] - 6s 21ms/step - loss: 0.2316 - accuracy: 0.6541\n",
            "Epoch 19/20\n",
            "263/263 [==============================] - 6s 21ms/step - loss: 0.1925 - accuracy: 0.6622\n",
            "Epoch 20/20\n",
            "263/263 [==============================] - 6s 21ms/step - loss: 0.1694 - accuracy: 0.6668\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7ff7cd5f3610>"
            ]
          },
          "metadata": {},
          "execution_count": 101
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sentence_generation('요즘 컨디션이 별로야')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "outputId": "a99373b7-e095-4313-9a59-582725e72054",
        "id": "iIwC3RS9GFNm"
      },
      "execution_count": 102,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "입력 : 요즘 컨디션이 별로야\n",
            "출력 : 살짝 뒤돌아봐도 괜찮아요 . \n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'살짝 뒤돌아봐도 괜찮아요 . '"
            ]
          },
          "metadata": {},
          "execution_count": 102
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sentence_generation('어떻게 생각할까?')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "outputId": "a7b7af2b-4065-4f3b-bf20-8ceb4d06e56b",
        "id": "nHaWhC86GFNm"
      },
      "execution_count": 103,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "입력 : 어떻게 생각할까?\n",
            "출력 : 아직은 잘 모르겠어요 . \n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'아직은 잘 모르겠어요 . '"
            ]
          },
          "metadata": {},
          "execution_count": 103
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sentence_generation('오늘 너무 피곤하다')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "outputId": "4cbc8e87-b160-4a9a-9051-942acd175e98",
        "id": "z_UYhgJtGFNm"
      },
      "execution_count": 104,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "입력 : 오늘 너무 피곤하다\n",
            "출력 : 아무래도 사생활이 적으니까요 . \n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'아무래도 사생활이 적으니까요 . '"
            ]
          },
          "metadata": {},
          "execution_count": 104
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sentence_generation('안녕하세요'), sentence_generation('반가워요!'), sentence_generation('재밌는 경기입니다.'), sentence_generation('너무 화가나요'), sentence_generation('배고파요'), sentence_generation('지쳤어요'), sentence_generation('공부하기 싫어요'), sentence_generation('저녁은 드셨나요?')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "700b25e6-82e7-4807-d2ad-b28c60aa330e",
        "id": "vXzXyaq_GFNm"
      },
      "execution_count": 105,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "입력 : 안녕하세요\n",
            "출력 : 안녕하세요 . \n",
            "입력 : 반가워요!\n",
            "출력 : 반갑습니다 . \n",
            "입력 : 재밌는 경기입니다.\n",
            "출력 : 제가 있잖아요 . \n",
            "입력 : 너무 화가나요\n",
            "출력 : 자신을 먼저 키우세요 . \n",
            "입력 : 배고파요\n",
            "출력 : 지금도 늦지 않았어요 . \n",
            "입력 : 지쳤어요\n",
            "출력 : 잠시 차분하게 생각해봐요 . \n",
            "입력 : 공부하기 싫어요\n",
            "출력 : 만나지 마세요 . \n",
            "입력 : 저녁은 드셨나요?\n",
            "출력 : 그게 진짜 사랑이네요 . \n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('안녕하세요 . ',\n",
              " '반갑습니다 . ',\n",
              " '제가 있잖아요 . ',\n",
              " '자신을 먼저 키우세요 . ',\n",
              " '지금도 늦지 않았어요 . ',\n",
              " '잠시 차분하게 생각해봐요 . ',\n",
              " '만나지 마세요 . ',\n",
              " '그게 진짜 사랑이네요 . ')"
            ]
          },
          "metadata": {},
          "execution_count": 105
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 6.4. 하이퍼파라미터 수정 - D_MODEL : 512"
      ],
      "metadata": {
        "id": "-R0V4kzSTokw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 6.4.1. NUM_HEAD = 8"
      ],
      "metadata": {
        "id": "zpFEo2jDTokw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tf.keras.backend.clear_session()\n",
        "\n",
        "NUM_LAYERS = 2 # 인코더와 디코더의 층의 개수\n",
        "D_MODEL = 512 # 인코더와 디코더 내부의 입, 출력의 고정 차원\n",
        "NUM_HEADS = 8 # 멀티 헤드 어텐션에서의 헤드 수 \n",
        "UNITS = 512 # 피드 포워드 신경망의 은닉층의 크기\n",
        "DROPOUT = 0.1 # 드롭아웃의 비율\n",
        "\n",
        "model = transformer(\n",
        "    vocab_size=VOCAB_SIZE,\n",
        "    num_layers=NUM_LAYERS,\n",
        "    units=UNITS,\n",
        "    d_model=D_MODEL,\n",
        "    num_heads=NUM_HEADS,\n",
        "    dropout=DROPOUT)\n",
        "\n",
        "model.summary()\n",
        "\n",
        "# 컴파일\n",
        "learning_rate = CustomSchedule(D_MODEL)\n",
        "\n",
        "optimizer = tf.keras.optimizers.Adam(\n",
        "    learning_rate, beta_1=0.9, beta_2=0.98, epsilon=1e-9)\n",
        "\n",
        "def accuracy(y_true, y_pred):\n",
        "  y_true = tf.reshape(y_true, shape=(-1, MAX_LENGTH - 1))\n",
        "  return tf.keras.metrics.sparse_categorical_accuracy(y_true, y_pred)\n",
        "\n",
        "model.compile(optimizer=optimizer, loss=loss_function, metrics=[accuracy])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g2_ccCUuT39H",
        "outputId": "34252eac-7553-4448-c7bc-db16b3338c99"
      },
      "execution_count": 111,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"transformer\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " inputs (InputLayer)            [(None, None)]       0           []                               \n",
            "                                                                                                  \n",
            " dec_inputs (InputLayer)        [(None, None)]       0           []                               \n",
            "                                                                                                  \n",
            " enc_padding_mask (Lambda)      (None, 1, 1, None)   0           ['inputs[0][0]']                 \n",
            "                                                                                                  \n",
            " encoder (Functional)           (None, None, 512)    8316416     ['inputs[0][0]',                 \n",
            "                                                                  'enc_padding_mask[0][0]']       \n",
            "                                                                                                  \n",
            " look_ahead_mask (Lambda)       (None, 1, None, Non  0           ['dec_inputs[0][0]']             \n",
            "                                e)                                                                \n",
            "                                                                                                  \n",
            " dec_padding_mask (Lambda)      (None, 1, 1, None)   0           ['inputs[0][0]']                 \n",
            "                                                                                                  \n",
            " decoder (Functional)           (None, None, 512)    10419712    ['dec_inputs[0][0]',             \n",
            "                                                                  'encoder[0][0]',                \n",
            "                                                                  'look_ahead_mask[0][0]',        \n",
            "                                                                  'dec_padding_mask[0][0]']       \n",
            "                                                                                                  \n",
            " outputs (Dense)                (None, None, 10079)  5170527     ['decoder[0][0]']                \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 23,906,655\n",
            "Trainable params: 23,906,655\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "EPOCHS = 20\n",
        "model.fit(dataset, epochs=EPOCHS, verbose=1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vzNvl4sPUXKE",
        "outputId": "ee009edf-3fa5-4ca1-94a2-5fe4c49f864a"
      },
      "execution_count": 112,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "263/263 [==============================] - 12s 25ms/step - loss: 5.1298 - accuracy: 0.1891\n",
            "Epoch 2/20\n",
            "263/263 [==============================] - 7s 25ms/step - loss: 3.8100 - accuracy: 0.2436\n",
            "Epoch 3/20\n",
            "263/263 [==============================] - 7s 25ms/step - loss: 3.4537 - accuracy: 0.2577\n",
            "Epoch 4/20\n",
            "263/263 [==============================] - 8s 31ms/step - loss: 3.1249 - accuracy: 0.2788\n",
            "Epoch 5/20\n",
            "263/263 [==============================] - 7s 25ms/step - loss: 2.7580 - accuracy: 0.3152\n",
            "Epoch 6/20\n",
            "263/263 [==============================] - 7s 26ms/step - loss: 2.3456 - accuracy: 0.3664\n",
            "Epoch 7/20\n",
            "263/263 [==============================] - 10s 37ms/step - loss: 1.8905 - accuracy: 0.4223\n",
            "Epoch 8/20\n",
            "263/263 [==============================] - 8s 32ms/step - loss: 1.4378 - accuracy: 0.4800\n",
            "Epoch 9/20\n",
            "263/263 [==============================] - 9s 36ms/step - loss: 1.0361 - accuracy: 0.5349\n",
            "Epoch 10/20\n",
            "263/263 [==============================] - 11s 40ms/step - loss: 0.7073 - accuracy: 0.5845\n",
            "Epoch 11/20\n",
            "263/263 [==============================] - 7s 25ms/step - loss: 0.4749 - accuracy: 0.6224\n",
            "Epoch 12/20\n",
            "263/263 [==============================] - 7s 25ms/step - loss: 0.3299 - accuracy: 0.6452\n",
            "Epoch 13/20\n",
            "263/263 [==============================] - 7s 25ms/step - loss: 0.2532 - accuracy: 0.6587\n",
            "Epoch 14/20\n",
            "263/263 [==============================] - 10s 38ms/step - loss: 0.2219 - accuracy: 0.6618\n",
            "Epoch 15/20\n",
            "263/263 [==============================] - 8s 32ms/step - loss: 0.2090 - accuracy: 0.6626\n",
            "Epoch 16/20\n",
            "263/263 [==============================] - 7s 25ms/step - loss: 0.1934 - accuracy: 0.6641\n",
            "Epoch 17/20\n",
            "263/263 [==============================] - 7s 25ms/step - loss: 0.1685 - accuracy: 0.6692\n",
            "Epoch 18/20\n",
            "263/263 [==============================] - 7s 26ms/step - loss: 0.1424 - accuracy: 0.6750\n",
            "Epoch 19/20\n",
            "263/263 [==============================] - 7s 25ms/step - loss: 0.1237 - accuracy: 0.6806\n",
            "Epoch 20/20\n",
            "263/263 [==============================] - 7s 25ms/step - loss: 0.1073 - accuracy: 0.6833\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7ff7ca387e50>"
            ]
          },
          "metadata": {},
          "execution_count": 112
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sentence_generation('요즘 컨디션이 별로야')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "outputId": "393e24c3-13d5-41fd-9a0b-9abb01a95e1a",
        "id": "ijQ3nA_FTokw"
      },
      "execution_count": 113,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "입력 : 요즘 컨디션이 별로야\n",
            "출력 : 잘할 수 있을 거예요 . \n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'잘할 수 있을 거예요 . '"
            ]
          },
          "metadata": {},
          "execution_count": 113
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sentence_generation('어떻게 생각할까?')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "outputId": "af4bc820-86d5-4977-92a6-e5fc5b259b57",
        "id": "xxoXAyplTokw"
      },
      "execution_count": 114,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "입력 : 어떻게 생각할까?\n",
            "출력 : 미련갖지 마세요 . \n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'미련갖지 마세요 . '"
            ]
          },
          "metadata": {},
          "execution_count": 114
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sentence_generation('오늘 너무 피곤하다')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "outputId": "7c184fd3-aa09-4044-a5a1-8e4e02cd50d7",
        "id": "jK6r1-1qTokx"
      },
      "execution_count": 115,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "입력 : 오늘 너무 피곤하다\n",
            "출력 : 계속 앉아있지 마세요 . \n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'계속 앉아있지 마세요 . '"
            ]
          },
          "metadata": {},
          "execution_count": 115
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sentence_generation('안녕하세요'), sentence_generation('반가워요!'), sentence_generation('재밌는 경기입니다.'), sentence_generation('너무 화가나요'), sentence_generation('배고파요'), sentence_generation('지쳤어요'), sentence_generation('공부하기 싫어요'), sentence_generation('저녁은 드셨나요?')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a595aa31-5fa1-4154-f96b-16605cc35656",
        "id": "0kDD7lopTokx"
      },
      "execution_count": 116,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "입력 : 안녕하세요\n",
            "출력 : 안녕하세요 . \n",
            "입력 : 반가워요!\n",
            "출력 : 반갑습니다 . \n",
            "입력 : 재밌는 경기입니다.\n",
            "출력 : 제가 있잖아요 . \n",
            "입력 : 너무 화가나요\n",
            "출력 : 안 좋은일이 있었나봐요 . \n",
            "입력 : 배고파요\n",
            "출력 : 좀 더 드세요 . \n",
            "입력 : 지쳤어요\n",
            "출력 : 제 얼굴 보셨나봐요 . \n",
            "입력 : 공부하기 싫어요\n",
            "출력 : 구속되기 쉽지 않을 거예요 . \n",
            "입력 : 저녁은 드셨나요?\n",
            "출력 : 냉장고 파먹기 해보세요 . \n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('안녕하세요 . ',\n",
              " '반갑습니다 . ',\n",
              " '제가 있잖아요 . ',\n",
              " '안 좋은일이 있었나봐요 . ',\n",
              " '좀 더 드세요 . ',\n",
              " '제 얼굴 보셨나봐요 . ',\n",
              " '구속되기 쉽지 않을 거예요 . ',\n",
              " '냉장고 파먹기 해보세요 . ')"
            ]
          },
          "metadata": {},
          "execution_count": 116
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 6.4.2. NUM_HEAD = 16"
      ],
      "metadata": {
        "id": "DQoJ9SI8Tokx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "NUM_HEAD \n",
        "\n",
        ": 8 -> 16\n"
      ],
      "metadata": {
        "id": "g8Y-3V5YTokx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tf.keras.backend.clear_session()\n",
        "\n",
        "NUM_LAYERS = 2 # 인코더와 디코더의 층의 개수\n",
        "D_MODEL = 512 # 인코더와 디코더 내부의 입, 출력의 고정 차원\n",
        "NUM_HEADS = 16 # 멀티 헤드 어텐션에서의 헤드 수 \n",
        "UNITS = 512 # 피드 포워드 신경망의 은닉층의 크기\n",
        "DROPOUT = 0.1 # 드롭아웃의 비율\n",
        "\n",
        "model = transformer(\n",
        "    vocab_size=VOCAB_SIZE,\n",
        "    num_layers=NUM_LAYERS,\n",
        "    units=UNITS,\n",
        "    d_model=D_MODEL,\n",
        "    num_heads=NUM_HEADS,\n",
        "    dropout=DROPOUT)\n",
        "\n",
        "model.summary()\n",
        "\n",
        "# 컴파일\n",
        "learning_rate = CustomSchedule(D_MODEL)\n",
        "\n",
        "optimizer = tf.keras.optimizers.Adam(\n",
        "    learning_rate, beta_1=0.9, beta_2=0.98, epsilon=1e-9)\n",
        "\n",
        "def accuracy(y_true, y_pred):\n",
        "  y_true = tf.reshape(y_true, shape=(-1, MAX_LENGTH - 1))\n",
        "  return tf.keras.metrics.sparse_categorical_accuracy(y_true, y_pred)\n",
        "\n",
        "model.compile(optimizer=optimizer, loss=loss_function, metrics=[accuracy])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ff74b580-358a-4995-ca2e-3530664c4f6b",
        "id": "UEJbStVfTokx"
      },
      "execution_count": 117,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"transformer\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " inputs (InputLayer)            [(None, None)]       0           []                               \n",
            "                                                                                                  \n",
            " dec_inputs (InputLayer)        [(None, None)]       0           []                               \n",
            "                                                                                                  \n",
            " enc_padding_mask (Lambda)      (None, 1, 1, None)   0           ['inputs[0][0]']                 \n",
            "                                                                                                  \n",
            " encoder (Functional)           (None, None, 512)    8316416     ['inputs[0][0]',                 \n",
            "                                                                  'enc_padding_mask[0][0]']       \n",
            "                                                                                                  \n",
            " look_ahead_mask (Lambda)       (None, 1, None, Non  0           ['dec_inputs[0][0]']             \n",
            "                                e)                                                                \n",
            "                                                                                                  \n",
            " dec_padding_mask (Lambda)      (None, 1, 1, None)   0           ['inputs[0][0]']                 \n",
            "                                                                                                  \n",
            " decoder (Functional)           (None, None, 512)    10419712    ['dec_inputs[0][0]',             \n",
            "                                                                  'encoder[0][0]',                \n",
            "                                                                  'look_ahead_mask[0][0]',        \n",
            "                                                                  'dec_padding_mask[0][0]']       \n",
            "                                                                                                  \n",
            " outputs (Dense)                (None, None, 10079)  5170527     ['decoder[0][0]']                \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 23,906,655\n",
            "Trainable params: 23,906,655\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- 학습"
      ],
      "metadata": {
        "id": "GoZSgWLlTokx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "EPOCHS = 20\n",
        "model.fit(dataset, epochs=EPOCHS, verbose=1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a4a878ad-b8e0-4b1c-ad40-8327f268de28",
        "id": "sJi8VR9gTokx"
      },
      "execution_count": 118,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "263/263 [==============================] - 13s 26ms/step - loss: 5.1777 - accuracy: 0.1862\n",
            "Epoch 2/20\n",
            "263/263 [==============================] - 7s 26ms/step - loss: 3.8211 - accuracy: 0.2426\n",
            "Epoch 3/20\n",
            "263/263 [==============================] - 7s 25ms/step - loss: 3.4498 - accuracy: 0.2569\n",
            "Epoch 4/20\n",
            "263/263 [==============================] - 7s 27ms/step - loss: 3.1142 - accuracy: 0.2788\n",
            "Epoch 5/20\n",
            "263/263 [==============================] - 7s 26ms/step - loss: 2.7461 - accuracy: 0.3171\n",
            "Epoch 6/20\n",
            "263/263 [==============================] - 7s 25ms/step - loss: 2.3314 - accuracy: 0.3691\n",
            "Epoch 7/20\n",
            "263/263 [==============================] - 7s 25ms/step - loss: 1.8778 - accuracy: 0.4265\n",
            "Epoch 8/20\n",
            "263/263 [==============================] - 7s 26ms/step - loss: 1.4307 - accuracy: 0.4814\n",
            "Epoch 9/20\n",
            "263/263 [==============================] - 7s 25ms/step - loss: 1.0359 - accuracy: 0.5355\n",
            "Epoch 10/20\n",
            "263/263 [==============================] - 7s 25ms/step - loss: 0.7058 - accuracy: 0.5856\n",
            "Epoch 11/20\n",
            "263/263 [==============================] - 7s 26ms/step - loss: 0.4766 - accuracy: 0.6213\n",
            "Epoch 12/20\n",
            "263/263 [==============================] - 7s 25ms/step - loss: 0.3309 - accuracy: 0.6450\n",
            "Epoch 13/20\n",
            "263/263 [==============================] - 7s 25ms/step - loss: 0.2514 - accuracy: 0.6575\n",
            "Epoch 14/20\n",
            "263/263 [==============================] - 7s 25ms/step - loss: 0.2183 - accuracy: 0.6624\n",
            "Epoch 15/20\n",
            "263/263 [==============================] - 7s 25ms/step - loss: 0.2006 - accuracy: 0.6648\n",
            "Epoch 16/20\n",
            "263/263 [==============================] - 7s 25ms/step - loss: 0.1928 - accuracy: 0.6655\n",
            "Epoch 17/20\n",
            "263/263 [==============================] - 7s 27ms/step - loss: 0.1683 - accuracy: 0.6704\n",
            "Epoch 18/20\n",
            "263/263 [==============================] - 7s 26ms/step - loss: 0.1385 - accuracy: 0.6759\n",
            "Epoch 19/20\n",
            "263/263 [==============================] - 7s 26ms/step - loss: 0.1170 - accuracy: 0.6808\n",
            "Epoch 20/20\n",
            "263/263 [==============================] - 7s 26ms/step - loss: 0.1078 - accuracy: 0.6830\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7ff798d97210>"
            ]
          },
          "metadata": {},
          "execution_count": 118
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sentence_generation('요즘 컨디션이 별로야')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "outputId": "2034c7ee-6ae6-44c1-e67b-7e2296514268",
        "id": "3eMTE0vqTokx"
      },
      "execution_count": 119,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "입력 : 요즘 컨디션이 별로야\n",
            "출력 : 사랑한 후에 좋은 추억이 남을 거예요 . \n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'사랑한 후에 좋은 추억이 남을 거예요 . '"
            ]
          },
          "metadata": {},
          "execution_count": 119
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sentence_generation('어떻게 생각할까?')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "outputId": "c32b98cb-0f34-4344-99cc-2232e31ba92d",
        "id": "M1gCOmqDTokx"
      },
      "execution_count": 120,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "입력 : 어떻게 생각할까?\n",
            "출력 : 글쎄요 . \n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'글쎄요 . '"
            ]
          },
          "metadata": {},
          "execution_count": 120
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sentence_generation('오늘 너무 피곤하다')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "outputId": "c539b63b-3b0f-4418-8c98-6c8193ca0060",
        "id": "3DQ56Fs8Toky"
      },
      "execution_count": 121,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "입력 : 오늘 너무 피곤하다\n",
            "출력 : 돈 없어도 할 수 있는게 많아요\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'돈 없어도 할 수 있는게 많아요'"
            ]
          },
          "metadata": {},
          "execution_count": 121
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sentence_generation('안녕하세요'), sentence_generation('반가워요!'), sentence_generation('재밌는 경기입니다.'), sentence_generation('너무 화가나요'), sentence_generation('배고파요'), sentence_generation('지쳤어요'), sentence_generation('공부하기 싫어요'), sentence_generation('저녁은 드셨나요?')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e3dd7fc6-b74b-4de1-aeca-adb5066ea795",
        "id": "mSAWsyXnToky"
      },
      "execution_count": 122,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "입력 : 안녕하세요\n",
            "출력 : 안녕하세요 . \n",
            "입력 : 반가워요!\n",
            "출력 : 반갑습니다 . \n",
            "입력 : 재밌는 경기입니다.\n",
            "출력 : 제가 있잖아요 . \n",
            "입력 : 너무 화가나요\n",
            "출력 : 그럴수록 당신이 힘들 거예요 . \n",
            "입력 : 배고파요\n",
            "출력 : 뭐 좀 챙겨드세요 . \n",
            "입력 : 지쳤어요\n",
            "출력 : 지친 거 티내보세요 . \n",
            "입력 : 공부하기 싫어요\n",
            "출력 : 기분마세요 . \n",
            "입력 : 저녁은 드셨나요?\n",
            "출력 : 그건 좋아하는 거 아니에요 . \n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('안녕하세요 . ',\n",
              " '반갑습니다 . ',\n",
              " '제가 있잖아요 . ',\n",
              " '그럴수록 당신이 힘들 거예요 . ',\n",
              " '뭐 좀 챙겨드세요 . ',\n",
              " '지친 거 티내보세요 . ',\n",
              " '기분마세요 . ',\n",
              " '그건 좋아하는 거 아니에요 . ')"
            ]
          },
          "metadata": {},
          "execution_count": 122
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 6.4.3. NUM_HEAD = 32"
      ],
      "metadata": {
        "id": "WAfZkwBeToky"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "NUM_HEAD \n",
        "\n",
        ": 16 -> 32\n"
      ],
      "metadata": {
        "id": "auF2fMIjToky"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tf.keras.backend.clear_session()\n",
        "\n",
        "NUM_LAYERS = 2 # 인코더와 디코더의 층의 개수\n",
        "D_MODEL = 512 # 인코더와 디코더 내부의 입, 출력의 고정 차원\n",
        "NUM_HEADS = 32 # 멀티 헤드 어텐션에서의 헤드 수 \n",
        "UNITS = 512 # 피드 포워드 신경망의 은닉층의 크기\n",
        "DROPOUT = 0.1 # 드롭아웃의 비율\n",
        "\n",
        "model = transformer(\n",
        "    vocab_size=VOCAB_SIZE,\n",
        "    num_layers=NUM_LAYERS,\n",
        "    units=UNITS,\n",
        "    d_model=D_MODEL,\n",
        "    num_heads=NUM_HEADS,\n",
        "    dropout=DROPOUT)\n",
        "\n",
        "model.summary()\n",
        "\n",
        "# 컴파일\n",
        "learning_rate = CustomSchedule(D_MODEL)\n",
        "\n",
        "optimizer = tf.keras.optimizers.Adam(\n",
        "    learning_rate, beta_1=0.9, beta_2=0.98, epsilon=1e-9)\n",
        "\n",
        "def accuracy(y_true, y_pred):\n",
        "  y_true = tf.reshape(y_true, shape=(-1, MAX_LENGTH - 1))\n",
        "  return tf.keras.metrics.sparse_categorical_accuracy(y_true, y_pred)\n",
        "\n",
        "model.compile(optimizer=optimizer, loss=loss_function, metrics=[accuracy])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ff85bec3-6dfe-4a5a-d90c-0634dd6ba820",
        "id": "GdXDK6wtToky"
      },
      "execution_count": 123,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"transformer\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " inputs (InputLayer)            [(None, None)]       0           []                               \n",
            "                                                                                                  \n",
            " dec_inputs (InputLayer)        [(None, None)]       0           []                               \n",
            "                                                                                                  \n",
            " enc_padding_mask (Lambda)      (None, 1, 1, None)   0           ['inputs[0][0]']                 \n",
            "                                                                                                  \n",
            " encoder (Functional)           (None, None, 512)    8316416     ['inputs[0][0]',                 \n",
            "                                                                  'enc_padding_mask[0][0]']       \n",
            "                                                                                                  \n",
            " look_ahead_mask (Lambda)       (None, 1, None, Non  0           ['dec_inputs[0][0]']             \n",
            "                                e)                                                                \n",
            "                                                                                                  \n",
            " dec_padding_mask (Lambda)      (None, 1, 1, None)   0           ['inputs[0][0]']                 \n",
            "                                                                                                  \n",
            " decoder (Functional)           (None, None, 512)    10419712    ['dec_inputs[0][0]',             \n",
            "                                                                  'encoder[0][0]',                \n",
            "                                                                  'look_ahead_mask[0][0]',        \n",
            "                                                                  'dec_padding_mask[0][0]']       \n",
            "                                                                                                  \n",
            " outputs (Dense)                (None, None, 10079)  5170527     ['decoder[0][0]']                \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 23,906,655\n",
            "Trainable params: 23,906,655\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- 학습"
      ],
      "metadata": {
        "id": "K6rAIn-2Toky"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "EPOCHS = 20\n",
        "model.fit(dataset, epochs=EPOCHS, verbose=1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b1f68cec-7740-4e35-9a6d-24112d73b3e8",
        "id": "AzUI3Cl4Toky"
      },
      "execution_count": 124,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "263/263 [==============================] - 13s 27ms/step - loss: 5.1856 - accuracy: 0.1783\n",
            "Epoch 2/20\n",
            "263/263 [==============================] - 7s 27ms/step - loss: 3.8148 - accuracy: 0.2435\n",
            "Epoch 3/20\n",
            "263/263 [==============================] - 7s 27ms/step - loss: 3.4408 - accuracy: 0.2581\n",
            "Epoch 4/20\n",
            "263/263 [==============================] - 7s 27ms/step - loss: 3.1070 - accuracy: 0.2797\n",
            "Epoch 5/20\n",
            "263/263 [==============================] - 7s 27ms/step - loss: 2.7370 - accuracy: 0.3166\n",
            "Epoch 6/20\n",
            "263/263 [==============================] - 7s 26ms/step - loss: 2.3215 - accuracy: 0.3692\n",
            "Epoch 7/20\n",
            "263/263 [==============================] - 7s 26ms/step - loss: 1.8660 - accuracy: 0.4269\n",
            "Epoch 8/20\n",
            "263/263 [==============================] - 7s 28ms/step - loss: 1.4187 - accuracy: 0.4855\n",
            "Epoch 9/20\n",
            "263/263 [==============================] - 7s 26ms/step - loss: 1.0165 - accuracy: 0.5403\n",
            "Epoch 10/20\n",
            "263/263 [==============================] - 7s 26ms/step - loss: 0.6958 - accuracy: 0.5882\n",
            "Epoch 11/20\n",
            "263/263 [==============================] - 7s 26ms/step - loss: 0.4690 - accuracy: 0.6234\n",
            "Epoch 12/20\n",
            "263/263 [==============================] - 7s 26ms/step - loss: 0.3240 - accuracy: 0.6478\n",
            "Epoch 13/20\n",
            "263/263 [==============================] - 7s 26ms/step - loss: 0.2514 - accuracy: 0.6582\n",
            "Epoch 14/20\n",
            "263/263 [==============================] - 7s 26ms/step - loss: 0.2153 - accuracy: 0.6619\n",
            "Epoch 15/20\n",
            "263/263 [==============================] - 7s 26ms/step - loss: 0.1986 - accuracy: 0.6658\n",
            "Epoch 16/20\n",
            "263/263 [==============================] - 7s 26ms/step - loss: 0.1889 - accuracy: 0.6662\n",
            "Epoch 17/20\n",
            "263/263 [==============================] - 7s 26ms/step - loss: 0.1619 - accuracy: 0.6713\n",
            "Epoch 18/20\n",
            "263/263 [==============================] - 7s 27ms/step - loss: 0.1399 - accuracy: 0.6760\n",
            "Epoch 19/20\n",
            "263/263 [==============================] - 7s 26ms/step - loss: 0.1189 - accuracy: 0.6808\n",
            "Epoch 20/20\n",
            "263/263 [==============================] - 7s 26ms/step - loss: 0.1035 - accuracy: 0.6843\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7ff7caab4750>"
            ]
          },
          "metadata": {},
          "execution_count": 124
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sentence_generation('요즘 컨디션이 별로야')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "outputId": "048da136-7058-419a-cef7-590ed24d862d",
        "id": "0sVzbE9-Toky"
      },
      "execution_count": 125,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "입력 : 요즘 컨디션이 별로야\n",
            "출력 : 나쁜 생각은 하지 마세요 . \n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'나쁜 생각은 하지 마세요 . '"
            ]
          },
          "metadata": {},
          "execution_count": 125
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sentence_generation('어떻게 생각할까?')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "outputId": "011a9b03-3915-419f-d27b-e203be10d680",
        "id": "yrkCjgXUToky"
      },
      "execution_count": 126,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "입력 : 어떻게 생각할까?\n",
            "출력 : 아직은 잘 모르겠어요 . \n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'아직은 잘 모르겠어요 . '"
            ]
          },
          "metadata": {},
          "execution_count": 126
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sentence_generation('오늘 너무 피곤하다')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "outputId": "f4845c33-c714-4c89-dac8-8b51764c42c4",
        "id": "JpqGJiDmTokz"
      },
      "execution_count": 127,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "입력 : 오늘 너무 피곤하다\n",
            "출력 : 아무래도 책임이 뒤따르니까요 . \n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'아무래도 책임이 뒤따르니까요 . '"
            ]
          },
          "metadata": {},
          "execution_count": 127
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sentence_generation('안녕하세요'), sentence_generation('반가워요!'), sentence_generation('재밌는 경기입니다.'), sentence_generation('너무 화가나요'), sentence_generation('배고파요'), sentence_generation('지쳤어요'), sentence_generation('공부하기 싫어요'), sentence_generation('저녁은 드셨나요?')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3b1ba67e-e2b2-458e-e9ff-4049e313ce13",
        "id": "HEoMEYoUTokz"
      },
      "execution_count": 128,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "입력 : 안녕하세요\n",
            "출력 : 안녕하세요 . \n",
            "입력 : 반가워요!\n",
            "출력 : 저한테 다 말씀하세요 . \n",
            "입력 : 재밌는 경기입니다.\n",
            "출력 : 제가 있잖아요 . \n",
            "입력 : 너무 화가나요\n",
            "출력 : 그럴수록 당신이 힘들 거예요 . \n",
            "입력 : 배고파요\n",
            "출력 : 뭐 좀 챙겨드세요 . \n",
            "입력 : 지쳤어요\n",
            "출력 : 지칠 때는 쉬어도 돼요 . \n",
            "입력 : 공부하기 싫어요\n",
            "출력 : 잠시 쉬어도 돼요 . \n",
            "입력 : 저녁은 드셨나요?\n",
            "출력 : 맛 있는거 드세요 . \n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('안녕하세요 . ',\n",
              " '저한테 다 말씀하세요 . ',\n",
              " '제가 있잖아요 . ',\n",
              " '그럴수록 당신이 힘들 거예요 . ',\n",
              " '뭐 좀 챙겨드세요 . ',\n",
              " '지칠 때는 쉬어도 돼요 . ',\n",
              " '잠시 쉬어도 돼요 . ',\n",
              " '맛 있는거 드세요 . ')"
            ]
          },
          "metadata": {},
          "execution_count": 128
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 6.4. 평가\n",
        "\n",
        "요약 : 큰 차이가 없는 것 같다.\n",
        "\n",
        "결과반영 : 6.3.과 6.4. 모두에서 조금 더 학습을 진행시켜 보아도 좋을 것 같다고 판단하여 NUM_HEAD 8/16/32와 D_MODEL 256/512 에서 epoch을 조금씩 조절해 보겠음."
      ],
      "metadata": {
        "id": "U9xVgWNuYzzc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 6.5. epoch 추가, EarlyStopping 설정"
      ],
      "metadata": {
        "id": "Ckw-kYIHZAQU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.callbacks import EarlyStopping"
      ],
      "metadata": {
        "id": "-8UNB_6TcpaT"
      },
      "execution_count": 135,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 6.5.1. D_MODEL = 256"
      ],
      "metadata": {
        "id": "XH6c_04FY-XM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### (1) NUM_HEAD = 8"
      ],
      "metadata": {
        "id": "ZWaMKZ03ZdBH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tf.keras.backend.clear_session()\n",
        "\n",
        "NUM_LAYERS = 2 # 인코더와 디코더의 층의 개수\n",
        "D_MODEL = 256 # 인코더와 디코더 내부의 입, 출력의 고정 차원\n",
        "NUM_HEADS = 8 # 멀티 헤드 어텐션에서의 헤드 수 \n",
        "UNITS = 512 # 피드 포워드 신경망의 은닉층의 크기\n",
        "DROPOUT = 0.1 # 드롭아웃의 비율\n",
        "\n",
        "model = transformer(\n",
        "    vocab_size=VOCAB_SIZE,\n",
        "    num_layers=NUM_LAYERS,\n",
        "    units=UNITS,\n",
        "    d_model=D_MODEL,\n",
        "    num_heads=NUM_HEADS,\n",
        "    dropout=DROPOUT)\n",
        "\n",
        "model.summary()\n",
        "\n",
        "# 컴파일\n",
        "learning_rate = CustomSchedule(D_MODEL)\n",
        "\n",
        "optimizer = tf.keras.optimizers.Adam(\n",
        "    learning_rate, beta_1=0.9, beta_2=0.98, epsilon=1e-9)\n",
        "\n",
        "def accuracy(y_true, y_pred):\n",
        "  y_true = tf.reshape(y_true, shape=(-1, MAX_LENGTH - 1))\n",
        "  return tf.keras.metrics.sparse_categorical_accuracy(y_true, y_pred)\n",
        "\n",
        "model.compile(optimizer=optimizer, loss=loss_function, metrics=[accuracy])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j9ejNkvDZrOL",
        "outputId": "5b97c332-b723-4e87-9856-26d7c1237e74"
      },
      "execution_count": 139,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"transformer\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " inputs (InputLayer)            [(None, None)]       0           []                               \n",
            "                                                                                                  \n",
            " dec_inputs (InputLayer)        [(None, None)]       0           []                               \n",
            "                                                                                                  \n",
            " enc_padding_mask (Lambda)      (None, 1, 1, None)   0           ['inputs[0][0]']                 \n",
            "                                                                                                  \n",
            " encoder (Functional)           (None, None, 256)    3634432     ['inputs[0][0]',                 \n",
            "                                                                  'enc_padding_mask[0][0]']       \n",
            "                                                                                                  \n",
            " look_ahead_mask (Lambda)       (None, 1, None, Non  0           ['dec_inputs[0][0]']             \n",
            "                                e)                                                                \n",
            "                                                                                                  \n",
            " dec_padding_mask (Lambda)      (None, 1, 1, None)   0           ['inputs[0][0]']                 \n",
            "                                                                                                  \n",
            " decoder (Functional)           (None, None, 256)    4161792     ['dec_inputs[0][0]',             \n",
            "                                                                  'encoder[0][0]',                \n",
            "                                                                  'look_ahead_mask[0][0]',        \n",
            "                                                                  'dec_padding_mask[0][0]']       \n",
            "                                                                                                  \n",
            " outputs (Dense)                (None, None, 10079)  2590303     ['decoder[0][0]']                \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 10,386,527\n",
            "Trainable params: 10,386,527\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "EPOCHS = 50\n",
        "es = EarlyStopping(monitor='loss', patience=1, verbose=1)\n",
        "model.fit(dataset, epochs=EPOCHS, callbacks=[es])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h9Uycg-KZuGg",
        "outputId": "a6736472-0c37-4b18-88c3-19cf8cb170d3"
      },
      "execution_count": 140,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "263/263 [==============================] - 12s 23ms/step - loss: 5.6871 - accuracy: 0.1523\n",
            "Epoch 2/50\n",
            "263/263 [==============================] - 6s 23ms/step - loss: 4.0992 - accuracy: 0.2410\n",
            "Epoch 3/50\n",
            "263/263 [==============================] - 8s 32ms/step - loss: 3.5678 - accuracy: 0.2499\n",
            "Epoch 4/50\n",
            "263/263 [==============================] - 10s 38ms/step - loss: 3.2914 - accuracy: 0.2648\n",
            "Epoch 5/50\n",
            "263/263 [==============================] - 10s 38ms/step - loss: 3.0146 - accuracy: 0.2859\n",
            "Epoch 6/50\n",
            "263/263 [==============================] - 8s 28ms/step - loss: 2.6942 - accuracy: 0.3192\n",
            "Epoch 7/50\n",
            "263/263 [==============================] - 6s 23ms/step - loss: 2.3372 - accuracy: 0.3653\n",
            "Epoch 8/50\n",
            "263/263 [==============================] - 6s 23ms/step - loss: 1.9507 - accuracy: 0.4135\n",
            "Epoch 9/50\n",
            "263/263 [==============================] - 6s 23ms/step - loss: 1.5636 - accuracy: 0.4569\n",
            "Epoch 10/50\n",
            "263/263 [==============================] - 6s 23ms/step - loss: 1.2043 - accuracy: 0.5024\n",
            "Epoch 11/50\n",
            "263/263 [==============================] - 6s 23ms/step - loss: 0.9028 - accuracy: 0.5439\n",
            "Epoch 12/50\n",
            "263/263 [==============================] - 6s 24ms/step - loss: 0.6602 - accuracy: 0.5815\n",
            "Epoch 13/50\n",
            "263/263 [==============================] - 6s 23ms/step - loss: 0.4867 - accuracy: 0.6098\n",
            "Epoch 14/50\n",
            "263/263 [==============================] - 6s 23ms/step - loss: 0.3664 - accuracy: 0.6305\n",
            "Epoch 15/50\n",
            "263/263 [==============================] - 6s 23ms/step - loss: 0.3055 - accuracy: 0.6414\n",
            "Epoch 16/50\n",
            "263/263 [==============================] - 6s 23ms/step - loss: 0.2588 - accuracy: 0.6500\n",
            "Epoch 17/50\n",
            "263/263 [==============================] - 6s 24ms/step - loss: 0.2022 - accuracy: 0.6627\n",
            "Epoch 18/50\n",
            "263/263 [==============================] - 6s 23ms/step - loss: 0.1633 - accuracy: 0.6700\n",
            "Epoch 19/50\n",
            "263/263 [==============================] - 6s 23ms/step - loss: 0.1443 - accuracy: 0.6744\n",
            "Epoch 20/50\n",
            "263/263 [==============================] - 6s 23ms/step - loss: 0.1153 - accuracy: 0.6812\n",
            "Epoch 21/50\n",
            "263/263 [==============================] - 6s 23ms/step - loss: 0.1024 - accuracy: 0.6843\n",
            "Epoch 22/50\n",
            "263/263 [==============================] - 6s 23ms/step - loss: 0.0921 - accuracy: 0.6866\n",
            "Epoch 23/50\n",
            "263/263 [==============================] - 6s 23ms/step - loss: 0.0855 - accuracy: 0.6887\n",
            "Epoch 24/50\n",
            "263/263 [==============================] - 6s 23ms/step - loss: 0.0744 - accuracy: 0.6907\n",
            "Epoch 25/50\n",
            "263/263 [==============================] - 6s 23ms/step - loss: 0.0710 - accuracy: 0.6917\n",
            "Epoch 26/50\n",
            "263/263 [==============================] - 6s 23ms/step - loss: 0.0609 - accuracy: 0.6946\n",
            "Epoch 27/50\n",
            "263/263 [==============================] - 6s 23ms/step - loss: 0.0581 - accuracy: 0.6954\n",
            "Epoch 28/50\n",
            "263/263 [==============================] - 6s 23ms/step - loss: 0.0547 - accuracy: 0.6961\n",
            "Epoch 29/50\n",
            "263/263 [==============================] - 6s 23ms/step - loss: 0.0512 - accuracy: 0.6967\n",
            "Epoch 30/50\n",
            "263/263 [==============================] - 6s 24ms/step - loss: 0.0478 - accuracy: 0.6979\n",
            "Epoch 31/50\n",
            "263/263 [==============================] - 6s 23ms/step - loss: 0.0455 - accuracy: 0.6986\n",
            "Epoch 32/50\n",
            "263/263 [==============================] - 6s 23ms/step - loss: 0.0440 - accuracy: 0.6989\n",
            "Epoch 33/50\n",
            "263/263 [==============================] - 6s 23ms/step - loss: 0.0438 - accuracy: 0.6992\n",
            "Epoch 34/50\n",
            "263/263 [==============================] - 6s 23ms/step - loss: 0.0377 - accuracy: 0.7002\n",
            "Epoch 35/50\n",
            "263/263 [==============================] - 6s 23ms/step - loss: 0.0396 - accuracy: 0.6998\n",
            "Epoch 35: early stopping\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7ff7540a7110>"
            ]
          },
          "metadata": {},
          "execution_count": 140
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sentence_generation('요즘 컨디션이 별로야')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "outputId": "7f415d6e-7557-40dd-f92b-507733183b36",
        "id": "5S1tZ6AJZ63G"
      },
      "execution_count": 141,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "입력 : 요즘 컨디션이 별로야\n",
            "출력 : 건강에 유의하세요 . \n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'건강에 유의하세요 . '"
            ]
          },
          "metadata": {},
          "execution_count": 141
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sentence_generation('어떻게 생각할까?')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "outputId": "d1089a6a-539c-4cdb-bca0-5e4dee007a63",
        "id": "PW8zlXNvZ63H"
      },
      "execution_count": 142,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "입력 : 어떻게 생각할까?\n",
            "출력 : 아직은 잘 모르겠어요 . \n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'아직은 잘 모르겠어요 . '"
            ]
          },
          "metadata": {},
          "execution_count": 142
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sentence_generation('오늘 너무 피곤하다')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "outputId": "d384b851-6722-41da-b388-be2c1107866c",
        "id": "EE9foLXmZ63H"
      },
      "execution_count": 143,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "입력 : 오늘 너무 피곤하다\n",
            "출력 : 아무래도 사생활이 적으니까요 . \n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'아무래도 사생활이 적으니까요 . '"
            ]
          },
          "metadata": {},
          "execution_count": 143
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sentence_generation('안녕하세요'), sentence_generation('반가워요!'), sentence_generation('재밌는 경기입니다.'), sentence_generation('너무 화가나요'), sentence_generation('배고파요'), sentence_generation('지쳤어요'), sentence_generation('공부하기 싫어요'), sentence_generation('저녁은 드셨나요?')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "30d4bf73-e207-4e77-da8b-575cf16dd2ca",
        "id": "f_ICpP5WZ63H"
      },
      "execution_count": 144,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "입력 : 안녕하세요\n",
            "출력 : 안녕하세요 . \n",
            "입력 : 반가워요!\n",
            "출력 : 저도 저도요 . \n",
            "입력 : 재밌는 경기입니다.\n",
            "출력 : 제가 있잖아요 . \n",
            "입력 : 너무 화가나요\n",
            "출력 : 그럴수록 당신이 힘들 거예요 . \n",
            "입력 : 배고파요\n",
            "출력 : 얼른 맛난 음식 드세요 . \n",
            "입력 : 지쳤어요\n",
            "출력 : 잘 하고 있어요 . \n",
            "입력 : 공부하기 싫어요\n",
            "출력 : 조금만 기다려 보세요 . \n",
            "입력 : 저녁은 드셨나요?\n",
            "출력 : 맛있는 거 드세요 . \n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('안녕하세요 . ',\n",
              " '저도 저도요 . ',\n",
              " '제가 있잖아요 . ',\n",
              " '그럴수록 당신이 힘들 거예요 . ',\n",
              " '얼른 맛난 음식 드세요 . ',\n",
              " '잘 하고 있어요 . ',\n",
              " '조금만 기다려 보세요 . ',\n",
              " '맛있는 거 드세요 . ')"
            ]
          },
          "metadata": {},
          "execution_count": 144
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### (2) NUM_HEAD = 16"
      ],
      "metadata": {
        "id": "YAHtZspyaIK4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tf.keras.backend.clear_session()\n",
        "\n",
        "NUM_LAYERS = 2 # 인코더와 디코더의 층의 개수\n",
        "D_MODEL = 256 # 인코더와 디코더 내부의 입, 출력의 고정 차원\n",
        "NUM_HEADS = 16 # 멀티 헤드 어텐션에서의 헤드 수 \n",
        "UNITS = 512 # 피드 포워드 신경망의 은닉층의 크기\n",
        "DROPOUT = 0.1 # 드롭아웃의 비율\n",
        "\n",
        "model = transformer(\n",
        "    vocab_size=VOCAB_SIZE,\n",
        "    num_layers=NUM_LAYERS,\n",
        "    units=UNITS,\n",
        "    d_model=D_MODEL,\n",
        "    num_heads=NUM_HEADS,\n",
        "    dropout=DROPOUT)\n",
        "\n",
        "model.summary()\n",
        "\n",
        "# 컴파일\n",
        "learning_rate = CustomSchedule(D_MODEL)\n",
        "\n",
        "optimizer = tf.keras.optimizers.Adam(\n",
        "    learning_rate, beta_1=0.9, beta_2=0.98, epsilon=1e-9)\n",
        "\n",
        "def accuracy(y_true, y_pred):\n",
        "  y_true = tf.reshape(y_true, shape=(-1, MAX_LENGTH - 1))\n",
        "  return tf.keras.metrics.sparse_categorical_accuracy(y_true, y_pred)\n",
        "\n",
        "model.compile(optimizer=optimizer, loss=loss_function, metrics=[accuracy])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ODfxfF07aIK4",
        "outputId": "9412c34c-d2a6-4ee8-b5d8-1c998748c7d7"
      },
      "execution_count": 145,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"transformer\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " inputs (InputLayer)            [(None, None)]       0           []                               \n",
            "                                                                                                  \n",
            " dec_inputs (InputLayer)        [(None, None)]       0           []                               \n",
            "                                                                                                  \n",
            " enc_padding_mask (Lambda)      (None, 1, 1, None)   0           ['inputs[0][0]']                 \n",
            "                                                                                                  \n",
            " encoder (Functional)           (None, None, 256)    3634432     ['inputs[0][0]',                 \n",
            "                                                                  'enc_padding_mask[0][0]']       \n",
            "                                                                                                  \n",
            " look_ahead_mask (Lambda)       (None, 1, None, Non  0           ['dec_inputs[0][0]']             \n",
            "                                e)                                                                \n",
            "                                                                                                  \n",
            " dec_padding_mask (Lambda)      (None, 1, 1, None)   0           ['inputs[0][0]']                 \n",
            "                                                                                                  \n",
            " decoder (Functional)           (None, None, 256)    4161792     ['dec_inputs[0][0]',             \n",
            "                                                                  'encoder[0][0]',                \n",
            "                                                                  'look_ahead_mask[0][0]',        \n",
            "                                                                  'dec_padding_mask[0][0]']       \n",
            "                                                                                                  \n",
            " outputs (Dense)                (None, None, 10079)  2590303     ['decoder[0][0]']                \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 10,386,527\n",
            "Trainable params: 10,386,527\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "EPOCHS = 50\n",
        "es = EarlyStopping(monitor='loss', patience=1, verbose=1)\n",
        "model.fit(dataset, epochs=EPOCHS, callbacks=[es])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U-BzoRiKaIK5",
        "outputId": "b9e35fda-4d72-4bfe-83cb-b6a38c6475f1"
      },
      "execution_count": 146,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "263/263 [==============================] - 13s 23ms/step - loss: 5.7323 - accuracy: 0.1572\n",
            "Epoch 2/50\n",
            "263/263 [==============================] - 6s 23ms/step - loss: 4.1159 - accuracy: 0.2407\n",
            "Epoch 3/50\n",
            "263/263 [==============================] - 6s 23ms/step - loss: 3.5713 - accuracy: 0.2509\n",
            "Epoch 4/50\n",
            "263/263 [==============================] - 6s 23ms/step - loss: 3.2827 - accuracy: 0.2661\n",
            "Epoch 5/50\n",
            "263/263 [==============================] - 6s 23ms/step - loss: 2.9941 - accuracy: 0.2876\n",
            "Epoch 6/50\n",
            "263/263 [==============================] - 6s 23ms/step - loss: 2.6697 - accuracy: 0.3238\n",
            "Epoch 7/50\n",
            "263/263 [==============================] - 6s 23ms/step - loss: 2.3086 - accuracy: 0.3697\n",
            "Epoch 8/50\n",
            "263/263 [==============================] - 8s 32ms/step - loss: 1.9250 - accuracy: 0.4156\n",
            "Epoch 9/50\n",
            "263/263 [==============================] - 11s 41ms/step - loss: 1.5420 - accuracy: 0.4605\n",
            "Epoch 10/50\n",
            "263/263 [==============================] - 7s 25ms/step - loss: 1.1859 - accuracy: 0.5072\n",
            "Epoch 11/50\n",
            "263/263 [==============================] - 6s 23ms/step - loss: 0.8860 - accuracy: 0.5472\n",
            "Epoch 12/50\n",
            "263/263 [==============================] - 6s 23ms/step - loss: 0.6567 - accuracy: 0.5824\n",
            "Epoch 13/50\n",
            "263/263 [==============================] - 10s 37ms/step - loss: 0.4763 - accuracy: 0.6122\n",
            "Epoch 14/50\n",
            "263/263 [==============================] - 6s 23ms/step - loss: 0.3596 - accuracy: 0.6329\n",
            "Epoch 15/50\n",
            "263/263 [==============================] - 6s 23ms/step - loss: 0.2967 - accuracy: 0.6418\n",
            "Epoch 16/50\n",
            "263/263 [==============================] - 6s 23ms/step - loss: 0.2576 - accuracy: 0.6492\n",
            "Epoch 17/50\n",
            "263/263 [==============================] - 6s 23ms/step - loss: 0.2052 - accuracy: 0.6620\n",
            "Epoch 18/50\n",
            "263/263 [==============================] - 10s 38ms/step - loss: 0.1650 - accuracy: 0.6701\n",
            "Epoch 19/50\n",
            "263/263 [==============================] - 6s 23ms/step - loss: 0.1374 - accuracy: 0.6753\n",
            "Epoch 20/50\n",
            "263/263 [==============================] - 6s 23ms/step - loss: 0.1196 - accuracy: 0.6811\n",
            "Epoch 21/50\n",
            "263/263 [==============================] - 6s 23ms/step - loss: 0.1060 - accuracy: 0.6839\n",
            "Epoch 22/50\n",
            "263/263 [==============================] - 6s 23ms/step - loss: 0.0938 - accuracy: 0.6866\n",
            "Epoch 23/50\n",
            "263/263 [==============================] - 6s 23ms/step - loss: 0.0835 - accuracy: 0.6897\n",
            "Epoch 24/50\n",
            "263/263 [==============================] - 6s 23ms/step - loss: 0.0758 - accuracy: 0.6911\n",
            "Epoch 25/50\n",
            "263/263 [==============================] - 6s 23ms/step - loss: 0.0689 - accuracy: 0.6926\n",
            "Epoch 26/50\n",
            "263/263 [==============================] - 6s 23ms/step - loss: 0.0621 - accuracy: 0.6940\n",
            "Epoch 27/50\n",
            "263/263 [==============================] - 6s 23ms/step - loss: 0.0572 - accuracy: 0.6956\n",
            "Epoch 28/50\n",
            "263/263 [==============================] - 6s 23ms/step - loss: 0.0518 - accuracy: 0.6970\n",
            "Epoch 29/50\n",
            "263/263 [==============================] - 6s 23ms/step - loss: 0.0472 - accuracy: 0.6978\n",
            "Epoch 30/50\n",
            "263/263 [==============================] - 6s 23ms/step - loss: 0.0473 - accuracy: 0.6980\n",
            "Epoch 30: early stopping\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7ff6d1dadbd0>"
            ]
          },
          "metadata": {},
          "execution_count": 146
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sentence_generation('요즘 컨디션이 별로야')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "id": "B2Szu4XQaIK5",
        "outputId": "d93d3c2c-087f-4fb4-e94c-bb91d57c8ec7"
      },
      "execution_count": 147,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "입력 : 요즘 컨디션이 별로야\n",
            "출력 : 당황했나요 ? \n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'당황했나요 ? '"
            ]
          },
          "metadata": {},
          "execution_count": 147
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sentence_generation('어떻게 생각할까?')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "id": "5S2IOvFfaIK5",
        "outputId": "376cb816-2afc-44cd-c431-47ef88460e69"
      },
      "execution_count": 148,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "입력 : 어떻게 생각할까?\n",
            "출력 : 저도 모르겠어요 . \n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'저도 모르겠어요 . '"
            ]
          },
          "metadata": {},
          "execution_count": 148
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sentence_generation('오늘 너무 피곤하다')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "id": "ki3OsBzEaIK5",
        "outputId": "f3f3502e-3a25-49f5-9cb1-91fb6bccd7cc"
      },
      "execution_count": 149,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "입력 : 오늘 너무 피곤하다\n",
            "출력 : 아무래도 사생활이 적으니까요 . \n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'아무래도 사생활이 적으니까요 . '"
            ]
          },
          "metadata": {},
          "execution_count": 149
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sentence_generation('안녕하세요'), sentence_generation('반가워요!'), sentence_generation('재밌는 경기입니다.'), sentence_generation('너무 화가나요'), sentence_generation('배고파요'), sentence_generation('지쳤어요'), sentence_generation('공부하기 싫어요'), sentence_generation('저녁은 드셨나요?')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nwUX3aIgaIK5",
        "outputId": "21b7e3bb-5c03-4b49-a603-f0313e2095cc"
      },
      "execution_count": 150,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "입력 : 안녕하세요\n",
            "출력 : 안녕하세요 . \n",
            "입력 : 반가워요!\n",
            "출력 : 저도 데려가 주세요 . \n",
            "입력 : 재밌는 경기입니다.\n",
            "출력 : 제가 있잖아요 . \n",
            "입력 : 너무 화가나요\n",
            "출력 : 안 보낼 편지 쓰지 마요 . \n",
            "입력 : 배고파요\n",
            "출력 : 저랑 한 잔 해요 . \n",
            "입력 : 지쳤어요\n",
            "출력 : 저랑 놀아서 그래요 . \n",
            "입력 : 공부하기 싫어요\n",
            "출력 : 아직 그립겠지만 괜찮아 질 거예요 . \n",
            "입력 : 저녁은 드셨나요?\n",
            "출력 : 맛있는 거 드세요 . \n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('안녕하세요 . ',\n",
              " '저도 데려가 주세요 . ',\n",
              " '제가 있잖아요 . ',\n",
              " '안 보낼 편지 쓰지 마요 . ',\n",
              " '저랑 한 잔 해요 . ',\n",
              " '저랑 놀아서 그래요 . ',\n",
              " '아직 그립겠지만 괜찮아 질 거예요 . ',\n",
              " '맛있는 거 드세요 . ')"
            ]
          },
          "metadata": {},
          "execution_count": 150
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### (3) NUM_HEAD = 32"
      ],
      "metadata": {
        "id": "yAZrM8KBaLNF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tf.keras.backend.clear_session()\n",
        "\n",
        "NUM_LAYERS = 2 # 인코더와 디코더의 층의 개수\n",
        "D_MODEL = 256 # 인코더와 디코더 내부의 입, 출력의 고정 차원\n",
        "NUM_HEADS = 32 # 멀티 헤드 어텐션에서의 헤드 수 \n",
        "UNITS = 512 # 피드 포워드 신경망의 은닉층의 크기\n",
        "DROPOUT = 0.1 # 드롭아웃의 비율\n",
        "\n",
        "model = transformer(\n",
        "    vocab_size=VOCAB_SIZE,\n",
        "    num_layers=NUM_LAYERS,\n",
        "    units=UNITS,\n",
        "    d_model=D_MODEL,\n",
        "    num_heads=NUM_HEADS,\n",
        "    dropout=DROPOUT)\n",
        "\n",
        "model.summary()\n",
        "\n",
        "# 컴파일\n",
        "learning_rate = CustomSchedule(D_MODEL)\n",
        "\n",
        "optimizer = tf.keras.optimizers.Adam(\n",
        "    learning_rate, beta_1=0.9, beta_2=0.98, epsilon=1e-9)\n",
        "\n",
        "def accuracy(y_true, y_pred):\n",
        "  y_true = tf.reshape(y_true, shape=(-1, MAX_LENGTH - 1))\n",
        "  return tf.keras.metrics.sparse_categorical_accuracy(y_true, y_pred)\n",
        "\n",
        "model.compile(optimizer=optimizer, loss=loss_function, metrics=[accuracy])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2kB6Uam8aLNG",
        "outputId": "3dd022d0-ad7d-4efe-e391-2d6784a35ee6"
      },
      "execution_count": 151,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"transformer\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " inputs (InputLayer)            [(None, None)]       0           []                               \n",
            "                                                                                                  \n",
            " dec_inputs (InputLayer)        [(None, None)]       0           []                               \n",
            "                                                                                                  \n",
            " enc_padding_mask (Lambda)      (None, 1, 1, None)   0           ['inputs[0][0]']                 \n",
            "                                                                                                  \n",
            " encoder (Functional)           (None, None, 256)    3634432     ['inputs[0][0]',                 \n",
            "                                                                  'enc_padding_mask[0][0]']       \n",
            "                                                                                                  \n",
            " look_ahead_mask (Lambda)       (None, 1, None, Non  0           ['dec_inputs[0][0]']             \n",
            "                                e)                                                                \n",
            "                                                                                                  \n",
            " dec_padding_mask (Lambda)      (None, 1, 1, None)   0           ['inputs[0][0]']                 \n",
            "                                                                                                  \n",
            " decoder (Functional)           (None, None, 256)    4161792     ['dec_inputs[0][0]',             \n",
            "                                                                  'encoder[0][0]',                \n",
            "                                                                  'look_ahead_mask[0][0]',        \n",
            "                                                                  'dec_padding_mask[0][0]']       \n",
            "                                                                                                  \n",
            " outputs (Dense)                (None, None, 10079)  2590303     ['decoder[0][0]']                \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 10,386,527\n",
            "Trainable params: 10,386,527\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "EPOCHS = 50\n",
        "es = EarlyStopping(monitor='loss', patience=1, verbose=1)\n",
        "model.fit(dataset, epochs=EPOCHS, callbacks=[es])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VwGE51z_aLNG",
        "outputId": "e37230a5-9a8c-4abe-d048-3410740a1564"
      },
      "execution_count": 152,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "263/263 [==============================] - 12s 24ms/step - loss: 5.7093 - accuracy: 0.1545\n",
            "Epoch 2/50\n",
            "263/263 [==============================] - 6s 24ms/step - loss: 4.1149 - accuracy: 0.2408\n",
            "Epoch 3/50\n",
            "263/263 [==============================] - 6s 24ms/step - loss: 3.5546 - accuracy: 0.2496\n",
            "Epoch 4/50\n",
            "263/263 [==============================] - 6s 24ms/step - loss: 3.2769 - accuracy: 0.2657\n",
            "Epoch 5/50\n",
            "263/263 [==============================] - 6s 23ms/step - loss: 2.9930 - accuracy: 0.2876\n",
            "Epoch 6/50\n",
            "263/263 [==============================] - 6s 23ms/step - loss: 2.6701 - accuracy: 0.3237\n",
            "Epoch 7/50\n",
            "263/263 [==============================] - 6s 23ms/step - loss: 2.3110 - accuracy: 0.3669\n",
            "Epoch 8/50\n",
            "263/263 [==============================] - 6s 24ms/step - loss: 1.9300 - accuracy: 0.4134\n",
            "Epoch 9/50\n",
            "263/263 [==============================] - 6s 24ms/step - loss: 1.5483 - accuracy: 0.4603\n",
            "Epoch 10/50\n",
            "263/263 [==============================] - 6s 23ms/step - loss: 1.1929 - accuracy: 0.5043\n",
            "Epoch 11/50\n",
            "263/263 [==============================] - 6s 23ms/step - loss: 0.8934 - accuracy: 0.5448\n",
            "Epoch 12/50\n",
            "263/263 [==============================] - 7s 25ms/step - loss: 0.6540 - accuracy: 0.5820\n",
            "Epoch 13/50\n",
            "263/263 [==============================] - 6s 24ms/step - loss: 0.4770 - accuracy: 0.6121\n",
            "Epoch 14/50\n",
            "263/263 [==============================] - 6s 24ms/step - loss: 0.3623 - accuracy: 0.6324\n",
            "Epoch 15/50\n",
            "263/263 [==============================] - 6s 23ms/step - loss: 0.2929 - accuracy: 0.6438\n",
            "Epoch 16/50\n",
            "263/263 [==============================] - 6s 23ms/step - loss: 0.2448 - accuracy: 0.6529\n",
            "Epoch 17/50\n",
            "263/263 [==============================] - 6s 24ms/step - loss: 0.1970 - accuracy: 0.6633\n",
            "Epoch 18/50\n",
            "263/263 [==============================] - 6s 24ms/step - loss: 0.1586 - accuracy: 0.6719\n",
            "Epoch 19/50\n",
            "263/263 [==============================] - 6s 23ms/step - loss: 0.1329 - accuracy: 0.6778\n",
            "Epoch 20/50\n",
            "263/263 [==============================] - 6s 24ms/step - loss: 0.1144 - accuracy: 0.6819\n",
            "Epoch 21/50\n",
            "263/263 [==============================] - 6s 24ms/step - loss: 0.1015 - accuracy: 0.6849\n",
            "Epoch 22/50\n",
            "263/263 [==============================] - 6s 24ms/step - loss: 0.0847 - accuracy: 0.6885\n",
            "Epoch 23/50\n",
            "263/263 [==============================] - 6s 24ms/step - loss: 0.0825 - accuracy: 0.6894\n",
            "Epoch 24/50\n",
            "263/263 [==============================] - 6s 24ms/step - loss: 0.0737 - accuracy: 0.6914\n",
            "Epoch 25/50\n",
            "263/263 [==============================] - 6s 24ms/step - loss: 0.0677 - accuracy: 0.6932\n",
            "Epoch 26/50\n",
            "263/263 [==============================] - 6s 24ms/step - loss: 0.0620 - accuracy: 0.6943\n",
            "Epoch 27/50\n",
            "263/263 [==============================] - 6s 24ms/step - loss: 0.0598 - accuracy: 0.6952\n",
            "Epoch 28/50\n",
            "263/263 [==============================] - 6s 24ms/step - loss: 0.0532 - accuracy: 0.6968\n",
            "Epoch 29/50\n",
            "263/263 [==============================] - 6s 23ms/step - loss: 0.0519 - accuracy: 0.6975\n",
            "Epoch 30/50\n",
            "263/263 [==============================] - 6s 23ms/step - loss: 0.0452 - accuracy: 0.6986\n",
            "Epoch 31/50\n",
            "263/263 [==============================] - 6s 23ms/step - loss: 0.0438 - accuracy: 0.6991\n",
            "Epoch 32/50\n",
            "263/263 [==============================] - 6s 23ms/step - loss: 0.0404 - accuracy: 0.6997\n",
            "Epoch 33/50\n",
            "263/263 [==============================] - 6s 23ms/step - loss: 0.0365 - accuracy: 0.7005\n",
            "Epoch 34/50\n",
            "263/263 [==============================] - 6s 23ms/step - loss: 0.0366 - accuracy: 0.7003\n",
            "Epoch 34: early stopping\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7ff7ca827c10>"
            ]
          },
          "metadata": {},
          "execution_count": 152
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sentence_generation('요즘 컨디션이 별로야')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "id": "O3LzB0A3aLNG",
        "outputId": "9b9681f6-e759-4836-d7a7-67c1901debb7"
      },
      "execution_count": 153,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "입력 : 요즘 컨디션이 별로야\n",
            "출력 : 자세히 말해주세요 . \n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'자세히 말해주세요 . '"
            ]
          },
          "metadata": {},
          "execution_count": 153
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sentence_generation('어떻게 생각할까?')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "id": "NObRaniYaLNH",
        "outputId": "e547aab1-47ef-488e-eb5d-b0c0830cd3dc"
      },
      "execution_count": 154,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "입력 : 어떻게 생각할까?\n",
            "출력 : 글쎄요 . \n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'글쎄요 . '"
            ]
          },
          "metadata": {},
          "execution_count": 154
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sentence_generation('오늘 너무 피곤하다')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "id": "VBjPjUbpaLNH",
        "outputId": "90a90420-15f0-4e0a-aa07-976182cc92c5"
      },
      "execution_count": 155,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "입력 : 오늘 너무 피곤하다\n",
            "출력 : 아무래도 사생활이 적으니까요 . \n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'아무래도 사생활이 적으니까요 . '"
            ]
          },
          "metadata": {},
          "execution_count": 155
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sentence_generation('안녕하세요'), sentence_generation('반가워요!'), sentence_generation('재밌는 경기입니다.'), sentence_generation('너무 화가나요'), sentence_generation('배고파요'), sentence_generation('지쳤어요'), sentence_generation('공부하기 싫어요'), sentence_generation('저녁은 드셨나요?')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Sop6px3taLNH",
        "outputId": "5d81865a-c202-4997-b382-7fb93ab078be"
      },
      "execution_count": 156,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "입력 : 안녕하세요\n",
            "출력 : 안녕하세요 . \n",
            "입력 : 반가워요!\n",
            "출력 : 저도 반가워요 . \n",
            "입력 : 재밌는 경기입니다.\n",
            "출력 : 제가 있잖아요 . \n",
            "입력 : 너무 화가나요\n",
            "출력 : 안 사면 그만큼 모으시는거예요 . \n",
            "입력 : 배고파요\n",
            "출력 : 그럼요 . 제가 함께 할게요 . \n",
            "입력 : 지쳤어요\n",
            "출력 : 지칠 때는 쉬어도 돼요 . \n",
            "입력 : 공부하기 싫어요\n",
            "출력 : 다시 채워질 거예요 . \n",
            "입력 : 저녁은 드셨나요?\n",
            "출력 : 맛있는 거 드세요 . \n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('안녕하세요 . ',\n",
              " '저도 반가워요 . ',\n",
              " '제가 있잖아요 . ',\n",
              " '안 사면 그만큼 모으시는거예요 . ',\n",
              " '그럼요 . 제가 함께 할게요 . ',\n",
              " '지칠 때는 쉬어도 돼요 . ',\n",
              " '다시 채워질 거예요 . ',\n",
              " '맛있는 거 드세요 . ')"
            ]
          },
          "metadata": {},
          "execution_count": 156
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 6.5.2. D_MODEL = 512"
      ],
      "metadata": {
        "id": "zdMhBKctZZ3A"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### (1) NUM_HEAD = 8"
      ],
      "metadata": {
        "id": "Bgeb4oqraX4w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tf.keras.backend.clear_session()\n",
        "\n",
        "NUM_LAYERS = 2 # 인코더와 디코더의 층의 개수\n",
        "D_MODEL = 512 # 인코더와 디코더 내부의 입, 출력의 고정 차원\n",
        "NUM_HEADS = 8 # 멀티 헤드 어텐션에서의 헤드 수 \n",
        "UNITS = 512 # 피드 포워드 신경망의 은닉층의 크기\n",
        "DROPOUT = 0.1 # 드롭아웃의 비율\n",
        "\n",
        "model = transformer(\n",
        "    vocab_size=VOCAB_SIZE,\n",
        "    num_layers=NUM_LAYERS,\n",
        "    units=UNITS,\n",
        "    d_model=D_MODEL,\n",
        "    num_heads=NUM_HEADS,\n",
        "    dropout=DROPOUT)\n",
        "\n",
        "model.summary()\n",
        "\n",
        "# 컴파일\n",
        "learning_rate = CustomSchedule(D_MODEL)\n",
        "\n",
        "optimizer = tf.keras.optimizers.Adam(\n",
        "    learning_rate, beta_1=0.9, beta_2=0.98, epsilon=1e-9)\n",
        "\n",
        "def accuracy(y_true, y_pred):\n",
        "  y_true = tf.reshape(y_true, shape=(-1, MAX_LENGTH - 1))\n",
        "  return tf.keras.metrics.sparse_categorical_accuracy(y_true, y_pred)\n",
        "\n",
        "model.compile(optimizer=optimizer, loss=loss_function, metrics=[accuracy])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qsxNmS96aX4w",
        "outputId": "18079cba-aa4f-4765-bcdf-0246d8aec3be"
      },
      "execution_count": 157,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"transformer\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " inputs (InputLayer)            [(None, None)]       0           []                               \n",
            "                                                                                                  \n",
            " dec_inputs (InputLayer)        [(None, None)]       0           []                               \n",
            "                                                                                                  \n",
            " enc_padding_mask (Lambda)      (None, 1, 1, None)   0           ['inputs[0][0]']                 \n",
            "                                                                                                  \n",
            " encoder (Functional)           (None, None, 512)    8316416     ['inputs[0][0]',                 \n",
            "                                                                  'enc_padding_mask[0][0]']       \n",
            "                                                                                                  \n",
            " look_ahead_mask (Lambda)       (None, 1, None, Non  0           ['dec_inputs[0][0]']             \n",
            "                                e)                                                                \n",
            "                                                                                                  \n",
            " dec_padding_mask (Lambda)      (None, 1, 1, None)   0           ['inputs[0][0]']                 \n",
            "                                                                                                  \n",
            " decoder (Functional)           (None, None, 512)    10419712    ['dec_inputs[0][0]',             \n",
            "                                                                  'encoder[0][0]',                \n",
            "                                                                  'look_ahead_mask[0][0]',        \n",
            "                                                                  'dec_padding_mask[0][0]']       \n",
            "                                                                                                  \n",
            " outputs (Dense)                (None, None, 10079)  5170527     ['decoder[0][0]']                \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 23,906,655\n",
            "Trainable params: 23,906,655\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "EPOCHS = 50\n",
        "es = EarlyStopping(monitor='loss', patience=1, verbose=1)\n",
        "model.fit(dataset, epochs=EPOCHS, callbacks=[es])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wJtthUrdaX4w",
        "outputId": "0969407b-02a0-49bb-d46c-d0772249f03a"
      },
      "execution_count": 158,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "263/263 [==============================] - 12s 25ms/step - loss: 5.1398 - accuracy: 0.1900\n",
            "Epoch 2/50\n",
            "263/263 [==============================] - 7s 25ms/step - loss: 3.8060 - accuracy: 0.2434\n",
            "Epoch 3/50\n",
            "263/263 [==============================] - 7s 27ms/step - loss: 3.4558 - accuracy: 0.2564\n",
            "Epoch 4/50\n",
            "263/263 [==============================] - 7s 26ms/step - loss: 3.1276 - accuracy: 0.2779\n",
            "Epoch 5/50\n",
            "263/263 [==============================] - 7s 26ms/step - loss: 2.7635 - accuracy: 0.3140\n",
            "Epoch 6/50\n",
            "263/263 [==============================] - 7s 26ms/step - loss: 2.3452 - accuracy: 0.3663\n",
            "Epoch 7/50\n",
            "263/263 [==============================] - 7s 26ms/step - loss: 1.8862 - accuracy: 0.4232\n",
            "Epoch 8/50\n",
            "263/263 [==============================] - 7s 26ms/step - loss: 1.4296 - accuracy: 0.4820\n",
            "Epoch 9/50\n",
            "263/263 [==============================] - 7s 26ms/step - loss: 1.0288 - accuracy: 0.5356\n",
            "Epoch 10/50\n",
            "263/263 [==============================] - 7s 26ms/step - loss: 0.7085 - accuracy: 0.5847\n",
            "Epoch 11/50\n",
            "263/263 [==============================] - 7s 26ms/step - loss: 0.4770 - accuracy: 0.6226\n",
            "Epoch 12/50\n",
            "263/263 [==============================] - 7s 26ms/step - loss: 0.3349 - accuracy: 0.6441\n",
            "Epoch 13/50\n",
            "263/263 [==============================] - 7s 26ms/step - loss: 0.2643 - accuracy: 0.6543\n",
            "Epoch 14/50\n",
            "263/263 [==============================] - 7s 26ms/step - loss: 0.2275 - accuracy: 0.6601\n",
            "Epoch 15/50\n",
            "263/263 [==============================] - 7s 26ms/step - loss: 0.2103 - accuracy: 0.6626\n",
            "Epoch 16/50\n",
            "263/263 [==============================] - 7s 26ms/step - loss: 0.2041 - accuracy: 0.6622\n",
            "Epoch 17/50\n",
            "263/263 [==============================] - 7s 26ms/step - loss: 0.1733 - accuracy: 0.6690\n",
            "Epoch 18/50\n",
            "263/263 [==============================] - 7s 26ms/step - loss: 0.1442 - accuracy: 0.6748\n",
            "Epoch 19/50\n",
            "263/263 [==============================] - 7s 26ms/step - loss: 0.1327 - accuracy: 0.6776\n",
            "Epoch 20/50\n",
            "263/263 [==============================] - 7s 26ms/step - loss: 0.1074 - accuracy: 0.6830\n",
            "Epoch 21/50\n",
            "263/263 [==============================] - 7s 26ms/step - loss: 0.1021 - accuracy: 0.6841\n",
            "Epoch 22/50\n",
            "263/263 [==============================] - 7s 26ms/step - loss: 0.0873 - accuracy: 0.6882\n",
            "Epoch 23/50\n",
            "263/263 [==============================] - 7s 26ms/step - loss: 0.0782 - accuracy: 0.6903\n",
            "Epoch 24/50\n",
            "263/263 [==============================] - 7s 26ms/step - loss: 0.0702 - accuracy: 0.6919\n",
            "Epoch 25/50\n",
            "263/263 [==============================] - 7s 26ms/step - loss: 0.0670 - accuracy: 0.6926\n",
            "Epoch 26/50\n",
            "263/263 [==============================] - 7s 26ms/step - loss: 0.0608 - accuracy: 0.6940\n",
            "Epoch 27/50\n",
            "263/263 [==============================] - 7s 26ms/step - loss: 0.0580 - accuracy: 0.6951\n",
            "Epoch 28/50\n",
            "263/263 [==============================] - 7s 26ms/step - loss: 0.0525 - accuracy: 0.6963\n",
            "Epoch 29/50\n",
            "263/263 [==============================] - 7s 26ms/step - loss: 0.0516 - accuracy: 0.6962\n",
            "Epoch 30/50\n",
            "263/263 [==============================] - 7s 26ms/step - loss: 0.0486 - accuracy: 0.6968\n",
            "Epoch 31/50\n",
            "263/263 [==============================] - 7s 26ms/step - loss: 0.0439 - accuracy: 0.6984\n",
            "Epoch 32/50\n",
            "263/263 [==============================] - 7s 26ms/step - loss: 0.0425 - accuracy: 0.6984\n",
            "Epoch 33/50\n",
            "263/263 [==============================] - 7s 26ms/step - loss: 0.0376 - accuracy: 0.6996\n",
            "Epoch 34/50\n",
            "263/263 [==============================] - 7s 26ms/step - loss: 0.0405 - accuracy: 0.6993\n",
            "Epoch 34: early stopping\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7ff799206b90>"
            ]
          },
          "metadata": {},
          "execution_count": 158
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sentence_generation('요즘 컨디션이 별로야')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "id": "gGDJQbXraX4w",
        "outputId": "d30bcb5c-4ce0-411d-daa1-2a5b6cf430da"
      },
      "execution_count": 159,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "입력 : 요즘 컨디션이 별로야\n",
            "출력 : 괜찮아요 . \n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'괜찮아요 . '"
            ]
          },
          "metadata": {},
          "execution_count": 159
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sentence_generation('어떻게 생각할까?')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "id": "qloLlD7saX4x",
        "outputId": "0aa3574b-bd7c-464a-c8ea-b64570e35832"
      },
      "execution_count": 160,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "입력 : 어떻게 생각할까?\n",
            "출력 : 아직은 잘 모르겠어요 . \n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'아직은 잘 모르겠어요 . '"
            ]
          },
          "metadata": {},
          "execution_count": 160
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sentence_generation('오늘 너무 피곤하다')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "id": "REH6dlndaX4x",
        "outputId": "678bd2ec-5de8-4e9b-d238-bfd6bb05b5cf"
      },
      "execution_count": 161,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "입력 : 오늘 너무 피곤하다\n",
            "출력 : 무슨 말을 하시고 싶으신가요 . \n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'무슨 말을 하시고 싶으신가요 . '"
            ]
          },
          "metadata": {},
          "execution_count": 161
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sentence_generation('안녕하세요'), sentence_generation('반가워요!'), sentence_generation('재밌는 경기입니다.'), sentence_generation('너무 화가나요'), sentence_generation('배고파요'), sentence_generation('지쳤어요'), sentence_generation('공부하기 싫어요'), sentence_generation('저녁은 드셨나요?')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7qrs8QoTaX4x",
        "outputId": "528df633-838b-42cf-cf03-14c2404f807b"
      },
      "execution_count": 162,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "입력 : 안녕하세요\n",
            "출력 : 안녕하세요 . \n",
            "입력 : 반가워요!\n",
            "출력 : 저도 좀 알려주세요 . \n",
            "입력 : 재밌는 경기입니다.\n",
            "출력 : 맘고생 많았어요 . \n",
            "입력 : 너무 화가나요\n",
            "출력 : 안 좋은일이 있었나봐요 . \n",
            "입력 : 배고파요\n",
            "출력 : 뭐 좀 챙겨드세요 . \n",
            "입력 : 지쳤어요\n",
            "출력 : 고생 많았어요 . \n",
            "입력 : 공부하기 싫어요\n",
            "출력 : 지금 상황을 그대로 받아들이세요 . \n",
            "입력 : 저녁은 드셨나요?\n",
            "출력 : 맛있는 거 드세요 . \n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('안녕하세요 . ',\n",
              " '저도 좀 알려주세요 . ',\n",
              " '맘고생 많았어요 . ',\n",
              " '안 좋은일이 있었나봐요 . ',\n",
              " '뭐 좀 챙겨드세요 . ',\n",
              " '고생 많았어요 . ',\n",
              " '지금 상황을 그대로 받아들이세요 . ',\n",
              " '맛있는 거 드세요 . ')"
            ]
          },
          "metadata": {},
          "execution_count": 162
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### (2) NUM_HEAD = 16"
      ],
      "metadata": {
        "id": "ZttlqbgbahfX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tf.keras.backend.clear_session()\n",
        "\n",
        "NUM_LAYERS = 2 # 인코더와 디코더의 층의 개수\n",
        "D_MODEL = 512 # 인코더와 디코더 내부의 입, 출력의 고정 차원\n",
        "NUM_HEADS = 16 # 멀티 헤드 어텐션에서의 헤드 수 \n",
        "UNITS = 512 # 피드 포워드 신경망의 은닉층의 크기\n",
        "DROPOUT = 0.1 # 드롭아웃의 비율\n",
        "\n",
        "model = transformer(\n",
        "    vocab_size=VOCAB_SIZE,\n",
        "    num_layers=NUM_LAYERS,\n",
        "    units=UNITS,\n",
        "    d_model=D_MODEL,\n",
        "    num_heads=NUM_HEADS,\n",
        "    dropout=DROPOUT)\n",
        "\n",
        "model.summary()\n",
        "\n",
        "# 컴파일\n",
        "learning_rate = CustomSchedule(D_MODEL)\n",
        "\n",
        "optimizer = tf.keras.optimizers.Adam(\n",
        "    learning_rate, beta_1=0.9, beta_2=0.98, epsilon=1e-9)\n",
        "\n",
        "def accuracy(y_true, y_pred):\n",
        "  y_true = tf.reshape(y_true, shape=(-1, MAX_LENGTH - 1))\n",
        "  return tf.keras.metrics.sparse_categorical_accuracy(y_true, y_pred)\n",
        "\n",
        "model.compile(optimizer=optimizer, loss=loss_function, metrics=[accuracy])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Phc21yriahfY",
        "outputId": "c5a220a0-f849-4b04-a033-8fa3f65572b0"
      },
      "execution_count": 163,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"transformer\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " inputs (InputLayer)            [(None, None)]       0           []                               \n",
            "                                                                                                  \n",
            " dec_inputs (InputLayer)        [(None, None)]       0           []                               \n",
            "                                                                                                  \n",
            " enc_padding_mask (Lambda)      (None, 1, 1, None)   0           ['inputs[0][0]']                 \n",
            "                                                                                                  \n",
            " encoder (Functional)           (None, None, 512)    8316416     ['inputs[0][0]',                 \n",
            "                                                                  'enc_padding_mask[0][0]']       \n",
            "                                                                                                  \n",
            " look_ahead_mask (Lambda)       (None, 1, None, Non  0           ['dec_inputs[0][0]']             \n",
            "                                e)                                                                \n",
            "                                                                                                  \n",
            " dec_padding_mask (Lambda)      (None, 1, 1, None)   0           ['inputs[0][0]']                 \n",
            "                                                                                                  \n",
            " decoder (Functional)           (None, None, 512)    10419712    ['dec_inputs[0][0]',             \n",
            "                                                                  'encoder[0][0]',                \n",
            "                                                                  'look_ahead_mask[0][0]',        \n",
            "                                                                  'dec_padding_mask[0][0]']       \n",
            "                                                                                                  \n",
            " outputs (Dense)                (None, None, 10079)  5170527     ['decoder[0][0]']                \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 23,906,655\n",
            "Trainable params: 23,906,655\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "EPOCHS = 50\n",
        "es = EarlyStopping(monitor='loss', patience=1, verbose=1)\n",
        "model.fit(dataset, epochs=EPOCHS, callbacks=[es])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9yvKSwZ7ahfY",
        "outputId": "23541536-4632-465e-8d5d-9e08e69f55e7"
      },
      "execution_count": 164,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "263/263 [==============================] - 14s 26ms/step - loss: 5.1990 - accuracy: 0.1783\n",
            "Epoch 2/50\n",
            "263/263 [==============================] - 7s 26ms/step - loss: 3.8109 - accuracy: 0.2437\n",
            "Epoch 3/50\n",
            "263/263 [==============================] - 7s 26ms/step - loss: 3.4419 - accuracy: 0.2579\n",
            "Epoch 4/50\n",
            "263/263 [==============================] - 7s 26ms/step - loss: 3.1121 - accuracy: 0.2793\n",
            "Epoch 5/50\n",
            "263/263 [==============================] - 7s 26ms/step - loss: 2.7474 - accuracy: 0.3163\n",
            "Epoch 6/50\n",
            "263/263 [==============================] - 7s 26ms/step - loss: 2.3322 - accuracy: 0.3688\n",
            "Epoch 7/50\n",
            "263/263 [==============================] - 7s 26ms/step - loss: 1.8791 - accuracy: 0.4262\n",
            "Epoch 8/50\n",
            "263/263 [==============================] - 7s 26ms/step - loss: 1.4277 - accuracy: 0.4834\n",
            "Epoch 9/50\n",
            "263/263 [==============================] - 7s 26ms/step - loss: 1.0281 - accuracy: 0.5359\n",
            "Epoch 10/50\n",
            "263/263 [==============================] - 10s 39ms/step - loss: 0.7015 - accuracy: 0.5864\n",
            "Epoch 11/50\n",
            "263/263 [==============================] - 7s 26ms/step - loss: 0.4702 - accuracy: 0.6238\n",
            "Epoch 12/50\n",
            "263/263 [==============================] - 7s 26ms/step - loss: 0.3269 - accuracy: 0.6468\n",
            "Epoch 13/50\n",
            "263/263 [==============================] - 7s 26ms/step - loss: 0.2548 - accuracy: 0.6574\n",
            "Epoch 14/50\n",
            "263/263 [==============================] - 7s 26ms/step - loss: 0.2171 - accuracy: 0.6622\n",
            "Epoch 15/50\n",
            "263/263 [==============================] - 7s 26ms/step - loss: 0.2060 - accuracy: 0.6630\n",
            "Epoch 16/50\n",
            "263/263 [==============================] - 7s 27ms/step - loss: 0.1891 - accuracy: 0.6659\n",
            "Epoch 17/50\n",
            "263/263 [==============================] - 7s 26ms/step - loss: 0.1614 - accuracy: 0.6703\n",
            "Epoch 18/50\n",
            "263/263 [==============================] - 7s 26ms/step - loss: 0.1398 - accuracy: 0.6762\n",
            "Epoch 19/50\n",
            "263/263 [==============================] - 7s 26ms/step - loss: 0.1203 - accuracy: 0.6808\n",
            "Epoch 20/50\n",
            "263/263 [==============================] - 7s 26ms/step - loss: 0.1039 - accuracy: 0.6846\n",
            "Epoch 21/50\n",
            "263/263 [==============================] - 7s 26ms/step - loss: 0.0902 - accuracy: 0.6873\n",
            "Epoch 22/50\n",
            "263/263 [==============================] - 7s 26ms/step - loss: 0.0848 - accuracy: 0.6888\n",
            "Epoch 23/50\n",
            "263/263 [==============================] - 7s 27ms/step - loss: 0.0774 - accuracy: 0.6906\n",
            "Epoch 24/50\n",
            "263/263 [==============================] - 7s 26ms/step - loss: 0.0644 - accuracy: 0.6931\n",
            "Epoch 25/50\n",
            "263/263 [==============================] - 7s 27ms/step - loss: 0.0594 - accuracy: 0.6947\n",
            "Epoch 26/50\n",
            "263/263 [==============================] - 7s 26ms/step - loss: 0.0573 - accuracy: 0.6949\n",
            "Epoch 27/50\n",
            "263/263 [==============================] - 7s 26ms/step - loss: 0.0531 - accuracy: 0.6961\n",
            "Epoch 28/50\n",
            "263/263 [==============================] - 7s 26ms/step - loss: 0.0481 - accuracy: 0.6974\n",
            "Epoch 29/50\n",
            "263/263 [==============================] - 7s 26ms/step - loss: 0.0462 - accuracy: 0.6981\n",
            "Epoch 30/50\n",
            "263/263 [==============================] - 7s 26ms/step - loss: 0.0451 - accuracy: 0.6985\n",
            "Epoch 31/50\n",
            "263/263 [==============================] - 7s 26ms/step - loss: 0.0396 - accuracy: 0.6991\n",
            "Epoch 32/50\n",
            "263/263 [==============================] - 7s 26ms/step - loss: 0.0381 - accuracy: 0.6994\n",
            "Epoch 33/50\n",
            "263/263 [==============================] - 7s 26ms/step - loss: 0.0341 - accuracy: 0.7004\n",
            "Epoch 34/50\n",
            "263/263 [==============================] - 7s 26ms/step - loss: 0.0343 - accuracy: 0.7004\n",
            "Epoch 34: early stopping\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7ff6d11b1e50>"
            ]
          },
          "metadata": {},
          "execution_count": 164
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sentence_generation('요즘 컨디션이 별로야')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "id": "zK10OBc1ahfZ",
        "outputId": "96c02ff6-a885-43ab-e819-ab70bb2ea2d8"
      },
      "execution_count": 165,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "입력 : 요즘 컨디션이 별로야\n",
            "출력 : 다음에는 잘 될 거예요 . \n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'다음에는 잘 될 거예요 . '"
            ]
          },
          "metadata": {},
          "execution_count": 165
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sentence_generation('어떻게 생각할까?')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "id": "_chmfQ0_ahfZ",
        "outputId": "e31ffde2-ac40-4392-e80c-68ebfed55f82"
      },
      "execution_count": 166,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "입력 : 어떻게 생각할까?\n",
            "출력 : 아직은 잘 모르겠어요 . \n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'아직은 잘 모르겠어요 . '"
            ]
          },
          "metadata": {},
          "execution_count": 166
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sentence_generation('오늘 너무 피곤하다')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "id": "nYSOLttZahfZ",
        "outputId": "84ae1c44-2dd0-455d-8c2e-801711bcbfae"
      },
      "execution_count": 167,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "입력 : 오늘 너무 피곤하다\n",
            "출력 : 아무래도 사생활이 적으니까요 . \n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'아무래도 사생활이 적으니까요 . '"
            ]
          },
          "metadata": {},
          "execution_count": 167
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sentence_generation('안녕하세요'), sentence_generation('반가워요!'), sentence_generation('재밌는 경기입니다.'), sentence_generation('너무 화가나요'), sentence_generation('배고파요'), sentence_generation('지쳤어요'), sentence_generation('공부하기 싫어요'), sentence_generation('저녁은 드셨나요?')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EzFUvTnGahfZ",
        "outputId": "4eab670a-de49-4d38-d0d9-af603e4abf38"
      },
      "execution_count": 168,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "입력 : 안녕하세요\n",
            "출력 : 안녕하세요 . \n",
            "입력 : 반가워요!\n",
            "출력 : 반갑습니다 . \n",
            "입력 : 재밌는 경기입니다.\n",
            "출력 : 제가 있잖아요 . \n",
            "입력 : 너무 화가나요\n",
            "출력 : 안 좋은일이 있었나봐요 . \n",
            "입력 : 배고파요\n",
            "출력 : 얼른 맛난 음식 드세요 . \n",
            "입력 : 지쳤어요\n",
            "출력 : 고생 많았어요 . \n",
            "입력 : 공부하기 싫어요\n",
            "출력 : 잠시 쉬어도 돼요 . \n",
            "입력 : 저녁은 드셨나요?\n",
            "출력 : 자신을 위한 결정을 내리길 바라요 . \n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('안녕하세요 . ',\n",
              " '반갑습니다 . ',\n",
              " '제가 있잖아요 . ',\n",
              " '안 좋은일이 있었나봐요 . ',\n",
              " '얼른 맛난 음식 드세요 . ',\n",
              " '고생 많았어요 . ',\n",
              " '잠시 쉬어도 돼요 . ',\n",
              " '자신을 위한 결정을 내리길 바라요 . ')"
            ]
          },
          "metadata": {},
          "execution_count": 168
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### (3) NUM_HEAD = 32"
      ],
      "metadata": {
        "id": "YQcOpdVDajfU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tf.keras.backend.clear_session()\n",
        "\n",
        "NUM_LAYERS = 2 # 인코더와 디코더의 층의 개수\n",
        "D_MODEL = 512 # 인코더와 디코더 내부의 입, 출력의 고정 차원\n",
        "NUM_HEADS = 32 # 멀티 헤드 어텐션에서의 헤드 수 \n",
        "UNITS = 512 # 피드 포워드 신경망의 은닉층의 크기\n",
        "DROPOUT = 0.1 # 드롭아웃의 비율\n",
        "\n",
        "model = transformer(\n",
        "    vocab_size=VOCAB_SIZE,\n",
        "    num_layers=NUM_LAYERS,\n",
        "    units=UNITS,\n",
        "    d_model=D_MODEL,\n",
        "    num_heads=NUM_HEADS,\n",
        "    dropout=DROPOUT)\n",
        "\n",
        "model.summary()\n",
        "\n",
        "# 컴파일\n",
        "learning_rate = CustomSchedule(D_MODEL)\n",
        "\n",
        "optimizer = tf.keras.optimizers.Adam(\n",
        "    learning_rate, beta_1=0.9, beta_2=0.98, epsilon=1e-9)\n",
        "\n",
        "def accuracy(y_true, y_pred):\n",
        "  y_true = tf.reshape(y_true, shape=(-1, MAX_LENGTH - 1))\n",
        "  return tf.keras.metrics.sparse_categorical_accuracy(y_true, y_pred)\n",
        "\n",
        "model.compile(optimizer=optimizer, loss=loss_function, metrics=[accuracy])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FjqI4VYuajfU",
        "outputId": "2facac16-8a84-4cef-d9a1-6cf0aabfff50"
      },
      "execution_count": 169,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"transformer\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " inputs (InputLayer)            [(None, None)]       0           []                               \n",
            "                                                                                                  \n",
            " dec_inputs (InputLayer)        [(None, None)]       0           []                               \n",
            "                                                                                                  \n",
            " enc_padding_mask (Lambda)      (None, 1, 1, None)   0           ['inputs[0][0]']                 \n",
            "                                                                                                  \n",
            " encoder (Functional)           (None, None, 512)    8316416     ['inputs[0][0]',                 \n",
            "                                                                  'enc_padding_mask[0][0]']       \n",
            "                                                                                                  \n",
            " look_ahead_mask (Lambda)       (None, 1, None, Non  0           ['dec_inputs[0][0]']             \n",
            "                                e)                                                                \n",
            "                                                                                                  \n",
            " dec_padding_mask (Lambda)      (None, 1, 1, None)   0           ['inputs[0][0]']                 \n",
            "                                                                                                  \n",
            " decoder (Functional)           (None, None, 512)    10419712    ['dec_inputs[0][0]',             \n",
            "                                                                  'encoder[0][0]',                \n",
            "                                                                  'look_ahead_mask[0][0]',        \n",
            "                                                                  'dec_padding_mask[0][0]']       \n",
            "                                                                                                  \n",
            " outputs (Dense)                (None, None, 10079)  5170527     ['decoder[0][0]']                \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 23,906,655\n",
            "Trainable params: 23,906,655\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "EPOCHS = 50\n",
        "es = EarlyStopping(monitor='loss', patience=1, verbose=1)\n",
        "model.fit(dataset, epochs=EPOCHS, callbacks=[es])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5UAuYmQzajfV",
        "outputId": "dbe9f833-12fb-438f-d0c2-0d370d38f7f3"
      },
      "execution_count": 170,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "263/263 [==============================] - 13s 27ms/step - loss: 5.1577 - accuracy: 0.1825\n",
            "Epoch 2/50\n",
            "263/263 [==============================] - 7s 27ms/step - loss: 3.8128 - accuracy: 0.2436\n",
            "Epoch 3/50\n",
            "263/263 [==============================] - 7s 27ms/step - loss: 3.4318 - accuracy: 0.2586\n",
            "Epoch 4/50\n",
            "263/263 [==============================] - 7s 27ms/step - loss: 3.0972 - accuracy: 0.2797\n",
            "Epoch 5/50\n",
            "263/263 [==============================] - 7s 27ms/step - loss: 2.7255 - accuracy: 0.3180\n",
            "Epoch 6/50\n",
            "263/263 [==============================] - 7s 27ms/step - loss: 2.3099 - accuracy: 0.3713\n",
            "Epoch 7/50\n",
            "263/263 [==============================] - 7s 27ms/step - loss: 1.8609 - accuracy: 0.4264\n",
            "Epoch 8/50\n",
            "263/263 [==============================] - 7s 27ms/step - loss: 1.4097 - accuracy: 0.4858\n",
            "Epoch 9/50\n",
            "263/263 [==============================] - 7s 27ms/step - loss: 1.0136 - accuracy: 0.5403\n",
            "Epoch 10/50\n",
            "263/263 [==============================] - 7s 27ms/step - loss: 0.6933 - accuracy: 0.5884\n",
            "Epoch 11/50\n",
            "263/263 [==============================] - 7s 27ms/step - loss: 0.4595 - accuracy: 0.6267\n",
            "Epoch 12/50\n",
            "263/263 [==============================] - 7s 27ms/step - loss: 0.3213 - accuracy: 0.6475\n",
            "Epoch 13/50\n",
            "263/263 [==============================] - 7s 27ms/step - loss: 0.2437 - accuracy: 0.6598\n",
            "Epoch 14/50\n",
            "263/263 [==============================] - 7s 27ms/step - loss: 0.2103 - accuracy: 0.6643\n",
            "Epoch 15/50\n",
            "263/263 [==============================] - 7s 27ms/step - loss: 0.1992 - accuracy: 0.6656\n",
            "Epoch 16/50\n",
            "263/263 [==============================] - 7s 27ms/step - loss: 0.1878 - accuracy: 0.6663\n",
            "Epoch 17/50\n",
            "263/263 [==============================] - 7s 27ms/step - loss: 0.1592 - accuracy: 0.6722\n",
            "Epoch 18/50\n",
            "263/263 [==============================] - 7s 27ms/step - loss: 0.1397 - accuracy: 0.6757\n",
            "Epoch 19/50\n",
            "263/263 [==============================] - 7s 27ms/step - loss: 0.1166 - accuracy: 0.6815\n",
            "Epoch 20/50\n",
            "263/263 [==============================] - 7s 27ms/step - loss: 0.1001 - accuracy: 0.6850\n",
            "Epoch 21/50\n",
            "263/263 [==============================] - 7s 27ms/step - loss: 0.0903 - accuracy: 0.6877\n",
            "Epoch 22/50\n",
            "263/263 [==============================] - 7s 27ms/step - loss: 0.0819 - accuracy: 0.6895\n",
            "Epoch 23/50\n",
            "263/263 [==============================] - 7s 27ms/step - loss: 0.0708 - accuracy: 0.6919\n",
            "Epoch 24/50\n",
            "263/263 [==============================] - 7s 27ms/step - loss: 0.0679 - accuracy: 0.6928\n",
            "Epoch 25/50\n",
            "263/263 [==============================] - 7s 27ms/step - loss: 0.0584 - accuracy: 0.6948\n",
            "Epoch 26/50\n",
            "263/263 [==============================] - 7s 27ms/step - loss: 0.0553 - accuracy: 0.6960\n",
            "Epoch 27/50\n",
            "263/263 [==============================] - 7s 27ms/step - loss: 0.0510 - accuracy: 0.6968\n",
            "Epoch 28/50\n",
            "263/263 [==============================] - 7s 27ms/step - loss: 0.0487 - accuracy: 0.6972\n",
            "Epoch 29/50\n",
            "263/263 [==============================] - 7s 27ms/step - loss: 0.0448 - accuracy: 0.6984\n",
            "Epoch 30/50\n",
            "263/263 [==============================] - 7s 27ms/step - loss: 0.0424 - accuracy: 0.6988\n",
            "Epoch 31/50\n",
            "263/263 [==============================] - 7s 27ms/step - loss: 0.0389 - accuracy: 0.6994\n",
            "Epoch 32/50\n",
            "263/263 [==============================] - 7s 27ms/step - loss: 0.0373 - accuracy: 0.6999\n",
            "Epoch 33/50\n",
            "263/263 [==============================] - 7s 27ms/step - loss: 0.0341 - accuracy: 0.7003\n",
            "Epoch 34/50\n",
            "263/263 [==============================] - 7s 27ms/step - loss: 0.0322 - accuracy: 0.7010\n",
            "Epoch 35/50\n",
            "263/263 [==============================] - 7s 27ms/step - loss: 0.0310 - accuracy: 0.7010\n",
            "Epoch 36/50\n",
            "263/263 [==============================] - 7s 27ms/step - loss: 0.0293 - accuracy: 0.7017\n",
            "Epoch 37/50\n",
            "263/263 [==============================] - 7s 27ms/step - loss: 0.0289 - accuracy: 0.7017\n",
            "Epoch 38/50\n",
            "263/263 [==============================] - 7s 27ms/step - loss: 0.0271 - accuracy: 0.7021\n",
            "Epoch 39/50\n",
            "263/263 [==============================] - 7s 27ms/step - loss: 0.0261 - accuracy: 0.7022\n",
            "Epoch 40/50\n",
            "263/263 [==============================] - 7s 27ms/step - loss: 0.0233 - accuracy: 0.7027\n",
            "Epoch 41/50\n",
            "263/263 [==============================] - 7s 27ms/step - loss: 0.0232 - accuracy: 0.7026\n",
            "Epoch 42/50\n",
            "263/263 [==============================] - 7s 27ms/step - loss: 0.0236 - accuracy: 0.7025\n",
            "Epoch 42: early stopping\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7ff753e50710>"
            ]
          },
          "metadata": {},
          "execution_count": 170
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sentence_generation('요즘 컨디션이 별로야')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "id": "cX7jiBtWajfV",
        "outputId": "ad82214f-77a6-40e3-cbdb-fda92dc99551"
      },
      "execution_count": 171,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "입력 : 요즘 컨디션이 별로야\n",
            "출력 : 재미로 보기 좋죠 . \n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'재미로 보기 좋죠 . '"
            ]
          },
          "metadata": {},
          "execution_count": 171
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sentence_generation('어떻게 생각할까?')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "id": "56Cv4_gFajfV",
        "outputId": "e4fe9891-9cc3-4896-a33c-c0d2d8efde5b"
      },
      "execution_count": 172,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "입력 : 어떻게 생각할까?\n",
            "출력 : 글쎄요 . \n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'글쎄요 . '"
            ]
          },
          "metadata": {},
          "execution_count": 172
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sentence_generation('오늘 너무 피곤하다')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "id": "-mWa9M9pajfV",
        "outputId": "dc86f6ca-eaa1-4934-8553-1f40e2ea28bd"
      },
      "execution_count": 173,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "입력 : 오늘 너무 피곤하다\n",
            "출력 : 아무래도 사생활이 적으니까요 . \n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'아무래도 사생활이 적으니까요 . '"
            ]
          },
          "metadata": {},
          "execution_count": 173
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sentence_generation('안녕하세요'), sentence_generation('반가워요!'), sentence_generation('재밌는 경기입니다.'), sentence_generation('너무 화가나요'), sentence_generation('배고파요'), sentence_generation('지쳤어요'), sentence_generation('공부하기 싫어요'), sentence_generation('저녁은 드셨나요?')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OS1tY5inajfV",
        "outputId": "6f781337-87b6-4619-f014-ba75a45a1862"
      },
      "execution_count": 174,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "입력 : 안녕하세요\n",
            "출력 : 안녕하세요 . \n",
            "입력 : 반가워요!\n",
            "출력 : 저는 위로봇입니다 . \n",
            "입력 : 재밌는 경기입니다.\n",
            "출력 : 제가 있잖아요 . \n",
            "입력 : 너무 화가나요\n",
            "출력 : 안 좋은일이 있었나봐요 . \n",
            "입력 : 배고파요\n",
            "출력 : 얼른 맛난 음식 드세요 . \n",
            "입력 : 지쳤어요\n",
            "출력 : 저랑 놀아요 . \n",
            "입력 : 공부하기 싫어요\n",
            "출력 : 잠시 쉬어도 돼요 . \n",
            "입력 : 저녁은 드셨나요?\n",
            "출력 : 맛있는 거 드세요 . \n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('안녕하세요 . ',\n",
              " '저는 위로봇입니다 . ',\n",
              " '제가 있잖아요 . ',\n",
              " '안 좋은일이 있었나봐요 . ',\n",
              " '얼른 맛난 음식 드세요 . ',\n",
              " '저랑 놀아요 . ',\n",
              " '잠시 쉬어도 돼요 . ',\n",
              " '맛있는 거 드세요 . ')"
            ]
          },
          "metadata": {},
          "execution_count": 174
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 7. 마치며\n",
        "\n",
        "- 정확도 최고 점수 : 0.7027(6.5.2.(3) 모델)\n",
        "- 최소 loss값 : 0.0232(6.5.2.(3) 모델)\n",
        "- 가장 적절한 문장 생성 : 6.5.1.(1) 모델\n",
        "\n",
        "    >입력 : 요즘 컨디션이 별로야    \n",
        ">\n",
        "    >출력 : 건강에 유의하세요 .\n",
        "\n",
        "    >입력 : 어떻게 생각할까?\n",
        ">\n",
        "    >출력 : 아직은 잘 모르겠어요 . \n",
        "\n",
        "    >입력 : 오늘 너무 피곤하다\n",
        ">\n",
        "    >출력 : 아무래도 사생활이 적으니까요 . \n",
        "\n",
        "    >입력 : 안녕하세요\n",
        ">\n",
        "    >출력 : 안녕하세요 . \n",
        "\n",
        "    >입력 : 반가워요!\n",
        ">\n",
        "    >출력 : 저도 저도요 . \n",
        "\n",
        "    >입력 : 재밌는 경기입니다.\n",
        ">\n",
        "    >출력 : 제가 있잖아요 . \n",
        "\n",
        "    >입력 : 너무 화가나요\n",
        ">\n",
        "    >출력 : 그럴수록 당신이 힘들 거예요 . \n",
        "\n",
        "    >입력 : 배고파요\n",
        ">\n",
        "    >출력 : 얼른 맛난 음식 드세요 . \n",
        "\n",
        "    >입력 : 지쳤어요\n",
        ">\n",
        "    >출력 : 잘 하고 있어요 . \n",
        "\n",
        "    >입력 : 공부하기 싫어요\n",
        ">\n",
        "    >출력 : 조금만 기다려 보세요 . \n",
        "\n",
        "    >입력 : 저녁은 드셨나요?\n",
        "    >\n",
        "    >출력 : 맛있는 거 드세요 . \n",
        "    >"
      ],
      "metadata": {
        "id": "SYCHuODBe5el"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 기억에 남는 학습 내용\n",
        "- 트랜스포머가 문장 단위로 입력을 받아, 토큰의 위치 정보를 기억하는 점\n",
        "- 더뎠지만, 과정을 거치며 서서히 개선되는 것을 보는 것이 좋았다.\n",
        "- 현 단계, 자연어 처리 모델에서 결과 확인은 사람이 해야 하는데, 영어에 대한 언어직관이 없으니 한국어 데이터를 사용하는 것이 훨씬 판단에 용이하다.\n",
        "\n",
        "### 어려웠던 점\n",
        "- 모델의 전반적인 구조\n",
        "- 내 건강(..)\n",
        "- 자연어 처리 모델은 대체로 어렵고, 대체로 과정이 덜 직관적이고, 대체로 결과 개선이 잘 안 된다.\n",
        "- 한웅님이 던져주신 질문 목록 중 '재밌는 경기입니다'에 거의 모든 모델이 '제가 있잖아요'라고 답해서 고통스러웠음\n",
        "\n",
        "### 추가로 해보고 싶은 점\n",
        "- 임베딩 과정을 다듬어 더 좋은 결과를 얻어보고 싶다는 욕심이 생겼는데, 남은 익스플로레이션을 보니 그 부분은 걱정하지 않아도 될 것 같다.\n",
        "\n",
        "\n",
        "### 총평: \n",
        "\n",
        "건강에 문제가 생기니 많은 것이 중단되었다. 체력 관리도 학습에 있어서 중요한 부분이 아닐까.\n",
        "\n",
        "반면(?), 커널이 죽는다던가, 커널이 죽는다던가, 커널이.. 그런 류의 억울한(..) 사건이 생기지 않았다는 것 만으로 훨씬 스트레스가 적었던 것 같다.\n",
        "\n",
        "트랜스포머 모델의 아이디어는 RNN을 기준으로 알고 있던 자연어 처리 분야에 대한 지평이 넓어지는 기분이었다.\n",
        "\n",
        "한국어 자연어 처리에 대한 여러 아이디어들을 배우는 것이 재미있겠다는 생각이 들었다.\n"
      ],
      "metadata": {
        "id": "1DHaym3ge7PI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "BJYYVyxYfMRc"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}